{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c8cb5ce0-f5b7-49f2-860c-77800a1c158e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv1D, MaxPooling1D, Dense, Flatten, Input, AveragePooling1D, Dropout, Softmax\n",
    "from keras.optimizers import Adam, Nadam\n",
    "from keras.regularizers import L2\n",
    "from keras.callbacks import ReduceLROnPlateau, LearningRateScheduler, Callback, LambdaCallback\n",
    "from keras.metrics import Metric\n",
    "from tensorflow import keras\n",
    "\n",
    "from time import perf_counter\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4719d771-9fca-4e41-be72-bbea116b0c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "stresses = ['Gm', 'Drought', 'Nutrient_Deficiency', 'Fs', 'Salinity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "637f054d-6243-4486-9e3c-05af014aa535",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amitt\\AppData\\Local\\Temp\\ipykernel_5344\\1297277926.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_path)\n"
     ]
    }
   ],
   "source": [
    "csv_path = r'..\\combined.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True, errors='ignore')\n",
    "df.drop(columns=['Fungal_infection'], inplace=True, errors='ignore')\n",
    "df[stresses] = df[stresses].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "057ff01b-88c7-4b81-8760-b17477496043",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_cols = [col for col in df.columns if col[0] == 'X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c0290aa-b40b-4772-8a9d-6a1fc049ee75",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzy_win = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c4b6328-e66e-4f61-94ae-679705a882bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_reshape(x):\n",
    "    return x.reshape((-1, x.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c57e57a-d38d-4139-816a-a5c782ccd1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "blur_factor = 4\n",
    "\n",
    "# x = drop_res(fuzzy_dx3, blur_factor=blur_factor)\n",
    "x = df[spec_cols].values\n",
    "y = df[stresses].values\n",
    "\n",
    "x /= x.max()\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02717ef7-b27d-4a48-909e-c2f4457af7a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b360a510-0ba8-4aa1-8846-5aed448034ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Accuracy(Metric):\n",
    "    def __init__(self, name='accuracy', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.accuracy = self.add_variable(\n",
    "            shape=(),\n",
    "            initializer='zeros',\n",
    "            name='accuracy'\n",
    "        )\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        p = tf.cast(tf.reduce_all((y_pred > .5) == y_true, axis=1), tf.float32)\n",
    "        \n",
    "        self.accuracy.assign(tf.reduce_mean(p))\n",
    "\n",
    "    def result(self):\n",
    "        return self.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e2b2baaa-0959-4cca-9578-d4a92f3a831e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.cache\n",
    "def fuzzy_dx_init(shape, dtype=None):\n",
    "    half_shape = list(shape)\n",
    "    half_shape[0] //= 2\n",
    "    half_shape = tuple(half_shape)\n",
    "    return np.vstack((np.ones(half_shape) * -1/half_shape[0], np.ones(half_shape)/half_shape[0]))\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(x_train.shape[1],1)),\n",
    "    Conv1D(1, fuzzy_win*2, trainable=False, kernel_initializer=fuzzy_dx_init),\n",
    "    Conv1D(1, fuzzy_win*2, trainable=False, kernel_initializer=fuzzy_dx_init),\n",
    "    Conv1D(1, fuzzy_win*2, trainable=False, kernel_initializer=fuzzy_dx_init),\n",
    "    AveragePooling1D(blur_factor),\n",
    "    Conv1D(20, 30, kernel_regularizer=L2(.001), name='conv1', activation='relu'),\n",
    "    Conv1D(20, 30, kernel_regularizer=L2(.001), name='conv2', activation='relu'),\n",
    "    MaxPooling1D(2),\n",
    "    Dropout(.02),\n",
    "    Flatten(),\n",
    "    Dense(100, kernel_regularizer=L2(.001), activation='relu'),\n",
    "    Dropout(.02),\n",
    "    Dense(100, kernel_regularizer=L2(.001), activation='relu'),\n",
    "    Dropout(.02),\n",
    "    Dense(100, kernel_regularizer=L2(.001), activation='relu'),\n",
    "    Dropout(.02),\n",
    "    Dense(100, kernel_regularizer=L2(.001), activation='relu'),\n",
    "    Dropout(.02),\n",
    "    Dense(10, kernel_regularizer=L2(.001), activation='relu'),\n",
    "    Dropout(.02),\n",
    "    Dense(y.shape[1], activation='sigmoid'),\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Nadam(1e-4), loss='binary_crossentropy', metrics=[Accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c1ec6a-bfc8-4178-a270-8deb009247f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - accuracy: 0.0612 - loss: 1.1152 - val_accuracy: 0.0000e+00 - val_loss: 0.8774\n",
      "Epoch 2/300\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.1369 - loss: 0.8381 - val_accuracy: 0.4167 - val_loss: 0.6351\n",
      "Epoch 3/300\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.3593 - loss: 0.6336 - val_accuracy: 0.4167 - val_loss: 0.5621\n",
      "Epoch 4/300\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.3624 - loss: 0.5729 - val_accuracy: 0.4167 - val_loss: 0.5282\n",
      "Epoch 5/300\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.3636 - loss: 0.5383 - val_accuracy: 0.4167 - val_loss: 0.5046\n",
      "Epoch 6/300\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.3654 - loss: 0.5104 - val_accuracy: 0.4167 - val_loss: 0.4918\n",
      "Epoch 7/300\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.3696 - loss: 0.4978 - val_accuracy: 0.4167 - val_loss: 0.4791\n",
      "Epoch 8/300\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.3677 - loss: 0.4851 - val_accuracy: 0.4167 - val_loss: 0.4713\n",
      "Epoch 9/300\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.3708 - loss: 0.4778 - val_accuracy: 0.4167 - val_loss: 0.4661\n",
      "Epoch 10/300\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.3762 - loss: 0.4707 - val_accuracy: 0.4167 - val_loss: 0.4628\n",
      "Epoch 11/300\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.3745 - loss: 0.4644 - val_accuracy: 0.4167 - val_loss: 0.4594\n",
      "Epoch 12/300\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.3758 - loss: 0.4648 - val_accuracy: 0.4167 - val_loss: 0.4566\n",
      "Epoch 13/300\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.3752 - loss: 0.4608 - val_accuracy: 0.4167 - val_loss: 0.4544\n",
      "Epoch 14/300\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.3739 - loss: 0.4579 - val_accuracy: 0.4167 - val_loss: 0.4532\n",
      "Epoch 15/300\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.3736 - loss: 0.4547 - val_accuracy: 0.4167 - val_loss: 0.4511\n",
      "Epoch 16/300\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - accuracy: 0.3753 - loss: 0.4524 - val_accuracy: 0.4167 - val_loss: 0.4503\n",
      "Epoch 17/300\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.3761 - loss: 0.4534 - val_accuracy: 0.4167 - val_loss: 0.4503\n",
      "Epoch 18/300\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.3755 - loss: 0.4487 - val_accuracy: 0.4167 - val_loss: 0.4477\n",
      "Epoch 19/300\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.3758 - loss: 0.4482 - val_accuracy: 0.4167 - val_loss: 0.4469\n",
      "Epoch 20/300\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.3772 - loss: 0.4481 - val_accuracy: 0.4167 - val_loss: 0.4461\n",
      "Epoch 21/300\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - accuracy: 0.3793 - loss: 0.4442 - val_accuracy: 0.4167 - val_loss: 0.4449\n",
      "Epoch 22/300\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - accuracy: 0.3798 - loss: 0.4441 - val_accuracy: 0.4167 - val_loss: 0.4442\n",
      "Epoch 23/300\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - accuracy: 0.3800 - loss: 0.4465 - val_accuracy: 0.4167 - val_loss: 0.4440\n",
      "Epoch 24/300\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - accuracy: 0.3792 - loss: 0.4443 - val_accuracy: 0.4167 - val_loss: 0.4431\n",
      "Epoch 25/300\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - accuracy: 0.3806 - loss: 0.4454 - val_accuracy: 0.4167 - val_loss: 0.4425\n",
      "Epoch 26/300\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - accuracy: 0.3783 - loss: 0.4415 - val_accuracy: 0.4167 - val_loss: 0.4421\n",
      "Epoch 27/300\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - accuracy: 0.3795 - loss: 0.4434 - val_accuracy: 0.4167 - val_loss: 0.4416\n",
      "Epoch 28/300\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - accuracy: 0.3789 - loss: 0.4407 - val_accuracy: 0.4167 - val_loss: 0.4412\n",
      "Epoch 29/300\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - accuracy: 0.3817 - loss: 0.4400 - val_accuracy: 0.4167 - val_loss: 0.4411\n",
      "Epoch 30/300\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - accuracy: 0.3808 - loss: 0.4411 - val_accuracy: 0.4167 - val_loss: 0.4413\n",
      "Epoch 31/300\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - accuracy: 0.3838 - loss: 0.4404 - val_accuracy: 0.4167 - val_loss: 0.4400\n",
      "Epoch 32/300\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - accuracy: 0.3844 - loss: 0.4428 - val_accuracy: 0.4167 - val_loss: 0.4397\n",
      "Epoch 33/300\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - accuracy: 0.3845 - loss: 0.4420 - val_accuracy: 0.4167 - val_loss: 0.4395\n",
      "Epoch 34/300\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - accuracy: 0.3846 - loss: 0.4397 - val_accuracy: 0.4167 - val_loss: 0.4392\n",
      "Epoch 35/300\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - accuracy: 0.3843 - loss: 0.4399 - val_accuracy: 0.4167 - val_loss: 0.4391\n",
      "Epoch 36/300\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - accuracy: 0.3847 - loss: 0.4370 - val_accuracy: 0.4167 - val_loss: 0.4390\n",
      "Epoch 37/300\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - accuracy: 0.3849 - loss: 0.4360 - val_accuracy: 0.4167 - val_loss: 0.4385\n",
      "Epoch 38/300\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - accuracy: 0.3847 - loss: 0.4402 - val_accuracy: 0.4167 - val_loss: 0.4383\n",
      "Epoch 39/300\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - accuracy: 0.3847 - loss: 0.4371 - val_accuracy: 0.4167 - val_loss: 0.4384\n",
      "Epoch 40/300\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - accuracy: 0.3848 - loss: 0.4373 - val_accuracy: 0.4167 - val_loss: 0.4381\n",
      "Epoch 41/300\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - accuracy: 0.3848 - loss: 0.4363 - val_accuracy: 0.4167 - val_loss: 0.4380\n",
      "Epoch 42/300\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - accuracy: 0.3845 - loss: 0.4353 - val_accuracy: 0.4167 - val_loss: 0.4377\n",
      "Epoch 43/300\n",
      "\u001b[1m 73/237\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - accuracy: 0.3789 - loss: 0.4402"
     ]
    }
   ],
   "source": [
    "start = perf_counter()\n",
    "\n",
    "history = model.fit(\n",
    "    cnn_reshape(x_train),\n",
    "    y_train,\n",
    "    epochs=300,\n",
    "    validation_data=(cnn_reshape(x_val), y_val),\n",
    "    batch_size=80,\n",
    ")\n",
    "\n",
    "print(perf_counter() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc56ab3-32ec-4e4d-b1b5-a3a3e0a55302",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.gca()\n",
    "\n",
    "ax.plot(history.history['loss'], label='Training')\n",
    "ax.plot(\n",
    "    np.convolve(np.array(history.history['val_loss']), np.ones(10)/10, mode='valid'),\n",
    "    label='Validation (Running Mean)'\n",
    ")\n",
    "ax.legend()\n",
    "ax.set_xlabel('# Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_ylim((0, 1))\n",
    "ax.set_title('CNN Loss over Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b881ed-adfb-4432-b53a-246b1be7a525",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(cnn_reshape(x_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
