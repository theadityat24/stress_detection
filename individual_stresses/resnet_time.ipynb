{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbbac137-e6b9-441d-8c62-8ea5f1df8bb5",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "539d8593-4794-4289-9002-173ba22394d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import sklearn\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import L1, L2, Regularizer, L1L2\n",
    "from keras import ops\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import keras\n",
    "\n",
    "import imblearn\n",
    "\n",
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bee29cb5-dfc1-4c90-a0bc-bbb9ee5345e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thead\\AppData\\Local\\Temp\\ipykernel_25144\\1803658105.py:3: DtypeWarning: Columns (2155) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_path)\n"
     ]
    }
   ],
   "source": [
    "stresses = ['Gm', 'Drought', 'Nutrient_Deficiency', 'Fs', 'Salinity']\n",
    "csv_path = r'..\\combined.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True, errors='ignore')\n",
    "df.drop(columns=['Fungal_infection'], inplace=True, errors='ignore')\n",
    "df[stresses] = df[stresses].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac56ce15-9a0b-4517-96ba-051f8cd7520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_cols = [col for col in df.columns if col[0] == 'X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c7edb38-8446-43b9-96d4-27e06d43cd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "trait_cols = np.array(['Photo',\n",
    "       'Ci', 'Cond', 'CTleaf', 'Trmmol', 'WUEi', 'WUEin', 'Fv_Fm', 'Fv_Fo',\n",
    "       'PI', 'SLA', 'LWC', 'Suc', 'OP', 'OP100', 'RWC', 'WP', 'N', 'C',\n",
    "       'Neoxanthin', 'Violaxanthin', 'Lutein', 'Zeaxanthin', 'Chl_b', 'Chl_a',\n",
    "       'B_carotene', 'Glucose', 'Fructose', 'Sucrose', 'Sugars', 'Starch',\n",
    "       'Ellagic', 'Gal', 'Rut', 'CTs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "505298f9-2c87-46bb-85be-061299b1c0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_spec = df[spec_cols].values\n",
    "yb = df[stresses].values.any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eea0b509-2f73-41e2-ab56-8bb9bf3aae1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t = df['Time'].values.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b322ca3-ef60-47cd-b136-d20ede604b1c",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8e146bf-ddb7-4740-8434-a47e76c4d192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_dx_init(shape, dtype=None):\n",
    "    half_shape = list(shape)\n",
    "    half_shape[0] //= 2\n",
    "    half_shape = tuple(half_shape)\n",
    "    return np.vstack((np.ones(half_shape) * -1/half_shape[0], np.ones(half_shape)/half_shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e2b183f-3539-4c13-a197-b6635fcf51e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_reshape(x):\n",
    "    return x.reshape((-1, x.shape[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d20796-bf28-4103-8ab7-8ff09b9ccb55",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14a53b3d-0156-43ec-96bf-7e8d29fc4df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_spec = ((x_spec - x_spec.min(axis=0))/(x_spec.max(axis=0)-x_spec.min(axis=0)))\n",
    "\n",
    "val_sel = np.random.random(size=(x_spec.shape[0],)) < .2\n",
    "x_spec_train, x_t_train, yb_train = x_spec[~val_sel], x_t[~val_sel], yb[~val_sel]\n",
    "x_spec_val, x_t_val, yb_val = x_spec[val_sel], x_t[val_sel], yb[val_sel]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0f9985-3714-4a12-a847-fc213e49df0c",
   "metadata": {},
   "source": [
    "#### Oversample Minority Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75b1d62c-39f0-4ca9-bf3a-c9a5558f4480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampler = imblearn.over_sampling.RandomOverSampler()\n",
    "# x_temp, yb_train = sampler.fit_resample(np.hstack((x_spec_train, x_t_train)), yb_train)\n",
    "# x_spec_train, x_t_train = x_temp[:,:-1], x_temp[:,-1].reshape((-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5785006-e2fb-4ff8-b0aa-a50cd3666163",
   "metadata": {},
   "source": [
    "## Resblock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00388401-1b12-4d85-b847-0075e05a61f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResBlock1D(x, kernel_size=3, k_reg=.001, pool=3, n_filters=10):\n",
    "    # padding has to be 'same' for add to work\n",
    "    \n",
    "    fx = layers.Conv1D(n_filters, kernel_size, activation='relu', padding='same', kernel_regularizer=L2(k_reg))(x)\n",
    "    fx = layers.BatchNormalization()(fx)\n",
    "    fx = layers.Conv1D(n_filters, kernel_size, activation='relu', padding='same', kernel_regularizer=L2(k_reg))(fx)\n",
    "\n",
    "    ix = layers.Conv1D(n_filters, 1, activation='relu', padding='same', kernel_regularizer=L2(k_reg))(x)\n",
    "    out = layers.Add()([ix, fx])\n",
    "    out = layers.LeakyReLU()(out)\n",
    "    out = layers.BatchNormalization()(out)\n",
    "    out = layers.MaxPooling1D(pool)(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fb781d-1636-4f7a-9937-be01d08020dc",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a9c7655-a380-49c4-81dd-5355acbe5c0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <KerasTensor shape=(None, 2048, 1), dtype=float32, sparse=False, name=keras_tensor_1>\n",
      "1 <KerasTensor shape=(None, 2048, 32), dtype=float32, sparse=False, name=keras_tensor_2>\n",
      "2 <KerasTensor shape=(None, 512, 32), dtype=float32, sparse=False, name=keras_tensor_3>\n",
      "3 <KerasTensor shape=(None, 512, 32), dtype=float32, sparse=False, name=keras_tensor_4>\n",
      "4 <KerasTensor shape=(None, 128, 32), dtype=float32, sparse=False, name=keras_tensor_5>\n",
      "5 <KerasTensor shape=(None, 128, 32), dtype=float32, sparse=False, name=keras_tensor_6>\n",
      "6 <KerasTensor shape=(None, 32, 32), dtype=float32, sparse=False, name=keras_tensor_7>\n",
      "7 <KerasTensor shape=(None, 32, 32), dtype=float32, sparse=False, name=keras_tensor_8>\n",
      "8 <KerasTensor shape=(None, 128, 32), dtype=float32, sparse=False, name=keras_tensor_9>\n",
      "9 <KerasTensor shape=(None, 128, 32), dtype=float32, sparse=False, name=keras_tensor_10>\n",
      "10 <KerasTensor shape=(None, 512, 32), dtype=float32, sparse=False, name=keras_tensor_11>\n",
      "11 <KerasTensor shape=(None, 512, 32), dtype=float32, sparse=False, name=keras_tensor_12>\n",
      "12 <KerasTensor shape=(None, 2048, 32), dtype=float32, sparse=False, name=keras_tensor_13>\n",
      "13 <KerasTensor shape=(None, 2048, 1), dtype=float32, sparse=False, name=keras_tensor_14>\n",
      "14 <KerasTensor shape=(None, 2151, 1), dtype=float32, sparse=False, name=keras_tensor_15>\n"
     ]
    }
   ],
   "source": [
    "k_reg = 0\n",
    "l_reg = 0\n",
    "ae_layers = []\n",
    "\n",
    "ae_layers.append(layers.Cropping1D(cropping=(0, x_spec.shape[-1]-2048)))\n",
    "\n",
    "for _ in range(3):\n",
    "    ae_layers.append(layers.Conv1D(32, 4, activation='relu', padding='same', kernel_regularizer=L2(k_reg)))\n",
    "    ae_layers.append(layers.MaxPooling1D(4))\n",
    "\n",
    "# ae_layers.append(layers.Flatten())\n",
    "# ae_layers.append(layers.Dense(64, activation='relu', kernel_regularizer=L2(l_reg)))\n",
    "\n",
    "# ae_layers.append(layers.Reshape((64, 1)))\n",
    "\n",
    "for _ in range(3):\n",
    "    ae_layers.append(layers.Conv1D(32, 4, activation='relu', padding='same', kernel_regularizer=L2(k_reg)))\n",
    "    ae_layers.append(layers.UpSampling1D(4))\n",
    "\n",
    "ae_layers.append(layers.Conv1D(1, 4, activation='relu', padding='same', kernel_regularizer=L2(k_reg)))\n",
    "\n",
    "# ae_layers.append(layers.Flatten())\n",
    "\n",
    "# ae_layers.append(layers.Dense(x_spec.shape[-1], activation='relu', kernel_regularizer=L2(l_reg)))\n",
    "# ae_layers.append(layers.Reshape((x_spec.shape[-1], 1)))\n",
    "\n",
    "ae_layers.append(layers.ZeroPadding1D(padding=(0,x_spec.shape[-1]-2048)))\n",
    "\n",
    "fx = layers.Input(shape=(x_spec.shape[1],1))\n",
    "for i, layer in enumerate(ae_layers):\n",
    "    fx = layer(fx)\n",
    "    print(f'{i} {fx}')\n",
    "\n",
    "ae_model = Sequential(ae_layers)\n",
    "ae_model.compile(optimizer=Adam(1e-4), loss='mse', metrics=['mse'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4dde6e3-6523-45ef-8ddb-0f94b72a9315",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 212ms/step - loss: 0.2488 - mse: 0.2488 - val_loss: 0.2417 - val_mse: 0.2417\n",
      "Epoch 2/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.2483 - mse: 0.2483 - val_loss: 0.2417 - val_mse: 0.2417\n",
      "Epoch 3/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.2495 - mse: 0.2495 - val_loss: 0.2417 - val_mse: 0.2417\n",
      "Epoch 4/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.2465 - mse: 0.2465 - val_loss: 0.2417 - val_mse: 0.2417\n",
      "Epoch 5/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.2480 - mse: 0.2480 - val_loss: 0.2414 - val_mse: 0.2414\n",
      "Epoch 6/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.2495 - mse: 0.2495 - val_loss: 0.2359 - val_mse: 0.2359\n",
      "Epoch 7/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.2382 - mse: 0.2382 - val_loss: 0.2256 - val_mse: 0.2256\n",
      "Epoch 8/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.2308 - mse: 0.2308 - val_loss: 0.2157 - val_mse: 0.2157\n",
      "Epoch 9/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.2211 - mse: 0.2211 - val_loss: 0.2055 - val_mse: 0.2055\n",
      "Epoch 10/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.2106 - mse: 0.2106 - val_loss: 0.1944 - val_mse: 0.1944\n",
      "Epoch 11/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.1965 - mse: 0.1965 - val_loss: 0.1822 - val_mse: 0.1822\n",
      "Epoch 12/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1850 - mse: 0.1850 - val_loss: 0.1680 - val_mse: 0.1680\n",
      "Epoch 13/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.1686 - mse: 0.1686 - val_loss: 0.1515 - val_mse: 0.1515\n",
      "Epoch 14/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.1521 - mse: 0.1521 - val_loss: 0.1323 - val_mse: 0.1323\n",
      "Epoch 15/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.1315 - mse: 0.1315 - val_loss: 0.1108 - val_mse: 0.1108\n",
      "Epoch 16/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.1091 - mse: 0.1091 - val_loss: 0.0875 - val_mse: 0.0875\n",
      "Epoch 17/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0855 - mse: 0.0855 - val_loss: 0.0634 - val_mse: 0.0634\n",
      "Epoch 18/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0604 - mse: 0.0604 - val_loss: 0.0416 - val_mse: 0.0416\n",
      "Epoch 19/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0396 - mse: 0.0396 - val_loss: 0.0276 - val_mse: 0.0276\n",
      "Epoch 20/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 21/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0258 - val_mse: 0.0258\n",
      "Epoch 22/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 23/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 24/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 25/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 26/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 27/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 28/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 29/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 30/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 31/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 32/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 33/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 34/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 35/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 36/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0124 - val_mse: 0.0124\n",
      "Epoch 37/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0121 - val_mse: 0.0121\n",
      "Epoch 38/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0118 - val_mse: 0.0118\n",
      "Epoch 39/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0116 - val_mse: 0.0116\n",
      "Epoch 40/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 41/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0110 - val_mse: 0.0110\n",
      "Epoch 42/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0108 - val_mse: 0.0108\n",
      "Epoch 43/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0106 - val_mse: 0.0106\n",
      "Epoch 44/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0104 - val_mse: 0.0104\n",
      "Epoch 45/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0103 - val_mse: 0.0103\n",
      "Epoch 46/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0102 - val_mse: 0.0102\n",
      "Epoch 47/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0101 - val_mse: 0.0101\n",
      "Epoch 48/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 49/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 50/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 51/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 52/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 53/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 54/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 55/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 56/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 57/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 58/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 59/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 60/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 61/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 62/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 63/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 64/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 65/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 66/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 67/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 68/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 69/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 70/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 71/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 72/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 73/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 74/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 75/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 76/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 77/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 78/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 79/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 80/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 81/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 82/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 83/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 84/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 85/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 86/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 87/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 88/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 89/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 90/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 91/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 92/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 93/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 94/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 95/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 96/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 97/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 98/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 99/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 100/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 101/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 102/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 103/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 104/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 105/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 106/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 107/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 108/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 109/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 110/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 111/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 112/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 113/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 114/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 115/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 116/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 117/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 118/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 119/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 120/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 121/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 122/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 123/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 124/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 125/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 126/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 127/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 128/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 129/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 130/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 131/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 132/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 133/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 134/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 135/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 136/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 137/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 138/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 139/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 140/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 141/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 142/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 143/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 144/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 145/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 146/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 147/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 148/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 149/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 150/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0084 - val_mse: 0.0084\n"
     ]
    }
   ],
   "source": [
    "history = ae_model.fit(\n",
    "    cnn_reshape(x_spec_train),\n",
    "    cnn_reshape(x_spec_train),\n",
    "    epochs=150,\n",
    "    validation_data=(cnn_reshape(x_spec_val), cnn_reshape(x_spec_val)),\n",
    "    batch_size=200,\n",
    "    # callbacks=[ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=10, min_lr=1e-5)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "442d44ba-c430-40c2-ab50-3d62d7d11556",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ae_train = cnn_reshape(x_spec_train)\n",
    "for layer in ae_model.layers[:8]:\n",
    "    x_ae_train = layer(x_ae_train)\n",
    "x_ae_train = x_ae_train.numpy()\n",
    "\n",
    "x_ae_val = cnn_reshape(x_spec_val)\n",
    "for layer in ae_model.layers[:8]:\n",
    "    x_ae_val = layer(x_ae_val)\n",
    "x_ae_val = x_ae_val.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b30b0c96-fcc1-4d52-abdc-f6884cc93d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(834, 32, 32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ae_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dda5bc8-00ab-4698-96cb-33f4310180ba",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9717ce6f-2cc2-477a-8ee9-adc96230fdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(x, t,\n",
    "    fuzzy_win = 5, blur_factor = 5, spatial_dropout_k = 0.2, dropout_k = .05, l_reg = .001, c_reg = .001,\n",
    "    n_filters=10, kernel_size=3, pool=5, n_conv_layers=3, n_conv_layers_pool_1=1, n_linear_layers=16, linear_size=50\n",
    "):\n",
    "    cnn_model_layers = [\n",
    "        # layers.GaussianNoise(.0),\n",
    "        # layers.Conv1D(1, fuzzy_win*2, trainable=False, kernel_initializer=fuzzy_dx_init),\n",
    "        # layers.AveragePooling1D(blur_factor),\n",
    "    ]\n",
    "\n",
    "    for _ in range(n_conv_layers):\n",
    "        cnn_model_layers.append(lambda x: ResBlock1D(x, kernel_size=kernel_size, k_reg=c_reg, pool=pool, n_filters=n_filters))\n",
    "        cnn_model_layers.append(layers.SpatialDropout1D(spatial_dropout_k))\n",
    "    for _ in range(n_conv_layers_pool_1):\n",
    "        cnn_model_layers.append(lambda x: ResBlock1D(x, kernel_size=kernel_size, k_reg=c_reg, pool=1, n_filters=n_filters))\n",
    "        cnn_model_layers.append(layers.SpatialDropout1D(spatial_dropout_k))\n",
    "    \n",
    "    \n",
    "    linear_layers = [\n",
    "    ]\n",
    "    \n",
    "    # for _ in range(1):\n",
    "    #     linear_layers.append(layers.Dense(128, activation='relu', kernel_regularizer=L2(l_reg)))\n",
    "    #     linear_layers.append(layers.Dropout(dropout_k))\n",
    "    \n",
    "    for _ in range(n_linear_layers):\n",
    "        linear_layers.append(layers.Dense(linear_size, activation='relu', kernel_regularizer=L2(l_reg)))\n",
    "        linear_layers.append(layers.Dropout(dropout_k))\n",
    "\n",
    "    for _ in range(n_linear_layers):\n",
    "        linear_layers.append(layers.Dense(linear_size//2, activation='relu', kernel_regularizer=L2(l_reg)))\n",
    "        linear_layers.append(layers.Dropout(dropout_k))\n",
    "    \n",
    "    linear_layers.append(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    \n",
    "    \n",
    "    spec_inputs = layers.Input(shape=(x.shape[1],x.shape[2]))\n",
    "    t_inputs = layers.Input(shape=(t.shape[1],))\n",
    "    \n",
    "    fx = spec_inputs\n",
    "    \n",
    "    for layer in cnn_model_layers:\n",
    "        print(fx.shape)\n",
    "        fx = layer(fx)\n",
    "    \n",
    "    fx = layers.Flatten()(fx)\n",
    "    fx = layers.Concatenate()([fx, t_inputs])\n",
    "    \n",
    "    for layer in linear_layers:\n",
    "        fx = layer(fx)\n",
    "    \n",
    "    cnn_model_outputs = fx\n",
    "    cnn_model = Model(inputs=[spec_inputs, t_inputs], outputs=cnn_model_outputs)\n",
    "    \n",
    "    cnn_model.compile(optimizer=Adam(4e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    # cnn_model.compile(optimizer=Adam(1e-4), loss=keras.losses.BinaryFocalCrossentropy(alpha=.1), metrics=['accuracy'])\n",
    "\n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4834763b-cc27-4c4b-977c-b275fa3fd26b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# acc = {'n_linear_layers': [], 'linear_size': [], 'accuracy': []}\n",
    "\n",
    "# for n_linear_layers in [8, 16, 32]:\n",
    "#     for linear_size in [32, 64, 128]:\n",
    "\n",
    "#         cnn_model = make_model(n_linear_layers=n_linear_layers, linear_size=linear_size)\n",
    "\n",
    "#         start = perf_counter()\n",
    "        \n",
    "#         history = cnn_model.fit(\n",
    "#             [cnn_reshape(x_spec_train), x_t_train],\n",
    "#             yb_train,\n",
    "#             epochs=100,\n",
    "#             validation_data=([cnn_reshape(x_spec_val), x_t_val], yb_val),\n",
    "#             batch_size=5,\n",
    "#             # callbacks=[ReduceLROnPlateau(monitor='val_loss', factor=0.4, patience=20, min_lr=1e-5)]\n",
    "#         )\n",
    "\n",
    "#         acc['n_linear_layers'].append(n_linear_layers)\n",
    "#         acc['linear_size'].append(linear_size)\n",
    "\n",
    "#         a = ((cnn_model.predict([cnn_reshape(x_spec_val), x_t_val]) > .5) == yb_val).mean()\n",
    "#         acc['accuracy'].append(a)\n",
    "        \n",
    "#         print(f'n_linear_layers={n_linear_layers}, linear_size={linear_size}, acc={a}, time={perf_counter() - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0e6b239-d2fa-4544-89b1-25c384e48ad1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 32, 32)\n",
      "(None, 16, 8)\n",
      "(None, 16, 8)\n",
      "(None, 16, 8)\n",
      "(None, 16, 8)\n",
      "(None, 16, 8)\n",
      "(None, 16, 8)\n",
      "(None, 16, 8)\n",
      "Epoch 1/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - accuracy: 0.3357 - loss: 0.6954 - val_accuracy: 0.6111 - val_loss: 0.6930\n",
      "Epoch 2/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.3525 - loss: 0.6946 - val_accuracy: 0.6768 - val_loss: 0.6924\n",
      "Epoch 3/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.5120 - loss: 0.6932 - val_accuracy: 0.6768 - val_loss: 0.6920\n",
      "Epoch 4/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6475 - loss: 0.6924 - val_accuracy: 0.6768 - val_loss: 0.6916\n",
      "Epoch 5/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6619 - loss: 0.6917 - val_accuracy: 0.6768 - val_loss: 0.6913\n",
      "Epoch 6/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6643 - loss: 0.6912 - val_accuracy: 0.6768 - val_loss: 0.6909\n",
      "Epoch 7/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6643 - loss: 0.6908 - val_accuracy: 0.6768 - val_loss: 0.6905\n",
      "Epoch 8/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6643 - loss: 0.6904 - val_accuracy: 0.6768 - val_loss: 0.6901\n",
      "Epoch 9/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6643 - loss: 0.6901 - val_accuracy: 0.6768 - val_loss: 0.6896\n",
      "Epoch 10/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6643 - loss: 0.6895 - val_accuracy: 0.6768 - val_loss: 0.6891\n",
      "Epoch 11/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6643 - loss: 0.6890 - val_accuracy: 0.6768 - val_loss: 0.6886\n",
      "Epoch 12/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6643 - loss: 0.6885 - val_accuracy: 0.6768 - val_loss: 0.6881\n",
      "Epoch 13/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.6643 - loss: 0.6880 - val_accuracy: 0.6768 - val_loss: 0.6875\n",
      "Epoch 14/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6643 - loss: 0.6876 - val_accuracy: 0.6768 - val_loss: 0.6870\n",
      "Epoch 15/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.6643 - loss: 0.6869 - val_accuracy: 0.6768 - val_loss: 0.6865\n",
      "Epoch 16/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6643 - loss: 0.6863 - val_accuracy: 0.6768 - val_loss: 0.6859\n",
      "Epoch 17/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6643 - loss: 0.6858 - val_accuracy: 0.6768 - val_loss: 0.6853\n",
      "Epoch 18/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6643 - loss: 0.6852 - val_accuracy: 0.6768 - val_loss: 0.6847\n",
      "Epoch 19/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6643 - loss: 0.6846 - val_accuracy: 0.6768 - val_loss: 0.6841\n",
      "Epoch 20/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6643 - loss: 0.6838 - val_accuracy: 0.6768 - val_loss: 0.6834\n",
      "Epoch 21/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6643 - loss: 0.6831 - val_accuracy: 0.6768 - val_loss: 0.6827\n",
      "Epoch 22/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.6643 - loss: 0.6823 - val_accuracy: 0.6768 - val_loss: 0.6820\n",
      "Epoch 23/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6643 - loss: 0.6815 - val_accuracy: 0.6768 - val_loss: 0.6813\n",
      "Epoch 24/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6643 - loss: 0.6805 - val_accuracy: 0.6768 - val_loss: 0.6806\n",
      "Epoch 25/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6643 - loss: 0.6796 - val_accuracy: 0.6768 - val_loss: 0.6798\n",
      "Epoch 26/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6643 - loss: 0.6788 - val_accuracy: 0.6768 - val_loss: 0.6790\n",
      "Epoch 27/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6643 - loss: 0.6774 - val_accuracy: 0.6768 - val_loss: 0.6781\n",
      "Epoch 28/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6643 - loss: 0.6763 - val_accuracy: 0.6768 - val_loss: 0.6771\n",
      "Epoch 29/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6643 - loss: 0.6749 - val_accuracy: 0.6768 - val_loss: 0.6761\n",
      "Epoch 30/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6643 - loss: 0.6736 - val_accuracy: 0.6768 - val_loss: 0.6750\n",
      "Epoch 31/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6643 - loss: 0.6722 - val_accuracy: 0.6768 - val_loss: 0.6737\n",
      "Epoch 32/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6643 - loss: 0.6697 - val_accuracy: 0.6768 - val_loss: 0.6723\n",
      "Epoch 33/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6643 - loss: 0.6683 - val_accuracy: 0.6768 - val_loss: 0.6707\n",
      "Epoch 34/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6643 - loss: 0.6652 - val_accuracy: 0.6768 - val_loss: 0.6689\n",
      "Epoch 35/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6643 - loss: 0.6641 - val_accuracy: 0.6768 - val_loss: 0.6670\n",
      "Epoch 36/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.6643 - loss: 0.6620 - val_accuracy: 0.6768 - val_loss: 0.6650\n",
      "Epoch 37/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6643 - loss: 0.6583 - val_accuracy: 0.6768 - val_loss: 0.6628\n",
      "Epoch 38/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6643 - loss: 0.6561 - val_accuracy: 0.6768 - val_loss: 0.6604\n",
      "Epoch 39/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6643 - loss: 0.6529 - val_accuracy: 0.6768 - val_loss: 0.6579\n",
      "Epoch 40/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6643 - loss: 0.6476 - val_accuracy: 0.6768 - val_loss: 0.6553\n",
      "Epoch 41/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6643 - loss: 0.6456 - val_accuracy: 0.6768 - val_loss: 0.6526\n",
      "Epoch 42/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6643 - loss: 0.6467 - val_accuracy: 0.6768 - val_loss: 0.6497\n",
      "Epoch 43/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6643 - loss: 0.6368 - val_accuracy: 0.6768 - val_loss: 0.6467\n",
      "Epoch 44/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6643 - loss: 0.6376 - val_accuracy: 0.6768 - val_loss: 0.6436\n",
      "Epoch 45/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.6643 - loss: 0.6329 - val_accuracy: 0.6768 - val_loss: 0.6407\n",
      "Epoch 46/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6643 - loss: 0.6337 - val_accuracy: 0.6768 - val_loss: 0.6380\n",
      "Epoch 47/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6643 - loss: 0.6295 - val_accuracy: 0.6768 - val_loss: 0.6359\n",
      "Epoch 48/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6643 - loss: 0.6398 - val_accuracy: 0.6768 - val_loss: 0.6345\n",
      "Epoch 49/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6643 - loss: 0.6320 - val_accuracy: 0.6768 - val_loss: 0.6338\n",
      "Epoch 50/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6643 - loss: 0.6371 - val_accuracy: 0.6768 - val_loss: 0.6336\n",
      "Epoch 51/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6643 - loss: 0.6394 - val_accuracy: 0.6768 - val_loss: 0.6339\n",
      "Epoch 52/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6643 - loss: 0.6324 - val_accuracy: 0.6768 - val_loss: 0.6343\n",
      "Epoch 53/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6643 - loss: 0.6275 - val_accuracy: 0.6768 - val_loss: 0.6348\n",
      "Epoch 54/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6643 - loss: 0.6304 - val_accuracy: 0.6768 - val_loss: 0.6353\n",
      "Epoch 55/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.6643 - loss: 0.6288 - val_accuracy: 0.6768 - val_loss: 0.6358\n",
      "Epoch 56/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.6643 - loss: 0.6306 - val_accuracy: 0.6768 - val_loss: 0.6363\n",
      "Epoch 57/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.6643 - loss: 0.6329 - val_accuracy: 0.6768 - val_loss: 0.6367\n",
      "Epoch 58/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.6643 - loss: 0.6293 - val_accuracy: 0.6768 - val_loss: 0.6371\n",
      "Epoch 59/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.6643 - loss: 0.6264 - val_accuracy: 0.6768 - val_loss: 0.6371\n",
      "Epoch 60/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6643 - loss: 0.6303 - val_accuracy: 0.6768 - val_loss: 0.6370\n",
      "Epoch 61/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6643 - loss: 0.6266 - val_accuracy: 0.6768 - val_loss: 0.6365\n",
      "Epoch 62/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6643 - loss: 0.6235 - val_accuracy: 0.6768 - val_loss: 0.6358\n",
      "Epoch 63/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6643 - loss: 0.6227 - val_accuracy: 0.6768 - val_loss: 0.6348\n",
      "Epoch 64/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6643 - loss: 0.6281 - val_accuracy: 0.6768 - val_loss: 0.6337\n",
      "Epoch 65/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6643 - loss: 0.6290 - val_accuracy: 0.6768 - val_loss: 0.6327\n",
      "Epoch 66/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6643 - loss: 0.6203 - val_accuracy: 0.6768 - val_loss: 0.6315\n",
      "Epoch 67/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.6643 - loss: 0.6231 - val_accuracy: 0.6768 - val_loss: 0.6305\n",
      "Epoch 68/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.6643 - loss: 0.6143 - val_accuracy: 0.6768 - val_loss: 0.6294\n",
      "Epoch 69/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.6643 - loss: 0.6215 - val_accuracy: 0.6768 - val_loss: 0.6284\n",
      "Epoch 70/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.6643 - loss: 0.6223 - val_accuracy: 0.6768 - val_loss: 0.6277\n",
      "Epoch 71/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.6643 - loss: 0.6234 - val_accuracy: 0.6768 - val_loss: 0.6274\n",
      "Epoch 72/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6643 - loss: 0.6219 - val_accuracy: 0.6768 - val_loss: 0.6273\n",
      "Epoch 73/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6643 - loss: 0.6252 - val_accuracy: 0.6768 - val_loss: 0.6274\n",
      "Epoch 74/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6643 - loss: 0.6178 - val_accuracy: 0.6768 - val_loss: 0.6275\n",
      "Epoch 75/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.6643 - loss: 0.6190 - val_accuracy: 0.6768 - val_loss: 0.6278\n",
      "Epoch 76/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6643 - loss: 0.6198 - val_accuracy: 0.6768 - val_loss: 0.6282\n",
      "Epoch 77/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6643 - loss: 0.6177 - val_accuracy: 0.6768 - val_loss: 0.6286\n",
      "Epoch 78/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6643 - loss: 0.6178 - val_accuracy: 0.6768 - val_loss: 0.6289\n",
      "Epoch 79/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.6643 - loss: 0.6114 - val_accuracy: 0.6768 - val_loss: 0.6289\n",
      "Epoch 80/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6643 - loss: 0.6162 - val_accuracy: 0.6768 - val_loss: 0.6287\n",
      "Epoch 81/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.6643 - loss: 0.6179 - val_accuracy: 0.6768 - val_loss: 0.6285\n",
      "Epoch 82/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6643 - loss: 0.6088 - val_accuracy: 0.6768 - val_loss: 0.6278\n",
      "Epoch 83/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6643 - loss: 0.6087 - val_accuracy: 0.6768 - val_loss: 0.6270\n",
      "Epoch 84/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6643 - loss: 0.6080 - val_accuracy: 0.6768 - val_loss: 0.6260\n",
      "Epoch 85/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6643 - loss: 0.6093 - val_accuracy: 0.6768 - val_loss: 0.6249\n",
      "Epoch 86/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6643 - loss: 0.6095 - val_accuracy: 0.6768 - val_loss: 0.6239\n",
      "Epoch 87/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6643 - loss: 0.6093 - val_accuracy: 0.6768 - val_loss: 0.6229\n",
      "Epoch 88/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6643 - loss: 0.6021 - val_accuracy: 0.6768 - val_loss: 0.6220\n",
      "Epoch 89/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6643 - loss: 0.6000 - val_accuracy: 0.6768 - val_loss: 0.6211\n",
      "Epoch 90/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6643 - loss: 0.6059 - val_accuracy: 0.6768 - val_loss: 0.6205\n",
      "Epoch 91/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6643 - loss: 0.6148 - val_accuracy: 0.6768 - val_loss: 0.6202\n",
      "Epoch 92/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6643 - loss: 0.6094 - val_accuracy: 0.6768 - val_loss: 0.6202\n",
      "Epoch 93/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6643 - loss: 0.5984 - val_accuracy: 0.6768 - val_loss: 0.6201\n",
      "Epoch 94/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6643 - loss: 0.6142 - val_accuracy: 0.6768 - val_loss: 0.6201\n",
      "Epoch 95/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6643 - loss: 0.6055 - val_accuracy: 0.6768 - val_loss: 0.6200\n",
      "Epoch 96/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.6643 - loss: 0.5974 - val_accuracy: 0.6768 - val_loss: 0.6197\n",
      "Epoch 97/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6643 - loss: 0.6013 - val_accuracy: 0.6768 - val_loss: 0.6192\n",
      "Epoch 98/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6643 - loss: 0.6076 - val_accuracy: 0.6768 - val_loss: 0.6187\n",
      "Epoch 99/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6643 - loss: 0.6005 - val_accuracy: 0.6768 - val_loss: 0.6181\n",
      "Epoch 100/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6643 - loss: 0.6024 - val_accuracy: 0.6768 - val_loss: 0.6174\n",
      "Epoch 101/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.6643 - loss: 0.5953 - val_accuracy: 0.6768 - val_loss: 0.6164\n",
      "Epoch 102/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6643 - loss: 0.5934 - val_accuracy: 0.6768 - val_loss: 0.6151\n",
      "Epoch 103/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.6643 - loss: 0.5954 - val_accuracy: 0.6768 - val_loss: 0.6138\n",
      "Epoch 104/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.6643 - loss: 0.5937 - val_accuracy: 0.6768 - val_loss: 0.6125\n",
      "Epoch 105/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.6643 - loss: 0.6031 - val_accuracy: 0.6768 - val_loss: 0.6113\n",
      "Epoch 106/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6643 - loss: 0.6023 - val_accuracy: 0.6768 - val_loss: 0.6103\n",
      "Epoch 107/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.6643 - loss: 0.5999 - val_accuracy: 0.6768 - val_loss: 0.6096\n",
      "Epoch 108/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6643 - loss: 0.5924 - val_accuracy: 0.6768 - val_loss: 0.6091\n",
      "Epoch 109/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6643 - loss: 0.5900 - val_accuracy: 0.6768 - val_loss: 0.6085\n",
      "Epoch 110/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6643 - loss: 0.5970 - val_accuracy: 0.6768 - val_loss: 0.6079\n",
      "Epoch 111/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6643 - loss: 0.6016 - val_accuracy: 0.6768 - val_loss: 0.6075\n",
      "Epoch 112/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6643 - loss: 0.5994 - val_accuracy: 0.6768 - val_loss: 0.6073\n",
      "Epoch 113/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6643 - loss: 0.5912 - val_accuracy: 0.6768 - val_loss: 0.6070\n",
      "Epoch 114/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.6643 - loss: 0.6041 - val_accuracy: 0.6768 - val_loss: 0.6070\n",
      "Epoch 115/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.6643 - loss: 0.5966 - val_accuracy: 0.6768 - val_loss: 0.6070\n",
      "Epoch 116/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.6643 - loss: 0.5985 - val_accuracy: 0.6768 - val_loss: 0.6069\n",
      "Epoch 117/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6643 - loss: 0.5899 - val_accuracy: 0.6768 - val_loss: 0.6066\n",
      "Epoch 118/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6643 - loss: 0.5966 - val_accuracy: 0.6768 - val_loss: 0.6064\n",
      "Epoch 119/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6643 - loss: 0.5905 - val_accuracy: 0.6768 - val_loss: 0.6061\n",
      "Epoch 120/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6643 - loss: 0.5861 - val_accuracy: 0.6768 - val_loss: 0.6056\n",
      "Epoch 121/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6643 - loss: 0.5904 - val_accuracy: 0.6768 - val_loss: 0.6052\n",
      "Epoch 122/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6643 - loss: 0.5891 - val_accuracy: 0.6768 - val_loss: 0.6048\n",
      "Epoch 123/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.6643 - loss: 0.5821 - val_accuracy: 0.6768 - val_loss: 0.6045\n",
      "Epoch 124/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6643 - loss: 0.5858 - val_accuracy: 0.6768 - val_loss: 0.6042\n",
      "Epoch 125/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.6643 - loss: 0.5849 - val_accuracy: 0.6768 - val_loss: 0.6041\n",
      "Epoch 126/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6643 - loss: 0.5852 - val_accuracy: 0.6768 - val_loss: 0.6041\n",
      "Epoch 127/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6643 - loss: 0.5874 - val_accuracy: 0.6768 - val_loss: 0.6041\n",
      "Epoch 128/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.6643 - loss: 0.5760 - val_accuracy: 0.6768 - val_loss: 0.6043\n",
      "Epoch 129/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6643 - loss: 0.5864 - val_accuracy: 0.6768 - val_loss: 0.6045\n",
      "Epoch 130/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6643 - loss: 0.5896 - val_accuracy: 0.6768 - val_loss: 0.6048\n",
      "Epoch 131/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.6643 - loss: 0.5824 - val_accuracy: 0.6768 - val_loss: 0.6048\n",
      "Epoch 132/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6643 - loss: 0.5911 - val_accuracy: 0.6768 - val_loss: 0.6050\n",
      "Epoch 133/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.6643 - loss: 0.5838 - val_accuracy: 0.6768 - val_loss: 0.6052\n",
      "Epoch 134/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6643 - loss: 0.5803 - val_accuracy: 0.6768 - val_loss: 0.6051\n",
      "Epoch 135/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6643 - loss: 0.5890 - val_accuracy: 0.6768 - val_loss: 0.6049\n",
      "Epoch 136/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6643 - loss: 0.5837 - val_accuracy: 0.6768 - val_loss: 0.6048\n",
      "Epoch 137/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6643 - loss: 0.5917 - val_accuracy: 0.6768 - val_loss: 0.6048\n",
      "Epoch 138/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6643 - loss: 0.5901 - val_accuracy: 0.6768 - val_loss: 0.6047\n",
      "Epoch 139/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6643 - loss: 0.5922 - val_accuracy: 0.6768 - val_loss: 0.6044\n",
      "Epoch 140/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6643 - loss: 0.5739 - val_accuracy: 0.6768 - val_loss: 0.6039\n",
      "Epoch 141/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6643 - loss: 0.5819 - val_accuracy: 0.6768 - val_loss: 0.6036\n",
      "Epoch 142/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6643 - loss: 0.5778 - val_accuracy: 0.6768 - val_loss: 0.6032\n",
      "Epoch 143/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6643 - loss: 0.5855 - val_accuracy: 0.6768 - val_loss: 0.6030\n",
      "Epoch 144/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.6643 - loss: 0.5790 - val_accuracy: 0.6768 - val_loss: 0.6028\n",
      "Epoch 145/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6643 - loss: 0.5901 - val_accuracy: 0.6768 - val_loss: 0.6030\n",
      "Epoch 146/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6643 - loss: 0.5693 - val_accuracy: 0.6768 - val_loss: 0.6030\n",
      "Epoch 147/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6643 - loss: 0.5665 - val_accuracy: 0.6768 - val_loss: 0.6030\n",
      "Epoch 148/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6643 - loss: 0.5723 - val_accuracy: 0.6768 - val_loss: 0.6030\n",
      "Epoch 149/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6643 - loss: 0.5793 - val_accuracy: 0.6768 - val_loss: 0.6031\n",
      "Epoch 150/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6643 - loss: 0.5793 - val_accuracy: 0.6768 - val_loss: 0.6032\n",
      "Epoch 151/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6643 - loss: 0.5767 - val_accuracy: 0.6768 - val_loss: 0.6035\n",
      "Epoch 152/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6643 - loss: 0.5752 - val_accuracy: 0.6768 - val_loss: 0.6035\n",
      "Epoch 153/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.6643 - loss: 0.5762 - val_accuracy: 0.6768 - val_loss: 0.6033\n",
      "Epoch 154/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6643 - loss: 0.5810 - val_accuracy: 0.6768 - val_loss: 0.6034\n",
      "Epoch 155/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6643 - loss: 0.5740 - val_accuracy: 0.6768 - val_loss: 0.6033\n",
      "Epoch 156/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6643 - loss: 0.5851 - val_accuracy: 0.6768 - val_loss: 0.6032\n",
      "Epoch 157/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6643 - loss: 0.5776 - val_accuracy: 0.6768 - val_loss: 0.6030\n",
      "Epoch 158/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.6990 - loss: 0.5933 - val_accuracy: 0.6768 - val_loss: 0.6030\n",
      "Epoch 159/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.7026 - loss: 0.5704 - val_accuracy: 0.6768 - val_loss: 0.6028\n",
      "Epoch 160/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7122 - loss: 0.5742 - val_accuracy: 0.6768 - val_loss: 0.6026\n",
      "Epoch 161/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7350 - loss: 0.5700 - val_accuracy: 0.6768 - val_loss: 0.6026\n",
      "Epoch 162/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7062 - loss: 0.5738 - val_accuracy: 0.6768 - val_loss: 0.6026\n",
      "Epoch 163/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7158 - loss: 0.5701 - val_accuracy: 0.6768 - val_loss: 0.6027\n",
      "Epoch 164/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7122 - loss: 0.5809 - val_accuracy: 0.6768 - val_loss: 0.6029\n",
      "Epoch 165/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.7278 - loss: 0.5676 - val_accuracy: 0.6768 - val_loss: 0.6030\n",
      "Epoch 166/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7134 - loss: 0.5753 - val_accuracy: 0.6768 - val_loss: 0.6028\n",
      "Epoch 167/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7002 - loss: 0.5813 - val_accuracy: 0.6768 - val_loss: 0.6027\n",
      "Epoch 168/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7242 - loss: 0.5776 - val_accuracy: 0.6768 - val_loss: 0.6027\n",
      "Epoch 169/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7158 - loss: 0.5675 - val_accuracy: 0.6768 - val_loss: 0.6028\n",
      "Epoch 170/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7206 - loss: 0.5747 - val_accuracy: 0.6768 - val_loss: 0.6029\n",
      "Epoch 171/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.7086 - loss: 0.5754 - val_accuracy: 0.6768 - val_loss: 0.6025\n",
      "Epoch 172/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7182 - loss: 0.5639 - val_accuracy: 0.6768 - val_loss: 0.6021\n",
      "Epoch 173/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7230 - loss: 0.5747 - val_accuracy: 0.6768 - val_loss: 0.6016\n",
      "Epoch 174/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.7050 - loss: 0.5726 - val_accuracy: 0.6768 - val_loss: 0.6014\n",
      "Epoch 175/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.7266 - loss: 0.5697 - val_accuracy: 0.6768 - val_loss: 0.6008\n",
      "Epoch 176/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7122 - loss: 0.5774 - val_accuracy: 0.6768 - val_loss: 0.6004\n",
      "Epoch 177/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7134 - loss: 0.5777 - val_accuracy: 0.6768 - val_loss: 0.6002\n",
      "Epoch 178/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7194 - loss: 0.5632 - val_accuracy: 0.6768 - val_loss: 0.5998\n",
      "Epoch 179/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7230 - loss: 0.5711 - val_accuracy: 0.6768 - val_loss: 0.5993\n",
      "Epoch 180/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.7254 - loss: 0.5616 - val_accuracy: 0.6768 - val_loss: 0.5988\n",
      "Epoch 181/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7134 - loss: 0.5680 - val_accuracy: 0.6768 - val_loss: 0.5983\n",
      "Epoch 182/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7302 - loss: 0.5794 - val_accuracy: 0.6768 - val_loss: 0.5982\n",
      "Epoch 183/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7242 - loss: 0.5715 - val_accuracy: 0.6768 - val_loss: 0.5979\n",
      "Epoch 184/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.7206 - loss: 0.5636 - val_accuracy: 0.6768 - val_loss: 0.5976\n",
      "Epoch 185/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7254 - loss: 0.5683 - val_accuracy: 0.6768 - val_loss: 0.5972\n",
      "Epoch 186/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7266 - loss: 0.5709 - val_accuracy: 0.6768 - val_loss: 0.5968\n",
      "Epoch 187/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7158 - loss: 0.5645 - val_accuracy: 0.6768 - val_loss: 0.5963\n",
      "Epoch 188/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7098 - loss: 0.5742 - val_accuracy: 0.6768 - val_loss: 0.5958\n",
      "Epoch 189/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.7386 - loss: 0.5586 - val_accuracy: 0.6768 - val_loss: 0.5955\n",
      "Epoch 190/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7218 - loss: 0.5608 - val_accuracy: 0.6768 - val_loss: 0.5953\n",
      "Epoch 191/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7194 - loss: 0.5616 - val_accuracy: 0.6768 - val_loss: 0.5949\n",
      "Epoch 192/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7206 - loss: 0.5765 - val_accuracy: 0.6768 - val_loss: 0.5944\n",
      "Epoch 193/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.7326 - loss: 0.5537 - val_accuracy: 0.6768 - val_loss: 0.5938\n",
      "Epoch 194/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7122 - loss: 0.5619 - val_accuracy: 0.6768 - val_loss: 0.5927\n",
      "Epoch 195/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7314 - loss: 0.5600 - val_accuracy: 0.6768 - val_loss: 0.5919\n",
      "Epoch 196/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7062 - loss: 0.5676 - val_accuracy: 0.6768 - val_loss: 0.5911\n",
      "Epoch 197/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7290 - loss: 0.5727 - val_accuracy: 0.6768 - val_loss: 0.5908\n",
      "Epoch 198/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7158 - loss: 0.5669 - val_accuracy: 0.6768 - val_loss: 0.5906\n",
      "Epoch 199/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7278 - loss: 0.5638 - val_accuracy: 0.6768 - val_loss: 0.5905\n",
      "Epoch 200/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.7206 - loss: 0.5723 - val_accuracy: 0.6768 - val_loss: 0.5903\n",
      "Epoch 201/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7266 - loss: 0.5518 - val_accuracy: 0.6768 - val_loss: 0.5896\n",
      "Epoch 202/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7362 - loss: 0.5608 - val_accuracy: 0.6768 - val_loss: 0.5898\n",
      "Epoch 203/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.7290 - loss: 0.5633 - val_accuracy: 0.6768 - val_loss: 0.5894\n",
      "Epoch 204/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7362 - loss: 0.5605 - val_accuracy: 0.6768 - val_loss: 0.5891\n",
      "Epoch 205/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7398 - loss: 0.5652 - val_accuracy: 0.6768 - val_loss: 0.5896\n",
      "Epoch 206/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7290 - loss: 0.5631 - val_accuracy: 0.6768 - val_loss: 0.5904\n",
      "Epoch 207/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7266 - loss: 0.5650 - val_accuracy: 0.6768 - val_loss: 0.5914\n",
      "Epoch 208/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7218 - loss: 0.5681 - val_accuracy: 0.6768 - val_loss: 0.5919\n",
      "Epoch 209/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.7398 - loss: 0.5580 - val_accuracy: 0.6768 - val_loss: 0.5920\n",
      "Epoch 210/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7266 - loss: 0.5596 - val_accuracy: 0.6768 - val_loss: 0.5918\n",
      "Epoch 211/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.7278 - loss: 0.5592 - val_accuracy: 0.6768 - val_loss: 0.5917\n",
      "Epoch 212/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.7302 - loss: 0.5598 - val_accuracy: 0.6768 - val_loss: 0.5916\n",
      "Epoch 213/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7446 - loss: 0.5484 - val_accuracy: 0.6768 - val_loss: 0.5918\n",
      "Epoch 214/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7446 - loss: 0.5437 - val_accuracy: 0.6768 - val_loss: 0.5917\n",
      "Epoch 215/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.7314 - loss: 0.5627 - val_accuracy: 0.6768 - val_loss: 0.5913\n",
      "Epoch 216/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7398 - loss: 0.5516 - val_accuracy: 0.6768 - val_loss: 0.5911\n",
      "Epoch 217/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7278 - loss: 0.5631 - val_accuracy: 0.6768 - val_loss: 0.5908\n",
      "Epoch 218/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7170 - loss: 0.5524 - val_accuracy: 0.6768 - val_loss: 0.5901\n",
      "Epoch 219/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7374 - loss: 0.5562 - val_accuracy: 0.6768 - val_loss: 0.5892\n",
      "Epoch 220/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7434 - loss: 0.5554 - val_accuracy: 0.6768 - val_loss: 0.5884\n",
      "Epoch 221/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7362 - loss: 0.5573 - val_accuracy: 0.6818 - val_loss: 0.5879\n",
      "Epoch 222/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7290 - loss: 0.5494 - val_accuracy: 0.6818 - val_loss: 0.5874\n",
      "Epoch 223/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.7398 - loss: 0.5419 - val_accuracy: 0.6818 - val_loss: 0.5867\n",
      "Epoch 224/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7086 - loss: 0.5612 - val_accuracy: 0.6818 - val_loss: 0.5862\n",
      "Epoch 225/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7362 - loss: 0.5463 - val_accuracy: 0.6818 - val_loss: 0.5853\n",
      "Epoch 226/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7410 - loss: 0.5481 - val_accuracy: 0.6818 - val_loss: 0.5845\n",
      "Epoch 227/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7290 - loss: 0.5470 - val_accuracy: 0.6818 - val_loss: 0.5839\n",
      "Epoch 228/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7422 - loss: 0.5587 - val_accuracy: 0.6818 - val_loss: 0.5839\n",
      "Epoch 229/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7398 - loss: 0.5499 - val_accuracy: 0.6818 - val_loss: 0.5835\n",
      "Epoch 230/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7290 - loss: 0.5527 - val_accuracy: 0.6970 - val_loss: 0.5826\n",
      "Epoch 231/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7338 - loss: 0.5450 - val_accuracy: 0.7071 - val_loss: 0.5817\n",
      "Epoch 232/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7194 - loss: 0.5559 - val_accuracy: 0.7121 - val_loss: 0.5808\n",
      "Epoch 233/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7242 - loss: 0.5557 - val_accuracy: 0.7121 - val_loss: 0.5804\n",
      "Epoch 234/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7626 - loss: 0.5445 - val_accuracy: 0.7121 - val_loss: 0.5803\n",
      "Epoch 235/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7566 - loss: 0.5444 - val_accuracy: 0.7071 - val_loss: 0.5807\n",
      "Epoch 236/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7386 - loss: 0.5411 - val_accuracy: 0.7071 - val_loss: 0.5810\n",
      "Epoch 237/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7398 - loss: 0.5628 - val_accuracy: 0.7071 - val_loss: 0.5804\n",
      "Epoch 238/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.7386 - loss: 0.5525 - val_accuracy: 0.7222 - val_loss: 0.5804\n",
      "Epoch 239/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7470 - loss: 0.5468 - val_accuracy: 0.7475 - val_loss: 0.5805\n",
      "Epoch 240/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.7278 - loss: 0.5571 - val_accuracy: 0.7626 - val_loss: 0.5812\n",
      "Epoch 241/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7278 - loss: 0.5553 - val_accuracy: 0.7626 - val_loss: 0.5819\n",
      "Epoch 242/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7266 - loss: 0.5619 - val_accuracy: 0.7727 - val_loss: 0.5826\n",
      "Epoch 243/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7590 - loss: 0.5462 - val_accuracy: 0.7727 - val_loss: 0.5824\n",
      "Epoch 244/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.7386 - loss: 0.5460 - val_accuracy: 0.7727 - val_loss: 0.5816\n",
      "Epoch 245/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7458 - loss: 0.5596 - val_accuracy: 0.7727 - val_loss: 0.5807\n",
      "Epoch 246/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.7410 - loss: 0.5552 - val_accuracy: 0.7727 - val_loss: 0.5801\n",
      "Epoch 247/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7386 - loss: 0.5551 - val_accuracy: 0.7727 - val_loss: 0.5800\n",
      "Epoch 248/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7470 - loss: 0.5516 - val_accuracy: 0.7727 - val_loss: 0.5800\n",
      "Epoch 249/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.7578 - loss: 0.5402 - val_accuracy: 0.7727 - val_loss: 0.5797\n",
      "Epoch 250/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7518 - loss: 0.5311 - val_accuracy: 0.7727 - val_loss: 0.5791\n",
      "Epoch 251/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.7446 - loss: 0.5520 - val_accuracy: 0.7727 - val_loss: 0.5784\n",
      "Epoch 252/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.7482 - loss: 0.5456 - val_accuracy: 0.7727 - val_loss: 0.5774\n",
      "Epoch 253/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.7446 - loss: 0.5357 - val_accuracy: 0.7727 - val_loss: 0.5761\n",
      "Epoch 254/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.7362 - loss: 0.5591 - val_accuracy: 0.7727 - val_loss: 0.5753\n",
      "Epoch 255/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7362 - loss: 0.5459 - val_accuracy: 0.7727 - val_loss: 0.5743\n",
      "Epoch 256/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7530 - loss: 0.5511 - val_accuracy: 0.7727 - val_loss: 0.5735\n",
      "Epoch 257/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7470 - loss: 0.5436 - val_accuracy: 0.7727 - val_loss: 0.5731\n",
      "Epoch 258/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7398 - loss: 0.5490 - val_accuracy: 0.7677 - val_loss: 0.5734\n",
      "Epoch 259/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7554 - loss: 0.5422 - val_accuracy: 0.7677 - val_loss: 0.5740\n",
      "Epoch 260/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7422 - loss: 0.5484 - val_accuracy: 0.7677 - val_loss: 0.5745\n",
      "Epoch 261/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7470 - loss: 0.5269 - val_accuracy: 0.7727 - val_loss: 0.5741\n",
      "Epoch 262/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7482 - loss: 0.5407 - val_accuracy: 0.7727 - val_loss: 0.5734\n",
      "Epoch 263/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7482 - loss: 0.5433 - val_accuracy: 0.7778 - val_loss: 0.5731\n",
      "Epoch 264/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7458 - loss: 0.5308 - val_accuracy: 0.7778 - val_loss: 0.5729\n",
      "Epoch 265/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7458 - loss: 0.5411 - val_accuracy: 0.7778 - val_loss: 0.5727\n",
      "Epoch 266/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7542 - loss: 0.5289 - val_accuracy: 0.7828 - val_loss: 0.5726\n",
      "Epoch 267/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7350 - loss: 0.5403 - val_accuracy: 0.7828 - val_loss: 0.5724\n",
      "Epoch 268/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7374 - loss: 0.5419 - val_accuracy: 0.7828 - val_loss: 0.5720\n",
      "Epoch 269/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7494 - loss: 0.5449 - val_accuracy: 0.7828 - val_loss: 0.5719\n",
      "Epoch 270/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7458 - loss: 0.5424 - val_accuracy: 0.7828 - val_loss: 0.5724\n",
      "Epoch 271/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.7350 - loss: 0.5508 - val_accuracy: 0.7828 - val_loss: 0.5733\n",
      "Epoch 272/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.7566 - loss: 0.5379 - val_accuracy: 0.7828 - val_loss: 0.5732\n",
      "Epoch 273/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.7410 - loss: 0.5371 - val_accuracy: 0.7828 - val_loss: 0.5725\n",
      "Epoch 274/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7302 - loss: 0.5316 - val_accuracy: 0.7828 - val_loss: 0.5712\n",
      "Epoch 275/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7338 - loss: 0.5454 - val_accuracy: 0.7828 - val_loss: 0.5700\n",
      "Epoch 276/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7398 - loss: 0.5470 - val_accuracy: 0.7828 - val_loss: 0.5697\n",
      "Epoch 277/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7566 - loss: 0.5269 - val_accuracy: 0.7828 - val_loss: 0.5699\n",
      "Epoch 278/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7446 - loss: 0.5415 - val_accuracy: 0.7828 - val_loss: 0.5703\n",
      "Epoch 279/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7482 - loss: 0.5350 - val_accuracy: 0.7828 - val_loss: 0.5702\n",
      "Epoch 280/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.7410 - loss: 0.5402 - val_accuracy: 0.7828 - val_loss: 0.5703\n",
      "Epoch 281/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7350 - loss: 0.5369 - val_accuracy: 0.7828 - val_loss: 0.5704\n",
      "Epoch 282/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.7602 - loss: 0.5338 - val_accuracy: 0.7828 - val_loss: 0.5703\n",
      "Epoch 283/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.7422 - loss: 0.5313 - val_accuracy: 0.7828 - val_loss: 0.5695\n",
      "Epoch 284/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7590 - loss: 0.5371 - val_accuracy: 0.7828 - val_loss: 0.5686\n",
      "Epoch 285/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7434 - loss: 0.5308 - val_accuracy: 0.7828 - val_loss: 0.5674\n",
      "Epoch 286/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7386 - loss: 0.5274 - val_accuracy: 0.7778 - val_loss: 0.5663\n",
      "Epoch 287/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7542 - loss: 0.5384 - val_accuracy: 0.7778 - val_loss: 0.5654\n",
      "Epoch 288/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7494 - loss: 0.5345 - val_accuracy: 0.7828 - val_loss: 0.5641\n",
      "Epoch 289/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7674 - loss: 0.5302 - val_accuracy: 0.7828 - val_loss: 0.5624\n",
      "Epoch 290/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7554 - loss: 0.5171 - val_accuracy: 0.7828 - val_loss: 0.5609\n",
      "Epoch 291/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.7626 - loss: 0.5230 - val_accuracy: 0.7828 - val_loss: 0.5599\n",
      "Epoch 292/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7542 - loss: 0.5291 - val_accuracy: 0.7828 - val_loss: 0.5597\n",
      "Epoch 293/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7662 - loss: 0.5288 - val_accuracy: 0.7828 - val_loss: 0.5601\n",
      "Epoch 294/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7494 - loss: 0.5361 - val_accuracy: 0.7828 - val_loss: 0.5610\n",
      "Epoch 295/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7542 - loss: 0.5307 - val_accuracy: 0.7828 - val_loss: 0.5616\n",
      "Epoch 296/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.7554 - loss: 0.5188 - val_accuracy: 0.7828 - val_loss: 0.5613\n",
      "Epoch 297/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.7542 - loss: 0.5237 - val_accuracy: 0.7828 - val_loss: 0.5602\n",
      "Epoch 298/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.7566 - loss: 0.5052 - val_accuracy: 0.7828 - val_loss: 0.5577\n",
      "Epoch 299/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.7734 - loss: 0.5145 - val_accuracy: 0.7828 - val_loss: 0.5546\n",
      "Epoch 300/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.7554 - loss: 0.5197 - val_accuracy: 0.7828 - val_loss: 0.5532\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step\n",
      "acc=0.7828282828282829, time=35.320555299986154\n"
     ]
    }
   ],
   "source": [
    "cnn_model = make_model(x_ae_train, x_t_train,\n",
    "    n_linear_layers=8, linear_size=32, n_filters=8, spatial_dropout_k = 0.125, dropout_k = .00, kernel_size=3,\n",
    "    n_conv_layers=1, n_conv_layers_pool_1=3, c_reg=0.000, l_reg=0.000, pool=2\n",
    ")\n",
    "\n",
    "start = perf_counter()\n",
    "\n",
    "history = cnn_model.fit(\n",
    "    [x_ae_train, x_t_train],\n",
    "    yb_train,\n",
    "    epochs=300,\n",
    "    validation_data=([x_ae_val, x_t_val], yb_val),\n",
    "    batch_size=1000,\n",
    "    # callbacks=[ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=30, min_lr=1e-5)]\n",
    ")\n",
    "\n",
    "a = ((cnn_model.predict([x_ae_val, x_t_val]).flatten() > .5) == yb_val).mean()\n",
    "\n",
    "print(f'acc={a}, time={perf_counter() - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6a25dac-1d82-4579-bb31-a5852b07da18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6642685851318945"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78634b08-8ed3-4da3-88ed-a6bd14c96509",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7828282828282829, 0.6767676767676768)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((cnn_model.predict([x_ae_val, x_t_val]) > .5).flatten() == yb_val).mean(), (yb_val).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb90aad0-f9f0-4d10-8de6-9142ef561eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'CNN Accuracy over Training')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.gca()\n",
    "\n",
    "ax.plot(history.history['accuracy'], label='Training')\n",
    "ax.plot(\n",
    "    np.convolve(np.array(history.history['val_accuracy']), np.ones(10)/10, mode='valid'),\n",
    "    label='Validation (Running Mean)'\n",
    ")\n",
    "ax.legend()\n",
    "ax.set_xlabel('# Epochs')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_ylim((0, 1))\n",
    "ax.set_title('CNN Accuracy over Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "165c497f-e419-4760-9645-24bfa8a9e007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    }
   ],
   "source": [
    "y_pred = cnn_model.predict([x_ae_val, x_t_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b27178e-aa3f-494e-b44a-aaf4d9ca02c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.10606060606060606, 0.0, 0.6767676767676768, 0.21717171717171718)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_i = (y_pred > .5).flatten()\n",
    "tn = ((y_pred_i == 0) & (yb_val == 0)).mean()\n",
    "fn = ((y_pred_i == 0) & (yb_val == 1)).mean()\n",
    "tp = ((y_pred_i == 1) & (yb_val == 1)).mean()\n",
    "fp = ((y_pred_i == 1) & (yb_val == 0)).mean()\n",
    "\n",
    "tn, fn, tp, fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a9cbd67-d242-4dcd-b772-795851713afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7570621468926553, 0.328125, 0.0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp / (tp + fp), tn/(tn + fp), fn/(tn+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00882bd1-7480-4221-b0c0-dc726a494a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_pred = np.vstack((x_t_val.flatten(), (y_pred.flatten()>.5) == yb_val)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c422668-9b63-4b22-9443-b9519e37844e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 1.0\n",
      "1: 0.7444444444444445\n",
      "2: 0.765625\n",
      "3: 0.782608695652174\n"
     ]
    }
   ],
   "source": [
    "for t in range(4):\n",
    "    print(f'{t}: {t_pred[t_pred[:,0]==t][:,1].mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3a3860-962a-4f1a-8142-bba7e8682739",
   "metadata": {},
   "source": [
    "### Risky Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "168fb501-eee5-4515-bc4b-903d03ce6d62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 32, 32)\n",
      "(None, 16, 4)\n",
      "(None, 16, 4)\n",
      "(None, 8, 4)\n",
      "(None, 8, 4)\n",
      "(None, 4, 4)\n",
      "(None, 32, 32)\n",
      "(None, 16, 4)\n",
      "(None, 16, 4)\n",
      "(None, 8, 4)\n",
      "(None, 8, 4)\n",
      "(None, 4, 4)\n",
      "(None, 32, 32)\n",
      "(None, 16, 4)\n",
      "(None, 16, 4)\n",
      "(None, 8, 4)\n",
      "(None, 8, 4)\n",
      "(None, 4, 4)\n",
      "(None, 32, 32)\n",
      "(None, 16, 4)\n",
      "(None, 16, 4)\n",
      "(None, 8, 4)\n",
      "(None, 8, 4)\n",
      "(None, 4, 4)\n",
      "Epoch 1/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.3487 - loss: 1.6592 - val_accuracy: 0.3232 - val_loss: 0.9727\n",
      "Epoch 2/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3607 - loss: 1.5472 - val_accuracy: 0.3232 - val_loss: 0.9657\n",
      "Epoch 3/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3301 - loss: 1.4492 - val_accuracy: 0.3232 - val_loss: 0.9544\n",
      "Epoch 4/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3490 - loss: 1.4114 - val_accuracy: 0.3232 - val_loss: 0.9149\n",
      "Epoch 5/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3443 - loss: 1.3769 - val_accuracy: 0.3232 - val_loss: 0.8897\n",
      "Epoch 6/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3410 - loss: 1.3068 - val_accuracy: 0.3232 - val_loss: 0.8798\n",
      "Epoch 7/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3514 - loss: 1.3348 - val_accuracy: 0.3232 - val_loss: 0.9147\n",
      "Epoch 8/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3409 - loss: 1.2756 - val_accuracy: 0.3232 - val_loss: 0.8765\n",
      "Epoch 9/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3476 - loss: 1.2991 - val_accuracy: 0.3232 - val_loss: 0.9361\n",
      "Epoch 10/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3192 - loss: 1.2476 - val_accuracy: 0.3232 - val_loss: 0.8806\n",
      "Epoch 11/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3455 - loss: 1.2514 - val_accuracy: 0.3232 - val_loss: 0.9502\n",
      "Epoch 12/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3362 - loss: 1.2386 - val_accuracy: 0.3232 - val_loss: 0.8643\n",
      "Epoch 13/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3390 - loss: 1.2269 - val_accuracy: 0.3232 - val_loss: 0.8654\n",
      "Epoch 14/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3487 - loss: 1.2373 - val_accuracy: 0.3232 - val_loss: 0.9097\n",
      "Epoch 15/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3305 - loss: 1.2160 - val_accuracy: 0.3232 - val_loss: 0.7995\n",
      "Epoch 16/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.3456 - loss: 1.2181 - val_accuracy: 0.3232 - val_loss: 0.8481\n",
      "Epoch 17/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3145 - loss: 1.1301 - val_accuracy: 0.3232 - val_loss: 0.9816\n",
      "Epoch 18/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3098 - loss: 1.1764 - val_accuracy: 0.3232 - val_loss: 1.0101\n",
      "Epoch 19/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3154 - loss: 1.2366 - val_accuracy: 0.3232 - val_loss: 0.8345\n",
      "Epoch 20/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3572 - loss: 1.1975 - val_accuracy: 0.3232 - val_loss: 0.8479\n",
      "Epoch 21/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3415 - loss: 1.1955 - val_accuracy: 0.3232 - val_loss: 1.0237\n",
      "Epoch 22/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3578 - loss: 1.2268 - val_accuracy: 0.3485 - val_loss: 0.8006\n",
      "Epoch 23/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3613 - loss: 1.1371 - val_accuracy: 0.3283 - val_loss: 0.8067\n",
      "Epoch 24/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3579 - loss: 1.2062 - val_accuracy: 0.3232 - val_loss: 0.8188\n",
      "Epoch 25/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3614 - loss: 1.1697 - val_accuracy: 0.3687 - val_loss: 0.7977\n",
      "Epoch 26/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3931 - loss: 1.1482 - val_accuracy: 0.3232 - val_loss: 1.0133\n",
      "Epoch 27/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3643 - loss: 1.1580 - val_accuracy: 0.3535 - val_loss: 0.8417\n",
      "Epoch 28/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3742 - loss: 1.1800 - val_accuracy: 0.5000 - val_loss: 0.8026\n",
      "Epoch 29/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4590 - loss: 1.1766 - val_accuracy: 0.4141 - val_loss: 0.8530\n",
      "Epoch 30/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4787 - loss: 1.1640 - val_accuracy: 0.5000 - val_loss: 0.8289\n",
      "Epoch 31/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5046 - loss: 1.1876 - val_accuracy: 0.4394 - val_loss: 0.8529\n",
      "Epoch 32/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5263 - loss: 1.1876 - val_accuracy: 0.5101 - val_loss: 0.8463\n",
      "Epoch 33/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4901 - loss: 1.1484 - val_accuracy: 0.3990 - val_loss: 0.9383\n",
      "Epoch 34/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4894 - loss: 1.1892 - val_accuracy: 0.4343 - val_loss: 0.8774\n",
      "Epoch 35/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4908 - loss: 1.1315 - val_accuracy: 0.4141 - val_loss: 0.9649\n",
      "Epoch 36/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4844 - loss: 1.1667 - val_accuracy: 0.5909 - val_loss: 0.7671\n",
      "Epoch 37/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4735 - loss: 1.1794 - val_accuracy: 0.5152 - val_loss: 0.8103\n",
      "Epoch 38/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5530 - loss: 1.1252 - val_accuracy: 0.3485 - val_loss: 0.9515\n",
      "Epoch 39/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4645 - loss: 1.1971 - val_accuracy: 0.3889 - val_loss: 0.9169\n",
      "Epoch 40/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5403 - loss: 1.1111 - val_accuracy: 0.4949 - val_loss: 0.8377\n",
      "Epoch 41/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5177 - loss: 1.1694 - val_accuracy: 0.5152 - val_loss: 0.8323\n",
      "Epoch 42/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5219 - loss: 1.1733 - val_accuracy: 0.6566 - val_loss: 0.7640\n",
      "Epoch 43/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5321 - loss: 1.1277 - val_accuracy: 0.4444 - val_loss: 0.8754\n",
      "Epoch 44/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4801 - loss: 1.1482 - val_accuracy: 0.3485 - val_loss: 0.9409\n",
      "Epoch 45/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5198 - loss: 1.0949 - val_accuracy: 0.5707 - val_loss: 0.7797\n",
      "Epoch 46/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4813 - loss: 1.1715 - val_accuracy: 0.4646 - val_loss: 0.8337\n",
      "Epoch 47/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4846 - loss: 1.1834 - val_accuracy: 0.5253 - val_loss: 0.8270\n",
      "Epoch 48/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5390 - loss: 1.1157 - val_accuracy: 0.6111 - val_loss: 0.7665\n",
      "Epoch 49/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5474 - loss: 1.1081 - val_accuracy: 0.5859 - val_loss: 0.7899\n",
      "Epoch 50/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5324 - loss: 1.1540 - val_accuracy: 0.5505 - val_loss: 0.8032\n",
      "Epoch 51/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5467 - loss: 1.1309 - val_accuracy: 0.4040 - val_loss: 0.9172\n",
      "Epoch 52/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5384 - loss: 1.0872 - val_accuracy: 0.4343 - val_loss: 0.8658\n",
      "Epoch 53/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5488 - loss: 1.1189 - val_accuracy: 0.3333 - val_loss: 0.9921\n",
      "Epoch 54/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4961 - loss: 1.1544 - val_accuracy: 0.6616 - val_loss: 0.7483\n",
      "Epoch 55/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5729 - loss: 1.1243 - val_accuracy: 0.5707 - val_loss: 0.7986\n",
      "Epoch 56/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5330 - loss: 1.1271 - val_accuracy: 0.3687 - val_loss: 1.0399\n",
      "Epoch 57/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5644 - loss: 1.1288 - val_accuracy: 0.5202 - val_loss: 0.8344\n",
      "Epoch 58/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5090 - loss: 1.1221 - val_accuracy: 0.5404 - val_loss: 0.8326\n",
      "Epoch 59/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5205 - loss: 1.1425 - val_accuracy: 0.4949 - val_loss: 0.8328\n",
      "Epoch 60/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5258 - loss: 1.1203 - val_accuracy: 0.5404 - val_loss: 0.8356\n",
      "Epoch 61/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5733 - loss: 1.1509 - val_accuracy: 0.4545 - val_loss: 1.0043\n",
      "Epoch 62/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5737 - loss: 1.1290 - val_accuracy: 0.3737 - val_loss: 1.0093\n",
      "Epoch 63/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5471 - loss: 1.1169 - val_accuracy: 0.6313 - val_loss: 0.7908\n",
      "Epoch 64/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5936 - loss: 1.0760 - val_accuracy: 0.4596 - val_loss: 0.9329\n",
      "Epoch 65/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5564 - loss: 1.1033 - val_accuracy: 0.3939 - val_loss: 0.9167\n",
      "Epoch 66/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5287 - loss: 1.1372 - val_accuracy: 0.5152 - val_loss: 0.8163\n",
      "Epoch 67/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5821 - loss: 1.1038 - val_accuracy: 0.4293 - val_loss: 0.8882\n",
      "Epoch 68/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5715 - loss: 1.0694 - val_accuracy: 0.3889 - val_loss: 0.9883\n",
      "Epoch 69/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5576 - loss: 1.1249 - val_accuracy: 0.4596 - val_loss: 1.0051\n",
      "Epoch 70/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5689 - loss: 1.0750 - val_accuracy: 0.5556 - val_loss: 0.8094\n",
      "Epoch 71/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5407 - loss: 1.1288 - val_accuracy: 0.6263 - val_loss: 0.8036\n",
      "Epoch 72/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5845 - loss: 1.1029 - val_accuracy: 0.3990 - val_loss: 0.9879\n",
      "Epoch 73/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6042 - loss: 1.1197 - val_accuracy: 0.4192 - val_loss: 0.9674\n",
      "Epoch 74/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5482 - loss: 1.0942 - val_accuracy: 0.3737 - val_loss: 1.0658\n",
      "Epoch 75/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5402 - loss: 1.0861 - val_accuracy: 0.5354 - val_loss: 0.8785\n",
      "Epoch 76/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5929 - loss: 1.0879 - val_accuracy: 0.6566 - val_loss: 0.7543\n",
      "Epoch 77/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6059 - loss: 1.1272 - val_accuracy: 0.5758 - val_loss: 0.7824\n",
      "Epoch 78/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5954 - loss: 1.1504 - val_accuracy: 0.4343 - val_loss: 0.9320\n",
      "Epoch 79/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6240 - loss: 1.1049 - val_accuracy: 0.5808 - val_loss: 0.8225\n",
      "Epoch 80/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5955 - loss: 1.0793 - val_accuracy: 0.5808 - val_loss: 0.8261\n",
      "Epoch 81/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5944 - loss: 1.1113 - val_accuracy: 0.7475 - val_loss: 0.7135\n",
      "Epoch 82/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5863 - loss: 1.1430 - val_accuracy: 0.6515 - val_loss: 0.7571\n",
      "Epoch 83/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6311 - loss: 1.0923 - val_accuracy: 0.5101 - val_loss: 0.8298\n",
      "Epoch 84/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6541 - loss: 1.0541 - val_accuracy: 0.3737 - val_loss: 1.0947\n",
      "Epoch 85/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6063 - loss: 1.1165 - val_accuracy: 0.4343 - val_loss: 0.9396\n",
      "Epoch 86/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6524 - loss: 1.0628 - val_accuracy: 0.6212 - val_loss: 0.7771\n",
      "Epoch 87/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6132 - loss: 1.0765 - val_accuracy: 0.5960 - val_loss: 0.8093\n",
      "Epoch 88/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6078 - loss: 1.0898 - val_accuracy: 0.7374 - val_loss: 0.7216\n",
      "Epoch 89/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6380 - loss: 1.0950 - val_accuracy: 0.6616 - val_loss: 0.7361\n",
      "Epoch 90/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6495 - loss: 1.0749 - val_accuracy: 0.6111 - val_loss: 0.7881\n",
      "Epoch 91/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5633 - loss: 1.1663 - val_accuracy: 0.6970 - val_loss: 0.7487\n",
      "Epoch 92/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6357 - loss: 1.0717 - val_accuracy: 0.4040 - val_loss: 1.0512\n",
      "Epoch 93/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6523 - loss: 1.0675 - val_accuracy: 0.6061 - val_loss: 0.7946\n",
      "Epoch 94/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6299 - loss: 1.0386 - val_accuracy: 0.6919 - val_loss: 0.7339\n",
      "Epoch 95/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6480 - loss: 1.0948 - val_accuracy: 0.5455 - val_loss: 0.8807\n",
      "Epoch 96/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6602 - loss: 1.0596 - val_accuracy: 0.6212 - val_loss: 0.8045\n",
      "Epoch 97/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6342 - loss: 1.0629 - val_accuracy: 0.5152 - val_loss: 0.9288\n",
      "Epoch 98/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6161 - loss: 1.0614 - val_accuracy: 0.4444 - val_loss: 1.0717\n",
      "Epoch 99/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6223 - loss: 1.1181 - val_accuracy: 0.6414 - val_loss: 0.7644\n",
      "Epoch 100/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6413 - loss: 1.0773 - val_accuracy: 0.5960 - val_loss: 0.8060\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "acc=0.5959595959595959, positive_rate=0.5597014925373135, negative_rate=0.671875, time=67.34172320005018\n",
      "Epoch 1/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.5122 - loss: 4.4064 - val_accuracy: 0.3232 - val_loss: 0.9839\n",
      "Epoch 2/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3223 - loss: 3.6128 - val_accuracy: 0.3232 - val_loss: 1.1320\n",
      "Epoch 3/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3550 - loss: 2.4202 - val_accuracy: 0.3232 - val_loss: 1.2174\n",
      "Epoch 4/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3199 - loss: 2.3197 - val_accuracy: 0.3232 - val_loss: 1.3321\n",
      "Epoch 5/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3423 - loss: 2.2997 - val_accuracy: 0.3232 - val_loss: 1.2925\n",
      "Epoch 6/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3185 - loss: 2.2574 - val_accuracy: 0.3232 - val_loss: 1.4981\n",
      "Epoch 7/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3135 - loss: 2.2162 - val_accuracy: 0.3232 - val_loss: 1.3675\n",
      "Epoch 8/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3343 - loss: 2.1371 - val_accuracy: 0.3232 - val_loss: 1.3787\n",
      "Epoch 9/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3390 - loss: 2.1163 - val_accuracy: 0.3232 - val_loss: 1.5148\n",
      "Epoch 10/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3358 - loss: 2.0392 - val_accuracy: 0.3232 - val_loss: 1.3775\n",
      "Epoch 11/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3567 - loss: 2.1634 - val_accuracy: 0.3232 - val_loss: 1.4821\n",
      "Epoch 12/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3406 - loss: 2.0345 - val_accuracy: 0.3232 - val_loss: 1.3079\n",
      "Epoch 13/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3143 - loss: 2.0093 - val_accuracy: 0.3232 - val_loss: 1.5323\n",
      "Epoch 14/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3546 - loss: 2.0033 - val_accuracy: 0.3232 - val_loss: 1.6042\n",
      "Epoch 15/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3465 - loss: 1.9662 - val_accuracy: 0.3232 - val_loss: 1.2315\n",
      "Epoch 16/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3518 - loss: 2.0942 - val_accuracy: 0.3232 - val_loss: 1.2947\n",
      "Epoch 17/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3314 - loss: 1.9241 - val_accuracy: 0.3232 - val_loss: 1.5742\n",
      "Epoch 18/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3360 - loss: 1.9538 - val_accuracy: 0.3232 - val_loss: 1.2383\n",
      "Epoch 19/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3439 - loss: 1.9560 - val_accuracy: 0.3232 - val_loss: 1.3929\n",
      "Epoch 20/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3492 - loss: 1.9235 - val_accuracy: 0.3232 - val_loss: 1.3502\n",
      "Epoch 21/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3309 - loss: 1.9885 - val_accuracy: 0.3232 - val_loss: 1.3092\n",
      "Epoch 22/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3234 - loss: 2.0128 - val_accuracy: 0.3232 - val_loss: 1.3422\n",
      "Epoch 23/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3379 - loss: 1.9776 - val_accuracy: 0.3232 - val_loss: 1.5987\n",
      "Epoch 24/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3231 - loss: 1.8690 - val_accuracy: 0.3232 - val_loss: 1.3854\n",
      "Epoch 25/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3317 - loss: 1.9001 - val_accuracy: 0.3232 - val_loss: 1.3367\n",
      "Epoch 26/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3389 - loss: 1.8562 - val_accuracy: 0.3232 - val_loss: 1.3747\n",
      "Epoch 27/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3562 - loss: 1.9399 - val_accuracy: 0.3232 - val_loss: 1.5482\n",
      "Epoch 28/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3198 - loss: 1.9648 - val_accuracy: 0.3232 - val_loss: 1.5232\n",
      "Epoch 29/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3306 - loss: 1.9506 - val_accuracy: 0.3232 - val_loss: 1.4533\n",
      "Epoch 30/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3145 - loss: 1.8395 - val_accuracy: 0.3232 - val_loss: 1.3587\n",
      "Epoch 31/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3173 - loss: 1.8675 - val_accuracy: 0.3434 - val_loss: 1.3592\n",
      "Epoch 32/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3758 - loss: 1.8340 - val_accuracy: 0.3636 - val_loss: 1.6717\n",
      "Epoch 33/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4058 - loss: 1.8594 - val_accuracy: 0.3687 - val_loss: 1.4871\n",
      "Epoch 34/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4102 - loss: 1.8473 - val_accuracy: 0.4293 - val_loss: 1.2690\n",
      "Epoch 35/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4165 - loss: 1.9073 - val_accuracy: 0.4192 - val_loss: 1.3394\n",
      "Epoch 36/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4414 - loss: 1.8460 - val_accuracy: 0.5152 - val_loss: 1.0244\n",
      "Epoch 37/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4501 - loss: 1.9099 - val_accuracy: 0.3737 - val_loss: 1.3781\n",
      "Epoch 38/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4552 - loss: 1.9034 - val_accuracy: 0.3889 - val_loss: 1.4340\n",
      "Epoch 39/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4314 - loss: 1.8714 - val_accuracy: 0.4141 - val_loss: 1.3958\n",
      "Epoch 40/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4601 - loss: 1.8198 - val_accuracy: 0.3788 - val_loss: 1.6283\n",
      "Epoch 41/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4154 - loss: 1.8812 - val_accuracy: 0.3687 - val_loss: 1.6358\n",
      "Epoch 42/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4655 - loss: 1.7207 - val_accuracy: 0.3535 - val_loss: 1.6507\n",
      "Epoch 43/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4297 - loss: 1.8166 - val_accuracy: 0.4697 - val_loss: 1.1754\n",
      "Epoch 44/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4401 - loss: 1.8115 - val_accuracy: 0.4697 - val_loss: 1.1660\n",
      "Epoch 45/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4682 - loss: 1.8524 - val_accuracy: 0.4444 - val_loss: 1.2498\n",
      "Epoch 46/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4336 - loss: 1.8262 - val_accuracy: 0.4192 - val_loss: 1.4337\n",
      "Epoch 47/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4448 - loss: 1.7655 - val_accuracy: 0.4495 - val_loss: 1.2389\n",
      "Epoch 48/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4537 - loss: 1.8250 - val_accuracy: 0.4545 - val_loss: 1.2998\n",
      "Epoch 49/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4831 - loss: 1.7108 - val_accuracy: 0.3586 - val_loss: 1.8749\n",
      "Epoch 50/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4766 - loss: 1.8233 - val_accuracy: 0.5202 - val_loss: 1.0590\n",
      "Epoch 51/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4966 - loss: 1.8610 - val_accuracy: 0.4596 - val_loss: 1.3322\n",
      "Epoch 52/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4672 - loss: 1.8173 - val_accuracy: 0.4192 - val_loss: 1.4027\n",
      "Epoch 53/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4818 - loss: 1.7378 - val_accuracy: 0.3990 - val_loss: 1.5650\n",
      "Epoch 54/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4327 - loss: 1.8109 - val_accuracy: 0.4091 - val_loss: 1.3726\n",
      "Epoch 55/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4385 - loss: 1.7179 - val_accuracy: 0.4343 - val_loss: 1.3947\n",
      "Epoch 56/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4689 - loss: 1.8094 - val_accuracy: 0.4545 - val_loss: 1.2399\n",
      "Epoch 57/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4793 - loss: 1.8534 - val_accuracy: 0.4343 - val_loss: 1.4130\n",
      "Epoch 58/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4777 - loss: 1.7960 - val_accuracy: 0.4242 - val_loss: 1.2998\n",
      "Epoch 59/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4819 - loss: 1.8202 - val_accuracy: 0.3990 - val_loss: 1.4132\n",
      "Epoch 60/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4775 - loss: 1.7588 - val_accuracy: 0.3939 - val_loss: 1.5669\n",
      "Epoch 61/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4745 - loss: 1.7598 - val_accuracy: 0.4394 - val_loss: 1.3443\n",
      "Epoch 62/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4511 - loss: 1.8411 - val_accuracy: 0.4040 - val_loss: 1.4733\n",
      "Epoch 63/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4390 - loss: 1.7478 - val_accuracy: 0.4192 - val_loss: 1.4087\n",
      "Epoch 64/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4637 - loss: 1.8035 - val_accuracy: 0.4949 - val_loss: 1.1280\n",
      "Epoch 65/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5010 - loss: 1.8107 - val_accuracy: 0.4091 - val_loss: 1.4520\n",
      "Epoch 66/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4943 - loss: 1.7704 - val_accuracy: 0.4343 - val_loss: 1.4092\n",
      "Epoch 67/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4777 - loss: 1.7731 - val_accuracy: 0.4545 - val_loss: 1.2847\n",
      "Epoch 68/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4690 - loss: 1.7910 - val_accuracy: 0.4242 - val_loss: 1.4290\n",
      "Epoch 69/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5020 - loss: 1.7037 - val_accuracy: 0.3990 - val_loss: 1.7638\n",
      "Epoch 70/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4743 - loss: 1.7832 - val_accuracy: 0.4444 - val_loss: 1.2216\n",
      "Epoch 71/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5254 - loss: 1.7011 - val_accuracy: 0.3838 - val_loss: 1.6013\n",
      "Epoch 72/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4586 - loss: 1.7172 - val_accuracy: 0.4293 - val_loss: 1.4867\n",
      "Epoch 73/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4746 - loss: 1.7200 - val_accuracy: 0.4596 - val_loss: 1.3052\n",
      "Epoch 74/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5032 - loss: 1.6734 - val_accuracy: 0.5909 - val_loss: 0.9155\n",
      "Epoch 75/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4796 - loss: 1.8389 - val_accuracy: 0.4596 - val_loss: 1.2388\n",
      "Epoch 76/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5318 - loss: 1.6986 - val_accuracy: 0.4192 - val_loss: 1.4939\n",
      "Epoch 77/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4958 - loss: 1.7061 - val_accuracy: 0.4394 - val_loss: 1.4253\n",
      "Epoch 78/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5102 - loss: 1.6937 - val_accuracy: 0.4293 - val_loss: 1.2961\n",
      "Epoch 79/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5103 - loss: 1.7499 - val_accuracy: 0.4040 - val_loss: 1.5533\n",
      "Epoch 80/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4856 - loss: 1.7954 - val_accuracy: 0.4899 - val_loss: 1.2187\n",
      "Epoch 81/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5036 - loss: 1.7843 - val_accuracy: 0.4192 - val_loss: 1.4478\n",
      "Epoch 82/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4525 - loss: 1.8040 - val_accuracy: 0.4242 - val_loss: 1.4682\n",
      "Epoch 83/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4474 - loss: 1.7860 - val_accuracy: 0.4141 - val_loss: 1.3874\n",
      "Epoch 84/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5348 - loss: 1.6581 - val_accuracy: 0.4293 - val_loss: 1.5589\n",
      "Epoch 85/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5148 - loss: 1.6408 - val_accuracy: 0.4091 - val_loss: 1.5357\n",
      "Epoch 86/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5107 - loss: 1.7094 - val_accuracy: 0.4646 - val_loss: 1.2070\n",
      "Epoch 87/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5125 - loss: 1.6761 - val_accuracy: 0.4545 - val_loss: 1.3919\n",
      "Epoch 88/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5109 - loss: 1.6476 - val_accuracy: 0.5000 - val_loss: 1.1476\n",
      "Epoch 89/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4984 - loss: 1.6768 - val_accuracy: 0.4242 - val_loss: 1.3780\n",
      "Epoch 90/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4664 - loss: 1.6651 - val_accuracy: 0.4141 - val_loss: 1.6571\n",
      "Epoch 91/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5232 - loss: 1.6503 - val_accuracy: 0.4747 - val_loss: 1.2224\n",
      "Epoch 92/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4856 - loss: 1.6828 - val_accuracy: 0.3990 - val_loss: 1.6240\n",
      "Epoch 93/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5150 - loss: 1.6693 - val_accuracy: 0.4596 - val_loss: 1.2818\n",
      "Epoch 94/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5105 - loss: 1.7641 - val_accuracy: 0.3990 - val_loss: 1.5201\n",
      "Epoch 95/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4667 - loss: 1.7304 - val_accuracy: 0.4495 - val_loss: 1.2888\n",
      "Epoch 96/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5497 - loss: 1.6278 - val_accuracy: 0.4141 - val_loss: 1.4831\n",
      "Epoch 97/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5184 - loss: 1.7283 - val_accuracy: 0.4747 - val_loss: 1.2187\n",
      "Epoch 98/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5350 - loss: 1.6598 - val_accuracy: 0.4495 - val_loss: 1.2979\n",
      "Epoch 99/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4977 - loss: 1.6534 - val_accuracy: 0.4495 - val_loss: 1.3685\n",
      "Epoch 100/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5333 - loss: 1.7096 - val_accuracy: 0.3939 - val_loss: 1.6787\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "acc=0.3939393939393939, positive_rate=0.14179104477611942, negative_rate=0.921875, time=123.24790800001938\n",
      "Epoch 1/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.3548 - loss: 13.9733 - val_accuracy: 0.3232 - val_loss: 1.2269\n",
      "Epoch 2/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3535 - loss: 4.9697 - val_accuracy: 0.3232 - val_loss: 1.6337\n",
      "Epoch 3/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3314 - loss: 3.3557 - val_accuracy: 0.3232 - val_loss: 1.7817\n",
      "Epoch 4/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3066 - loss: 3.3465 - val_accuracy: 0.3232 - val_loss: 1.8841\n",
      "Epoch 5/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2987 - loss: 3.2990 - val_accuracy: 0.3232 - val_loss: 2.0324\n",
      "Epoch 6/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3142 - loss: 3.2266 - val_accuracy: 0.3232 - val_loss: 2.4520\n",
      "Epoch 7/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3528 - loss: 3.1298 - val_accuracy: 0.3232 - val_loss: 2.2813\n",
      "Epoch 8/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3378 - loss: 3.1544 - val_accuracy: 0.3232 - val_loss: 2.3778\n",
      "Epoch 9/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3363 - loss: 3.0976 - val_accuracy: 0.3232 - val_loss: 2.1860\n",
      "Epoch 10/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3055 - loss: 3.2301 - val_accuracy: 0.3232 - val_loss: 2.5519\n",
      "Epoch 11/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3339 - loss: 3.0515 - val_accuracy: 0.3232 - val_loss: 2.3155\n",
      "Epoch 12/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3396 - loss: 2.9891 - val_accuracy: 0.3232 - val_loss: 2.5231\n",
      "Epoch 13/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3399 - loss: 2.9116 - val_accuracy: 0.3232 - val_loss: 2.7716\n",
      "Epoch 14/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3126 - loss: 3.0128 - val_accuracy: 0.3232 - val_loss: 2.8843\n",
      "Epoch 15/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3353 - loss: 3.0175 - val_accuracy: 0.3232 - val_loss: 2.2782\n",
      "Epoch 16/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3323 - loss: 3.0196 - val_accuracy: 0.3232 - val_loss: 2.6188\n",
      "Epoch 17/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3416 - loss: 2.9454 - val_accuracy: 0.3232 - val_loss: 2.4195\n",
      "Epoch 18/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3170 - loss: 2.9388 - val_accuracy: 0.3232 - val_loss: 2.4670\n",
      "Epoch 19/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3224 - loss: 2.9037 - val_accuracy: 0.3232 - val_loss: 2.5577\n",
      "Epoch 20/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3042 - loss: 2.9598 - val_accuracy: 0.3232 - val_loss: 2.7488\n",
      "Epoch 21/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3351 - loss: 2.9136 - val_accuracy: 0.3232 - val_loss: 2.5908\n",
      "Epoch 22/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3007 - loss: 2.9342 - val_accuracy: 0.3232 - val_loss: 2.5065\n",
      "Epoch 23/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3373 - loss: 2.9184 - val_accuracy: 0.3232 - val_loss: 2.0802\n",
      "Epoch 24/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3347 - loss: 2.8868 - val_accuracy: 0.3232 - val_loss: 2.2554\n",
      "Epoch 25/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3414 - loss: 2.9366 - val_accuracy: 0.3232 - val_loss: 2.2584\n",
      "Epoch 26/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3391 - loss: 2.8836 - val_accuracy: 0.3232 - val_loss: 2.2070\n",
      "Epoch 27/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3264 - loss: 2.8548 - val_accuracy: 0.3232 - val_loss: 2.5836\n",
      "Epoch 28/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3312 - loss: 2.9138 - val_accuracy: 0.3232 - val_loss: 2.1563\n",
      "Epoch 29/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3549 - loss: 2.9220 - val_accuracy: 0.3232 - val_loss: 2.3414\n",
      "Epoch 30/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3323 - loss: 2.8254 - val_accuracy: 0.3232 - val_loss: 2.4072\n",
      "Epoch 31/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3233 - loss: 2.9275 - val_accuracy: 0.3232 - val_loss: 2.2341\n",
      "Epoch 32/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3458 - loss: 2.8723 - val_accuracy: 0.3232 - val_loss: 2.2474\n",
      "Epoch 33/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3451 - loss: 2.8934 - val_accuracy: 0.3232 - val_loss: 2.4256\n",
      "Epoch 34/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3315 - loss: 2.8243 - val_accuracy: 0.3232 - val_loss: 2.4054\n",
      "Epoch 35/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3622 - loss: 2.8212 - val_accuracy: 0.3232 - val_loss: 2.2541\n",
      "Epoch 36/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3446 - loss: 2.7862 - val_accuracy: 0.3232 - val_loss: 2.3152\n",
      "Epoch 37/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3283 - loss: 2.8135 - val_accuracy: 0.3232 - val_loss: 2.3550\n",
      "Epoch 38/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3293 - loss: 2.7917 - val_accuracy: 0.3232 - val_loss: 2.1823\n",
      "Epoch 39/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3553 - loss: 2.7955 - val_accuracy: 0.3232 - val_loss: 2.1324\n",
      "Epoch 40/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3219 - loss: 2.8580 - val_accuracy: 0.3232 - val_loss: 2.2636\n",
      "Epoch 41/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3583 - loss: 2.7544 - val_accuracy: 0.3232 - val_loss: 1.9016\n",
      "Epoch 42/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3425 - loss: 2.9924 - val_accuracy: 0.3232 - val_loss: 1.8842\n",
      "Epoch 43/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3187 - loss: 2.7828 - val_accuracy: 0.3232 - val_loss: 2.2181\n",
      "Epoch 44/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3466 - loss: 2.8043 - val_accuracy: 0.3232 - val_loss: 2.4416\n",
      "Epoch 45/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3371 - loss: 2.7658 - val_accuracy: 0.3232 - val_loss: 2.1004\n",
      "Epoch 46/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3418 - loss: 2.7371 - val_accuracy: 0.3232 - val_loss: 2.1967\n",
      "Epoch 47/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3399 - loss: 2.7462 - val_accuracy: 0.3232 - val_loss: 2.0959\n",
      "Epoch 48/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3238 - loss: 2.8062 - val_accuracy: 0.3232 - val_loss: 2.1273\n",
      "Epoch 49/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3345 - loss: 2.8074 - val_accuracy: 0.3232 - val_loss: 2.0602\n",
      "Epoch 50/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3292 - loss: 2.7800 - val_accuracy: 0.3232 - val_loss: 2.1061\n",
      "Epoch 51/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3560 - loss: 2.7581 - val_accuracy: 0.3232 - val_loss: 2.0396\n",
      "Epoch 52/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3150 - loss: 2.7156 - val_accuracy: 0.3232 - val_loss: 2.4618\n",
      "Epoch 53/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3498 - loss: 2.7655 - val_accuracy: 0.3232 - val_loss: 1.9175\n",
      "Epoch 54/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3331 - loss: 2.6813 - val_accuracy: 0.3232 - val_loss: 2.3016\n",
      "Epoch 55/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3150 - loss: 2.7879 - val_accuracy: 0.3232 - val_loss: 2.3451\n",
      "Epoch 56/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3136 - loss: 2.6435 - val_accuracy: 0.3232 - val_loss: 2.2454\n",
      "Epoch 57/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3496 - loss: 2.7605 - val_accuracy: 0.3232 - val_loss: 2.0057\n",
      "Epoch 58/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3236 - loss: 2.7268 - val_accuracy: 0.3232 - val_loss: 2.1564\n",
      "Epoch 59/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3505 - loss: 2.6642 - val_accuracy: 0.3232 - val_loss: 2.1255\n",
      "Epoch 60/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3501 - loss: 2.5830 - val_accuracy: 0.3232 - val_loss: 1.7353\n",
      "Epoch 61/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3119 - loss: 2.7027 - val_accuracy: 0.3232 - val_loss: 2.4077\n",
      "Epoch 62/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3399 - loss: 2.7039 - val_accuracy: 0.3232 - val_loss: 2.0418\n",
      "Epoch 63/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3272 - loss: 2.9236 - val_accuracy: 0.3232 - val_loss: 2.3613\n",
      "Epoch 64/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3210 - loss: 2.7717 - val_accuracy: 0.3232 - val_loss: 2.1891\n",
      "Epoch 65/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3270 - loss: 2.7338 - val_accuracy: 0.3232 - val_loss: 2.2282\n",
      "Epoch 66/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3450 - loss: 2.6830 - val_accuracy: 0.3232 - val_loss: 2.0043\n",
      "Epoch 67/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3059 - loss: 2.6072 - val_accuracy: 0.3232 - val_loss: 2.0414\n",
      "Epoch 68/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3486 - loss: 2.4954 - val_accuracy: 0.3232 - val_loss: 2.2331\n",
      "Epoch 69/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3653 - loss: 2.5793 - val_accuracy: 0.3232 - val_loss: 2.3322\n",
      "Epoch 70/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3426 - loss: 2.6936 - val_accuracy: 0.3232 - val_loss: 2.2321\n",
      "Epoch 71/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3385 - loss: 2.5979 - val_accuracy: 0.3232 - val_loss: 2.2579\n",
      "Epoch 72/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3535 - loss: 2.6120 - val_accuracy: 0.3232 - val_loss: 1.8640\n",
      "Epoch 73/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3300 - loss: 2.7043 - val_accuracy: 0.3232 - val_loss: 1.9147\n",
      "Epoch 74/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3307 - loss: 2.5749 - val_accuracy: 0.3232 - val_loss: 2.6605\n",
      "Epoch 75/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3176 - loss: 2.6136 - val_accuracy: 0.3232 - val_loss: 2.0747\n",
      "Epoch 76/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3385 - loss: 2.4439 - val_accuracy: 0.3232 - val_loss: 1.9920\n",
      "Epoch 77/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3181 - loss: 2.6657 - val_accuracy: 0.3232 - val_loss: 2.4355\n",
      "Epoch 78/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3483 - loss: 2.5985 - val_accuracy: 0.3232 - val_loss: 2.0377\n",
      "Epoch 79/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3210 - loss: 2.5775 - val_accuracy: 0.3788 - val_loss: 2.1085\n",
      "Epoch 80/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3785 - loss: 2.5586 - val_accuracy: 0.3636 - val_loss: 2.0870\n",
      "Epoch 81/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3987 - loss: 2.5020 - val_accuracy: 0.3687 - val_loss: 1.9374\n",
      "Epoch 82/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4117 - loss: 2.5082 - val_accuracy: 0.3485 - val_loss: 2.6900\n",
      "Epoch 83/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3514 - loss: 2.7013 - val_accuracy: 0.3586 - val_loss: 2.1760\n",
      "Epoch 84/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4071 - loss: 2.5840 - val_accuracy: 0.4242 - val_loss: 1.8815\n",
      "Epoch 85/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4058 - loss: 2.4934 - val_accuracy: 0.4192 - val_loss: 1.8213\n",
      "Epoch 86/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4040 - loss: 2.6785 - val_accuracy: 0.3586 - val_loss: 2.2051\n",
      "Epoch 87/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4086 - loss: 2.4311 - val_accuracy: 0.3636 - val_loss: 2.4124\n",
      "Epoch 88/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4104 - loss: 2.4734 - val_accuracy: 0.3889 - val_loss: 2.3301\n",
      "Epoch 89/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4050 - loss: 2.4717 - val_accuracy: 0.4293 - val_loss: 1.7545\n",
      "Epoch 90/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4381 - loss: 2.5277 - val_accuracy: 0.3939 - val_loss: 2.0175\n",
      "Epoch 91/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4333 - loss: 2.4950 - val_accuracy: 0.4040 - val_loss: 2.2501\n",
      "Epoch 92/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4349 - loss: 2.4155 - val_accuracy: 0.4192 - val_loss: 2.3459\n",
      "Epoch 93/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4441 - loss: 2.4662 - val_accuracy: 0.3939 - val_loss: 2.0393\n",
      "Epoch 94/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3432 - loss: 2.6680 - val_accuracy: 0.4141 - val_loss: 2.0006\n",
      "Epoch 95/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4558 - loss: 2.4595 - val_accuracy: 0.4394 - val_loss: 1.7245\n",
      "Epoch 96/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4368 - loss: 2.4978 - val_accuracy: 0.4242 - val_loss: 1.7451\n",
      "Epoch 97/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3669 - loss: 2.7393 - val_accuracy: 0.3586 - val_loss: 2.6868\n",
      "Epoch 98/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3750 - loss: 2.6844 - val_accuracy: 0.3535 - val_loss: 2.1685\n",
      "Epoch 99/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4108 - loss: 2.4823 - val_accuracy: 0.3788 - val_loss: 2.1949\n",
      "Epoch 100/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3881 - loss: 2.5645 - val_accuracy: 0.4343 - val_loss: 1.7732\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "acc=0.43434343434343436, positive_rate=0.1865671641791045, negative_rate=0.953125, time=180.59542100003455\n",
      "Epoch 1/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.3462 - loss: 61.7320 - val_accuracy: 0.3232 - val_loss: 1.0066\n",
      "Epoch 2/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3160 - loss: 30.9925 - val_accuracy: 0.3232 - val_loss: 1.3359\n",
      "Epoch 3/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3505 - loss: 4.6323 - val_accuracy: 0.3232 - val_loss: 1.4980\n",
      "Epoch 4/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3477 - loss: 4.2067 - val_accuracy: 0.3232 - val_loss: 1.5534\n",
      "Epoch 5/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3296 - loss: 4.1995 - val_accuracy: 0.3232 - val_loss: 1.6874\n",
      "Epoch 6/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3447 - loss: 4.0648 - val_accuracy: 0.3232 - val_loss: 1.9729\n",
      "Epoch 7/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3455 - loss: 3.9803 - val_accuracy: 0.3232 - val_loss: 2.2086\n",
      "Epoch 8/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3374 - loss: 4.0729 - val_accuracy: 0.3232 - val_loss: 2.9997\n",
      "Epoch 9/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3440 - loss: 3.9690 - val_accuracy: 0.3232 - val_loss: 3.1445\n",
      "Epoch 10/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2992 - loss: 4.1014 - val_accuracy: 0.3232 - val_loss: 3.4372\n",
      "Epoch 11/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3459 - loss: 3.9595 - val_accuracy: 0.3232 - val_loss: 3.0090\n",
      "Epoch 12/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3487 - loss: 3.9097 - val_accuracy: 0.3232 - val_loss: 3.1397\n",
      "Epoch 13/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3505 - loss: 3.9117 - val_accuracy: 0.3232 - val_loss: 2.5358\n",
      "Epoch 14/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3225 - loss: 3.9366 - val_accuracy: 0.3232 - val_loss: 3.5144\n",
      "Epoch 15/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3405 - loss: 3.8491 - val_accuracy: 0.3232 - val_loss: 3.6053\n",
      "Epoch 16/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3362 - loss: 3.8465 - val_accuracy: 0.3232 - val_loss: 3.6311\n",
      "Epoch 17/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3625 - loss: 3.7795 - val_accuracy: 0.3232 - val_loss: 2.7563\n",
      "Epoch 18/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3329 - loss: 3.8722 - val_accuracy: 0.3232 - val_loss: 3.1697\n",
      "Epoch 19/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3487 - loss: 3.8095 - val_accuracy: 0.3232 - val_loss: 2.8007\n",
      "Epoch 20/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3364 - loss: 3.8042 - val_accuracy: 0.3232 - val_loss: 3.0520\n",
      "Epoch 21/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3397 - loss: 3.7750 - val_accuracy: 0.3232 - val_loss: 2.4796\n",
      "Epoch 22/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3636 - loss: 3.7893 - val_accuracy: 0.3232 - val_loss: 3.3798\n",
      "Epoch 23/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3421 - loss: 3.7856 - val_accuracy: 0.3232 - val_loss: 3.1901\n",
      "Epoch 24/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3507 - loss: 3.6858 - val_accuracy: 0.3232 - val_loss: 3.2617\n",
      "Epoch 25/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3334 - loss: 3.8051 - val_accuracy: 0.3232 - val_loss: 2.2531\n",
      "Epoch 26/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3092 - loss: 3.7451 - val_accuracy: 0.3232 - val_loss: 3.3919\n",
      "Epoch 27/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3587 - loss: 3.6871 - val_accuracy: 0.3232 - val_loss: 2.8117\n",
      "Epoch 28/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3131 - loss: 3.8775 - val_accuracy: 0.3232 - val_loss: 2.7524\n",
      "Epoch 29/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3208 - loss: 3.7429 - val_accuracy: 0.3232 - val_loss: 3.8408\n",
      "Epoch 30/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3202 - loss: 3.7599 - val_accuracy: 0.3232 - val_loss: 3.2279\n",
      "Epoch 31/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3593 - loss: 3.5894 - val_accuracy: 0.3232 - val_loss: 2.7486\n",
      "Epoch 32/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3519 - loss: 3.6149 - val_accuracy: 0.3232 - val_loss: 3.6135\n",
      "Epoch 33/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3490 - loss: 3.7398 - val_accuracy: 0.3232 - val_loss: 2.9888\n",
      "Epoch 34/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3234 - loss: 3.7292 - val_accuracy: 0.3232 - val_loss: 3.0403\n",
      "Epoch 35/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3332 - loss: 3.6561 - val_accuracy: 0.3232 - val_loss: 3.3803\n",
      "Epoch 36/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3490 - loss: 3.6387 - val_accuracy: 0.3232 - val_loss: 3.1868\n",
      "Epoch 37/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3573 - loss: 3.6003 - val_accuracy: 0.3232 - val_loss: 2.9332\n",
      "Epoch 38/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3126 - loss: 3.7061 - val_accuracy: 0.3232 - val_loss: 3.2618\n",
      "Epoch 39/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3303 - loss: 3.5475 - val_accuracy: 0.3232 - val_loss: 3.4978\n",
      "Epoch 40/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3681 - loss: 3.5684 - val_accuracy: 0.3232 - val_loss: 3.2581\n",
      "Epoch 41/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3506 - loss: 3.5134 - val_accuracy: 0.3232 - val_loss: 2.8408\n",
      "Epoch 42/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3405 - loss: 3.6404 - val_accuracy: 0.3232 - val_loss: 2.8634\n",
      "Epoch 43/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3280 - loss: 3.6713 - val_accuracy: 0.3232 - val_loss: 2.8817\n",
      "Epoch 44/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3325 - loss: 3.4674 - val_accuracy: 0.3232 - val_loss: 3.2002\n",
      "Epoch 45/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3845 - loss: 3.3911 - val_accuracy: 0.3232 - val_loss: 3.0774\n",
      "Epoch 46/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3474 - loss: 3.5043 - val_accuracy: 0.3232 - val_loss: 3.5044\n",
      "Epoch 47/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3302 - loss: 3.5867 - val_accuracy: 0.3232 - val_loss: 2.7934\n",
      "Epoch 48/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3456 - loss: 3.4897 - val_accuracy: 0.3232 - val_loss: 2.7777\n",
      "Epoch 49/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3446 - loss: 3.3975 - val_accuracy: 0.3232 - val_loss: 3.6359\n",
      "Epoch 50/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3356 - loss: 3.4397 - val_accuracy: 0.3232 - val_loss: 2.8553\n",
      "Epoch 51/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3351 - loss: 3.5590 - val_accuracy: 0.3232 - val_loss: 3.0694\n",
      "Epoch 52/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3403 - loss: 3.4156 - val_accuracy: 0.3232 - val_loss: 3.5263\n",
      "Epoch 53/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3217 - loss: 3.5057 - val_accuracy: 0.3232 - val_loss: 3.2746\n",
      "Epoch 54/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3247 - loss: 3.4848 - val_accuracy: 0.3232 - val_loss: 2.8928\n",
      "Epoch 55/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3369 - loss: 3.4771 - val_accuracy: 0.3232 - val_loss: 3.0916\n",
      "Epoch 56/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3509 - loss: 3.3827 - val_accuracy: 0.3232 - val_loss: 2.6248\n",
      "Epoch 57/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3314 - loss: 3.4688 - val_accuracy: 0.3232 - val_loss: 2.9905\n",
      "Epoch 58/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3253 - loss: 3.4440 - val_accuracy: 0.3232 - val_loss: 2.8223\n",
      "Epoch 59/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3265 - loss: 3.4492 - val_accuracy: 0.3232 - val_loss: 2.4987\n",
      "Epoch 60/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3507 - loss: 3.5266 - val_accuracy: 0.3232 - val_loss: 2.5346\n",
      "Epoch 61/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3252 - loss: 3.4387 - val_accuracy: 0.3232 - val_loss: 5.1393\n",
      "Epoch 62/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3586 - loss: 3.5392 - val_accuracy: 0.3232 - val_loss: 2.6063\n",
      "Epoch 63/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3226 - loss: 3.3847 - val_accuracy: 0.3232 - val_loss: 2.5452\n",
      "Epoch 64/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3316 - loss: 3.4120 - val_accuracy: 0.3232 - val_loss: 3.1006\n",
      "Epoch 65/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3412 - loss: 3.3018 - val_accuracy: 0.3232 - val_loss: 2.9235\n",
      "Epoch 66/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3281 - loss: 3.5591 - val_accuracy: 0.3232 - val_loss: 3.5855\n",
      "Epoch 67/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3315 - loss: 3.6413 - val_accuracy: 0.3232 - val_loss: 3.0406\n",
      "Epoch 68/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3146 - loss: 3.4424 - val_accuracy: 0.3232 - val_loss: 2.5916\n",
      "Epoch 69/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3457 - loss: 3.4501 - val_accuracy: 0.3232 - val_loss: 3.4934\n",
      "Epoch 70/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3263 - loss: 3.3782 - val_accuracy: 0.3232 - val_loss: 3.3800\n",
      "Epoch 71/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3358 - loss: 3.3240 - val_accuracy: 0.3232 - val_loss: 3.0045\n",
      "Epoch 72/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3369 - loss: 3.5167 - val_accuracy: 0.3232 - val_loss: 2.8858\n",
      "Epoch 73/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3405 - loss: 3.3876 - val_accuracy: 0.3232 - val_loss: 2.5123\n",
      "Epoch 74/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3238 - loss: 3.5108 - val_accuracy: 0.3232 - val_loss: 2.6510\n",
      "Epoch 75/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3544 - loss: 3.3251 - val_accuracy: 0.3232 - val_loss: 2.6972\n",
      "Epoch 76/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3426 - loss: 3.3580 - val_accuracy: 0.3232 - val_loss: 3.0532\n",
      "Epoch 77/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3261 - loss: 3.2315 - val_accuracy: 0.3232 - val_loss: 3.2877\n",
      "Epoch 78/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3575 - loss: 3.3248 - val_accuracy: 0.3232 - val_loss: 2.9265\n",
      "Epoch 79/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3060 - loss: 3.3427 - val_accuracy: 0.3232 - val_loss: 3.5230\n",
      "Epoch 80/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3373 - loss: 3.3372 - val_accuracy: 0.3232 - val_loss: 3.4713\n",
      "Epoch 81/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3377 - loss: 4.1634 - val_accuracy: 0.3232 - val_loss: 3.4309\n",
      "Epoch 82/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3388 - loss: 3.3185 - val_accuracy: 0.3232 - val_loss: 2.5169\n",
      "Epoch 83/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3468 - loss: 3.5862 - val_accuracy: 0.3232 - val_loss: 2.7453\n",
      "Epoch 84/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3075 - loss: 3.4773 - val_accuracy: 0.3232 - val_loss: 2.6767\n",
      "Epoch 85/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3221 - loss: 3.2931 - val_accuracy: 0.3232 - val_loss: 2.6109\n",
      "Epoch 86/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3579 - loss: 3.3069 - val_accuracy: 0.3232 - val_loss: 3.3379\n",
      "Epoch 87/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3174 - loss: 3.3688 - val_accuracy: 0.3232 - val_loss: 3.4543\n",
      "Epoch 88/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3421 - loss: 3.2057 - val_accuracy: 0.3232 - val_loss: 2.9454\n",
      "Epoch 89/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3535 - loss: 3.0896 - val_accuracy: 0.3232 - val_loss: 3.4616\n",
      "Epoch 90/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3509 - loss: 3.2698 - val_accuracy: 0.3232 - val_loss: 3.1725\n",
      "Epoch 91/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3509 - loss: 3.4631 - val_accuracy: 0.3232 - val_loss: 2.7227\n",
      "Epoch 92/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3460 - loss: 3.5119 - val_accuracy: 0.3232 - val_loss: 2.8518\n",
      "Epoch 93/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3355 - loss: 3.1530 - val_accuracy: 0.3232 - val_loss: 2.9628\n",
      "Epoch 94/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3306 - loss: 3.4199 - val_accuracy: 0.3232 - val_loss: 3.3528\n",
      "Epoch 95/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3286 - loss: 3.3009 - val_accuracy: 0.3232 - val_loss: 2.8248\n",
      "Epoch 96/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3576 - loss: 3.2269 - val_accuracy: 0.3232 - val_loss: 2.4597\n",
      "Epoch 97/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3264 - loss: 3.2798 - val_accuracy: 0.3232 - val_loss: 2.7606\n",
      "Epoch 98/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3506 - loss: 3.0574 - val_accuracy: 0.3232 - val_loss: 2.5098\n",
      "Epoch 99/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3373 - loss: 3.3038 - val_accuracy: 0.3232 - val_loss: 2.7291\n",
      "Epoch 100/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3548 - loss: 3.0674 - val_accuracy: 0.3232 - val_loss: 3.3907\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 258ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "acc=0.32323232323232326, positive_rate=0.0, negative_rate=1.0, time=238.4459865000099\n"
     ]
    }
   ],
   "source": [
    "risky_models = [make_model(x_ae_train, x_t_train,\n",
    "    n_linear_layers=4, linear_size=16, n_filters=4, spatial_dropout_k = 0.00, dropout_k = .0, kernel_size=3,\n",
    "    n_conv_layers=3, n_conv_layers_pool_1=0, c_reg=0.002, l_reg=0.002, pool=2\n",
    ") for _ in range(4)]\n",
    "\n",
    "start = perf_counter()\n",
    "\n",
    "for i in range(len(risky_models)):\n",
    "    history = risky_models[i].fit(\n",
    "        [x_ae_train, x_t_train],\n",
    "        yb_train,\n",
    "        epochs=100,\n",
    "        validation_data=([x_ae_val, x_t_val], yb_val),\n",
    "        batch_size=10,\n",
    "        class_weight={0: 4**(i+1), 1: 1}\n",
    "        # callbacks=[ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=30, min_lr=1e-5)]\n",
    "    )\n",
    "    \n",
    "    a = ((risky_models[i].predict([x_ae_val, x_t_val]).flatten() > .5) == yb_val).mean()\n",
    "\n",
    "    y_pred = risky_models[i].predict([x_ae_val, x_t_val]).flatten()\n",
    "    y_pred_i = (y_pred > .5).flatten()\n",
    "    tn = ((y_pred_i == 0) & (yb_val == 0)).mean()\n",
    "    fn = ((y_pred_i == 0) & (yb_val == 1)).mean()\n",
    "    tp = ((y_pred_i == 1) & (yb_val == 1)).mean()\n",
    "    fp = ((y_pred_i == 1) & (yb_val == 0)).mean()\n",
    "\n",
    "    print(f'acc={a}, positive_rate={tp/(tp+fn)}, negative_rate={tn/(tn + fp)}, time={perf_counter() - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a79e78ac-81dd-49c6-9aba-fc95bd4a89a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Risky CNN loss over Training')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.gca()\n",
    "\n",
    "ax.plot(history.history['loss'], label='Training')\n",
    "ax.plot(\n",
    "    np.convolve(np.array(history.history['val_loss']), np.ones(10)/10, mode='valid'),\n",
    "    label='Validation (Running Mean)'\n",
    ")\n",
    "ax.legend()\n",
    "ax.set_xlabel('# Epochs')\n",
    "ax.set_ylabel('loss')\n",
    "ax.set_ylim((0, 1))\n",
    "ax.set_title('Risky CNN loss over Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c7275873-35c3-4cc9-af77-065670205c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    }
   ],
   "source": [
    "y_pred = risky_models[-1].predict([x_ae_val, x_t_val]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f3377255-097d-45e3-84d9-2f08325f79e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.32323232323232326, 0.6767676767676768, 0.0, 0.0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_i = (y_pred > .5).flatten()\n",
    "tn = ((y_pred_i == 0) & (yb_val == 0)).mean()\n",
    "fn = ((y_pred_i == 0) & (yb_val == 1)).mean()\n",
    "tp = ((y_pred_i == 1) & (yb_val == 1)).mean()\n",
    "fp = ((y_pred_i == 1) & (yb_val == 0)).mean()\n",
    "\n",
    "tn, fn, tp, fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "78508634-36c3-41a1-ab11-120c7219ddb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn/(tn + fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "082c7243-ae29-428c-96e1-a557f794fcd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.  , 0.  , 0.76])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_predict = cnn_model.predict([x_ae_val, x_t_val]).flatten()\n",
    "risky_predict = risky_model.predict([x_ae_val, x_t_val]).flatten()\n",
    "\n",
    "sel = (cnn_predict > .5) & (risky_predict < .5)\n",
    "\n",
    "(np.vstack((\n",
    "    cnn_predict,\n",
    "    risky_predict,\n",
    "    yb_val\n",
    ")).T > .5)[sel].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6ddaa38b-7e33-4cbe-8993-e2883518f4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-10 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-10 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-10 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-10 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-10 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-10 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-10 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-10 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-10 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-10 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_model = sklearn.linear_model.LogisticRegression()\n",
    "xm_train = np.hstack([cnn_model.predict([x_ae_train, x_t_train])] + [risky_models[i].predict([x_ae_train, x_t_train]) for i in range(len(risky_models))])\n",
    "xm_val = np.hstack([cnn_model.predict([x_ae_val, x_t_val])] + [risky_models[i].predict([x_ae_val, x_t_val]) for i in range(len(risky_models))])\n",
    "\n",
    "top_model.fit(xm_train, yb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7ab45c2c-337c-43c4-a9db-8633fb220e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7121212121212122"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(top_model.predict(xm_val) == yb_val).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8c0883eb-49ed-489a-9e31-d6374a1b9ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.85287882, 5.46718156, 0.68462707, 1.96821083, 1.69881954]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11485575-2a2f-4d18-9e37-a623a4d5cddb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Individual Stresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b3dfa5c5-d779-4fe5-a06d-491ef3eb0a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stress_sel = df[stresses].any(axis=1)\n",
    "x_traits = df[stress_sel][trait_cols].values\n",
    "yi = df[stress_sel][stresses].values\n",
    "x_t_stress = x_t[stress_sel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5a00011f-fe35-400c-be8c-bc21833c7135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "\n",
    "x_traits = ((x_traits - x_traits.min(axis=0))/(x_traits.max(axis=0)-x_traits.min(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "22ef97ff-e563-466a-8666-fe0846de2fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only single stress samples\n",
    "\n",
    "sel_1 = yi.sum(axis=1).flatten() == 1\n",
    "x_traits = x_traits[sel_1]\n",
    "yi = yi[sel_1]\n",
    "x_t_stress = x_t_stress[sel_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "99c9055a-c187-4004-8471-c1e0027b6cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(yi.sum(axis=1) > 1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facdb357-e078-4c93-ab0b-cfb0d46bd70a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Cancel Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "178d6156-e8a8-4a11-9dcf-c3833562f8f7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class COReg(Regularizer):\n",
    "    def __init__(self, lambda_1=1e-3, lambda_2=1e-3):\n",
    "        self.lambda_1 = lambda_1\n",
    "        self.lambda_2 = lambda_2\n",
    "\n",
    "    def call(self, x):\n",
    "        return -1*lambda_1*ops.var(x) + L1(lambda_2)(x)\n",
    "\n",
    "class CancelOutLayer(keras.layers.Layer):\n",
    "    def __init__(self, lambda_1=1e-3, lambda_2=1e-3, **kwargs):\n",
    "        super(CancelOutLayer, self).__init__(**kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        weight_shape = (1, input_shape[-1])\n",
    "\n",
    "        \n",
    "        \n",
    "        self.kernel = self.add_weight(\n",
    "            name='kernel', \n",
    "            shape=weight_shape,\n",
    "            initializer='uniform',\n",
    "            trainable=True,\n",
    "            regularizer=COReg\n",
    "        )\n",
    "        \n",
    "        self.bias = self.add_weight(\n",
    "            name='bias', \n",
    "            shape=weight_shape,\n",
    "            initializer='zeros',\n",
    "            trainable=True\n",
    "        )\n",
    "        \n",
    "        self.built=True\n",
    "    \n",
    "    #operation:\n",
    "    def call(self, inputs):\n",
    "        return (inputs * self.kernel) + self.bias\n",
    "    \n",
    "    #output shape\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "    \n",
    "    #for saving the model - only necessary if you have parameters in __init__\n",
    "    def get_config(self):\n",
    "        config = super(SingleConnected, self).get_config()\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf55dc02-d9b7-42df-8c50-ac75d246f13e",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8da37159-84fc-4dbc-ab21-3fcd1e3ecb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_sel = np.random.random(size=(x_traits.shape[0],)) < .2\n",
    "x_traits_train, x_traits_val = x_traits[~val_sel], x_traits[val_sel]\n",
    "yi_train, yi_val = yi[~val_sel], yi[val_sel]\n",
    "x_t_stress_train, x_t_stress_val = x_t_stress[~val_sel], x_t_stress[val_sel]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cc7880-305e-4591-ae54-6be3d2a74f75",
   "metadata": {},
   "source": [
    "#### NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ab5ed361-d2a3-4c09-bd6a-abab951a69c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_reg = 0\n",
    "\n",
    "individual_layers = []\n",
    "\n",
    "individual_layers.append(CancelOutLayer(lambda_1=0, lambda_2=0))\n",
    "\n",
    "for _ in range(6):\n",
    "    individual_layers.append(layers.Dense(32, activation='relu', kernel_regularizer=L2(l_reg)))\n",
    "    # individual_layers.append(layers.BatchNormalization())\n",
    "    individual_layers.append(layers.Dropout(0.00))\n",
    "\n",
    "individual_layers.append(layers.Dense(yi.shape[1], activation='softmax'))\n",
    "\n",
    "individual_model = Sequential(individual_layers)\n",
    "\n",
    "individual_model.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12428ed-2ed3-464f-bdfd-0ae674da8c55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2522 - loss: 1.7971 - val_accuracy: 0.2840 - val_loss: 1.7770\n",
      "Epoch 2/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3548 - loss: 1.7691 - val_accuracy: 0.2840 - val_loss: 1.7518\n",
      "Epoch 3/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3064 - loss: 1.7456 - val_accuracy: 0.2840 - val_loss: 1.7273\n",
      "Epoch 4/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3751 - loss: 1.7134 - val_accuracy: 0.2840 - val_loss: 1.6985\n",
      "Epoch 5/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3555 - loss: 1.6735 - val_accuracy: 0.2840 - val_loss: 1.6670\n",
      "Epoch 6/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3949 - loss: 1.6022 - val_accuracy: 0.2840 - val_loss: 1.6447\n",
      "Epoch 7/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3316 - loss: 1.6275 - val_accuracy: 0.2840 - val_loss: 1.6323\n",
      "Epoch 8/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3260 - loss: 1.6172 - val_accuracy: 0.2840 - val_loss: 1.6219\n",
      "Epoch 9/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3348 - loss: 1.5783 - val_accuracy: 0.2840 - val_loss: 1.6105\n",
      "Epoch 10/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3312 - loss: 1.5877 - val_accuracy: 0.2840 - val_loss: 1.6033\n",
      "Epoch 11/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3481 - loss: 1.5737 - val_accuracy: 0.2840 - val_loss: 1.5952\n",
      "Epoch 12/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3379 - loss: 1.5715 - val_accuracy: 0.2840 - val_loss: 1.5884\n",
      "Epoch 13/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3474 - loss: 1.5594 - val_accuracy: 0.2840 - val_loss: 1.5830\n",
      "Epoch 14/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3914 - loss: 1.5216 - val_accuracy: 0.2840 - val_loss: 1.5766\n",
      "Epoch 15/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3733 - loss: 1.5327 - val_accuracy: 0.2840 - val_loss: 1.5711\n",
      "Epoch 16/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3241 - loss: 1.5665 - val_accuracy: 0.2840 - val_loss: 1.5681\n",
      "Epoch 17/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3533 - loss: 1.5412 - val_accuracy: 0.2840 - val_loss: 1.5637\n",
      "Epoch 18/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3589 - loss: 1.5165 - val_accuracy: 0.2840 - val_loss: 1.5601\n",
      "Epoch 19/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3281 - loss: 1.5349 - val_accuracy: 0.2840 - val_loss: 1.5575\n",
      "Epoch 20/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3193 - loss: 1.5561 - val_accuracy: 0.2840 - val_loss: 1.5550\n",
      "Epoch 21/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3604 - loss: 1.5141 - val_accuracy: 0.2840 - val_loss: 1.5518\n",
      "Epoch 22/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3431 - loss: 1.5254 - val_accuracy: 0.2840 - val_loss: 1.5501\n",
      "Epoch 23/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3722 - loss: 1.5099 - val_accuracy: 0.2840 - val_loss: 1.5472\n",
      "Epoch 24/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3729 - loss: 1.4869 - val_accuracy: 0.2840 - val_loss: 1.5440\n",
      "Epoch 25/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3593 - loss: 1.5146 - val_accuracy: 0.2840 - val_loss: 1.5420\n",
      "Epoch 26/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3938 - loss: 1.4972 - val_accuracy: 0.2840 - val_loss: 1.5396\n",
      "Epoch 27/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3539 - loss: 1.5242 - val_accuracy: 0.2840 - val_loss: 1.5367\n",
      "Epoch 28/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3340 - loss: 1.5164 - val_accuracy: 0.2840 - val_loss: 1.5350\n",
      "Epoch 29/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3279 - loss: 1.5398 - val_accuracy: 0.2840 - val_loss: 1.5337\n",
      "Epoch 30/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3233 - loss: 1.4964 - val_accuracy: 0.2840 - val_loss: 1.5300\n",
      "Epoch 31/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3207 - loss: 1.5374 - val_accuracy: 0.2840 - val_loss: 1.5279\n",
      "Epoch 32/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3298 - loss: 1.4869 - val_accuracy: 0.2840 - val_loss: 1.5237\n",
      "Epoch 33/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3262 - loss: 1.5137 - val_accuracy: 0.2840 - val_loss: 1.5192\n",
      "Epoch 34/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3654 - loss: 1.5025 - val_accuracy: 0.2840 - val_loss: 1.5139\n",
      "Epoch 35/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3385 - loss: 1.4762 - val_accuracy: 0.2840 - val_loss: 1.5084\n",
      "Epoch 36/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2788 - loss: 1.5392 - val_accuracy: 0.2840 - val_loss: 1.5030\n",
      "Epoch 37/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2935 - loss: 1.5162 - val_accuracy: 0.2840 - val_loss: 1.4948\n",
      "Epoch 38/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3374 - loss: 1.4999 - val_accuracy: 0.2840 - val_loss: 1.4773\n",
      "Epoch 39/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3440 - loss: 1.4749 - val_accuracy: 0.2840 - val_loss: 1.4594\n",
      "Epoch 40/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3312 - loss: 1.4768 - val_accuracy: 0.2840 - val_loss: 1.4403\n",
      "Epoch 41/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3630 - loss: 1.4394 - val_accuracy: 0.2840 - val_loss: 1.4111\n",
      "Epoch 42/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3387 - loss: 1.4364 - val_accuracy: 0.2840 - val_loss: 1.3881\n",
      "Epoch 43/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3601 - loss: 1.4316 - val_accuracy: 0.2840 - val_loss: 1.3655\n",
      "Epoch 44/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3615 - loss: 1.4171 - val_accuracy: 0.3333 - val_loss: 1.3472\n",
      "Epoch 45/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3691 - loss: 1.3649 - val_accuracy: 0.3951 - val_loss: 1.3236\n",
      "Epoch 46/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4083 - loss: 1.3873 - val_accuracy: 0.4198 - val_loss: 1.3151\n",
      "Epoch 47/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4468 - loss: 1.3282 - val_accuracy: 0.4074 - val_loss: 1.2999\n",
      "Epoch 48/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4284 - loss: 1.3637 - val_accuracy: 0.3951 - val_loss: 1.2950\n",
      "Epoch 49/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4207 - loss: 1.3414 - val_accuracy: 0.4198 - val_loss: 1.2996\n",
      "Epoch 50/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4179 - loss: 1.3474 - val_accuracy: 0.4321 - val_loss: 1.2750\n",
      "Epoch 51/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3695 - loss: 1.3530 - val_accuracy: 0.4568 - val_loss: 1.2678\n",
      "Epoch 52/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3674 - loss: 1.3714 - val_accuracy: 0.4691 - val_loss: 1.2622\n",
      "Epoch 53/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3638 - loss: 1.4044 - val_accuracy: 0.4691 - val_loss: 1.2581\n",
      "Epoch 54/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3581 - loss: 1.3738 - val_accuracy: 0.4321 - val_loss: 1.2630\n",
      "Epoch 55/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3817 - loss: 1.3535 - val_accuracy: 0.4691 - val_loss: 1.2501\n",
      "Epoch 56/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3958 - loss: 1.3333 - val_accuracy: 0.4691 - val_loss: 1.2468\n",
      "Epoch 57/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3853 - loss: 1.3611 - val_accuracy: 0.4691 - val_loss: 1.2484\n",
      "Epoch 58/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4229 - loss: 1.3004 - val_accuracy: 0.4691 - val_loss: 1.2437\n",
      "Epoch 59/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4117 - loss: 1.3326 - val_accuracy: 0.4815 - val_loss: 1.2385\n",
      "Epoch 60/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4148 - loss: 1.3252 - val_accuracy: 0.4815 - val_loss: 1.2346\n",
      "Epoch 61/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3777 - loss: 1.3265 - val_accuracy: 0.4815 - val_loss: 1.2343\n",
      "Epoch 62/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3892 - loss: 1.3446 - val_accuracy: 0.4691 - val_loss: 1.2368\n",
      "Epoch 63/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4234 - loss: 1.3313 - val_accuracy: 0.4815 - val_loss: 1.2322\n",
      "Epoch 64/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3929 - loss: 1.3164 - val_accuracy: 0.4815 - val_loss: 1.2271\n",
      "Epoch 65/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4617 - loss: 1.2735 - val_accuracy: 0.4815 - val_loss: 1.2273\n",
      "Epoch 66/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4465 - loss: 1.3025 - val_accuracy: 0.4815 - val_loss: 1.2242\n",
      "Epoch 67/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3678 - loss: 1.3617 - val_accuracy: 0.4815 - val_loss: 1.2223\n",
      "Epoch 68/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4450 - loss: 1.2772 - val_accuracy: 0.4815 - val_loss: 1.2227\n",
      "Epoch 69/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3902 - loss: 1.3450 - val_accuracy: 0.4815 - val_loss: 1.2206\n",
      "Epoch 70/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4599 - loss: 1.2607 - val_accuracy: 0.4815 - val_loss: 1.2192\n",
      "Epoch 71/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4169 - loss: 1.3111 - val_accuracy: 0.4815 - val_loss: 1.2185\n",
      "Epoch 72/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4213 - loss: 1.3124 - val_accuracy: 0.4815 - val_loss: 1.2168\n",
      "Epoch 73/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4191 - loss: 1.2911 - val_accuracy: 0.4815 - val_loss: 1.2130\n",
      "Epoch 74/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4098 - loss: 1.3062 - val_accuracy: 0.4815 - val_loss: 1.2147\n",
      "Epoch 75/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4354 - loss: 1.3264 - val_accuracy: 0.4815 - val_loss: 1.2181\n",
      "Epoch 76/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4196 - loss: 1.3212 - val_accuracy: 0.4815 - val_loss: 1.2105\n",
      "Epoch 77/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4497 - loss: 1.3088 - val_accuracy: 0.4815 - val_loss: 1.2147\n",
      "Epoch 78/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3864 - loss: 1.3216 - val_accuracy: 0.4815 - val_loss: 1.2153\n",
      "Epoch 79/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4704 - loss: 1.2410 - val_accuracy: 0.4815 - val_loss: 1.2158\n",
      "Epoch 80/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4208 - loss: 1.2983 - val_accuracy: 0.4815 - val_loss: 1.2143\n",
      "Epoch 81/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3958 - loss: 1.2841 - val_accuracy: 0.4815 - val_loss: 1.2171\n",
      "Epoch 82/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4008 - loss: 1.3618 - val_accuracy: 0.4815 - val_loss: 1.2156\n",
      "Epoch 83/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3925 - loss: 1.3318 - val_accuracy: 0.4815 - val_loss: 1.2100\n",
      "Epoch 84/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4087 - loss: 1.3350 - val_accuracy: 0.4815 - val_loss: 1.2152\n",
      "Epoch 85/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4044 - loss: 1.3066 - val_accuracy: 0.4815 - val_loss: 1.2136\n",
      "Epoch 86/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4293 - loss: 1.3310 - val_accuracy: 0.4815 - val_loss: 1.2091\n",
      "Epoch 87/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3911 - loss: 1.3210 - val_accuracy: 0.4815 - val_loss: 1.2088\n",
      "Epoch 88/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4381 - loss: 1.2961 - val_accuracy: 0.4815 - val_loss: 1.2043\n",
      "Epoch 89/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4065 - loss: 1.3404 - val_accuracy: 0.4815 - val_loss: 1.1982\n",
      "Epoch 90/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4056 - loss: 1.3060 - val_accuracy: 0.4815 - val_loss: 1.2129\n",
      "Epoch 91/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4379 - loss: 1.2935 - val_accuracy: 0.4815 - val_loss: 1.2008\n",
      "Epoch 92/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4285 - loss: 1.2845 - val_accuracy: 0.4815 - val_loss: 1.2003\n",
      "Epoch 93/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4268 - loss: 1.3293 - val_accuracy: 0.4815 - val_loss: 1.2061\n",
      "Epoch 94/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4082 - loss: 1.3200 - val_accuracy: 0.4815 - val_loss: 1.2009\n",
      "Epoch 95/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4434 - loss: 1.2883 - val_accuracy: 0.4815 - val_loss: 1.1898\n",
      "Epoch 96/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4341 - loss: 1.3002 - val_accuracy: 0.4815 - val_loss: 1.1995\n",
      "Epoch 97/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4493 - loss: 1.2572 - val_accuracy: 0.4815 - val_loss: 1.1964\n",
      "Epoch 98/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4014 - loss: 1.2778 - val_accuracy: 0.4938 - val_loss: 1.1987\n",
      "Epoch 99/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5027 - loss: 1.2960 - val_accuracy: 0.4815 - val_loss: 1.1843\n",
      "Epoch 100/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4223 - loss: 1.3130 - val_accuracy: 0.4938 - val_loss: 1.1959\n",
      "Epoch 101/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4862 - loss: 1.2185 - val_accuracy: 0.4815 - val_loss: 1.1865\n",
      "Epoch 102/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4753 - loss: 1.2540 - val_accuracy: 0.4938 - val_loss: 1.1986\n",
      "Epoch 103/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5354 - loss: 1.2433 - val_accuracy: 0.4938 - val_loss: 1.1901\n",
      "Epoch 104/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4961 - loss: 1.2425 - val_accuracy: 0.4938 - val_loss: 1.1895\n",
      "Epoch 105/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5042 - loss: 1.2510 - val_accuracy: 0.4938 - val_loss: 1.1798\n",
      "Epoch 106/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4681 - loss: 1.2579 - val_accuracy: 0.5185 - val_loss: 1.1944\n",
      "Epoch 107/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4763 - loss: 1.2812 - val_accuracy: 0.5062 - val_loss: 1.1847\n",
      "Epoch 108/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4700 - loss: 1.2579 - val_accuracy: 0.4938 - val_loss: 1.1748\n",
      "Epoch 109/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4835 - loss: 1.2451 - val_accuracy: 0.5185 - val_loss: 1.1862\n",
      "Epoch 110/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4971 - loss: 1.2542 - val_accuracy: 0.5309 - val_loss: 1.1861\n",
      "Epoch 111/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4915 - loss: 1.2423 - val_accuracy: 0.5062 - val_loss: 1.1665\n",
      "Epoch 112/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5368 - loss: 1.2107 - val_accuracy: 0.4938 - val_loss: 1.1573\n",
      "Epoch 113/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4931 - loss: 1.2935 - val_accuracy: 0.5185 - val_loss: 1.1679\n",
      "Epoch 114/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5240 - loss: 1.2469 - val_accuracy: 0.5062 - val_loss: 1.1525\n",
      "Epoch 115/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4872 - loss: 1.2428 - val_accuracy: 0.5185 - val_loss: 1.1546\n",
      "Epoch 116/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5033 - loss: 1.2441 - val_accuracy: 0.5062 - val_loss: 1.1414\n",
      "Epoch 117/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5404 - loss: 1.2305 - val_accuracy: 0.4938 - val_loss: 1.1329\n",
      "Epoch 118/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5286 - loss: 1.1800 - val_accuracy: 0.5185 - val_loss: 1.1402\n",
      "Epoch 119/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4755 - loss: 1.2770 - val_accuracy: 0.5185 - val_loss: 1.1371\n",
      "Epoch 120/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5045 - loss: 1.2618 - val_accuracy: 0.5185 - val_loss: 1.1307\n",
      "Epoch 121/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4999 - loss: 1.2298 - val_accuracy: 0.5309 - val_loss: 1.1318\n",
      "Epoch 122/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5420 - loss: 1.1797 - val_accuracy: 0.5185 - val_loss: 1.1128\n",
      "Epoch 123/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5106 - loss: 1.2136 - val_accuracy: 0.5185 - val_loss: 1.1127\n",
      "Epoch 124/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5338 - loss: 1.2195 - val_accuracy: 0.5309 - val_loss: 1.1151\n",
      "Epoch 125/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5173 - loss: 1.1722 - val_accuracy: 0.5185 - val_loss: 1.1178\n",
      "Epoch 126/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5221 - loss: 1.1875 - val_accuracy: 0.5062 - val_loss: 1.1351\n",
      "Epoch 127/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5121 - loss: 1.2654 - val_accuracy: 0.5309 - val_loss: 1.0992\n",
      "Epoch 128/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5071 - loss: 1.1974 - val_accuracy: 0.5185 - val_loss: 1.0844\n",
      "Epoch 129/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5450 - loss: 1.1392 - val_accuracy: 0.5185 - val_loss: 1.0768\n",
      "Epoch 130/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5623 - loss: 1.1469 - val_accuracy: 0.5309 - val_loss: 1.0749\n",
      "Epoch 131/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5240 - loss: 1.1656 - val_accuracy: 0.5309 - val_loss: 1.0790\n",
      "Epoch 132/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5304 - loss: 1.1279 - val_accuracy: 0.5309 - val_loss: 1.0687\n",
      "Epoch 133/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5499 - loss: 1.1254 - val_accuracy: 0.5185 - val_loss: 1.0535\n",
      "Epoch 134/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5100 - loss: 1.1865 - val_accuracy: 0.5309 - val_loss: 1.0556\n",
      "Epoch 135/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5248 - loss: 1.1719 - val_accuracy: 0.5309 - val_loss: 1.0423\n",
      "Epoch 136/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5819 - loss: 1.0764 - val_accuracy: 0.5309 - val_loss: 1.0474\n",
      "Epoch 137/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5564 - loss: 1.1276 - val_accuracy: 0.5309 - val_loss: 1.0429\n",
      "Epoch 138/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5378 - loss: 1.1145 - val_accuracy: 0.5309 - val_loss: 1.0342\n",
      "Epoch 139/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5371 - loss: 1.1063 - val_accuracy: 0.5309 - val_loss: 1.0291\n",
      "Epoch 140/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5296 - loss: 1.1090 - val_accuracy: 0.5185 - val_loss: 1.0095\n",
      "Epoch 141/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4971 - loss: 1.1521 - val_accuracy: 0.5309 - val_loss: 1.0156\n",
      "Epoch 142/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5265 - loss: 1.1368 - val_accuracy: 0.5185 - val_loss: 1.0407\n",
      "Epoch 143/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5137 - loss: 1.0972 - val_accuracy: 0.5309 - val_loss: 1.0010\n",
      "Epoch 144/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5005 - loss: 1.1608 - val_accuracy: 0.5185 - val_loss: 1.0309\n",
      "Epoch 145/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5269 - loss: 1.1108 - val_accuracy: 0.5309 - val_loss: 0.9848\n",
      "Epoch 146/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5521 - loss: 1.0958 - val_accuracy: 0.5309 - val_loss: 0.9795\n",
      "Epoch 147/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5200 - loss: 1.0459 - val_accuracy: 0.5185 - val_loss: 1.0026\n",
      "Epoch 148/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5639 - loss: 1.0789 - val_accuracy: 0.5309 - val_loss: 0.9755\n",
      "Epoch 149/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5256 - loss: 1.0719 - val_accuracy: 0.5309 - val_loss: 0.9841\n",
      "Epoch 150/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5328 - loss: 1.1130 - val_accuracy: 0.5309 - val_loss: 0.9681\n",
      "Epoch 151/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5667 - loss: 1.0687 - val_accuracy: 0.5185 - val_loss: 0.9862\n",
      "Epoch 152/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5629 - loss: 1.0389 - val_accuracy: 0.5309 - val_loss: 0.9631\n",
      "Epoch 153/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5555 - loss: 1.0792 - val_accuracy: 0.5309 - val_loss: 0.9528\n",
      "Epoch 154/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5635 - loss: 1.0606 - val_accuracy: 0.5185 - val_loss: 0.9745\n",
      "Epoch 155/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6012 - loss: 0.9734 - val_accuracy: 0.5309 - val_loss: 0.9461\n",
      "Epoch 156/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5843 - loss: 0.9747 - val_accuracy: 0.5309 - val_loss: 0.9482\n",
      "Epoch 157/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5411 - loss: 1.0530 - val_accuracy: 0.5309 - val_loss: 0.9473\n",
      "Epoch 158/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5465 - loss: 1.0480 - val_accuracy: 0.5185 - val_loss: 0.9639\n",
      "Epoch 159/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4985 - loss: 1.0980 - val_accuracy: 0.5309 - val_loss: 0.9698\n",
      "Epoch 160/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5219 - loss: 1.1106 - val_accuracy: 0.5432 - val_loss: 0.9309\n",
      "Epoch 161/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5333 - loss: 1.0735 - val_accuracy: 0.5309 - val_loss: 0.9623\n",
      "Epoch 162/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5572 - loss: 1.0052 - val_accuracy: 0.5185 - val_loss: 0.9411\n",
      "Epoch 163/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5676 - loss: 1.0312 - val_accuracy: 0.5432 - val_loss: 0.9266\n",
      "Epoch 164/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5530 - loss: 1.0139 - val_accuracy: 0.5432 - val_loss: 0.9134\n",
      "Epoch 165/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5457 - loss: 1.0460 - val_accuracy: 0.5432 - val_loss: 0.9176\n",
      "Epoch 166/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5206 - loss: 1.0815 - val_accuracy: 0.5432 - val_loss: 0.9134\n",
      "Epoch 167/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6057 - loss: 0.9903 - val_accuracy: 0.5185 - val_loss: 0.9626\n",
      "Epoch 168/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5517 - loss: 1.0438 - val_accuracy: 0.5432 - val_loss: 0.9126\n",
      "Epoch 169/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5476 - loss: 1.0126 - val_accuracy: 0.5432 - val_loss: 0.9138\n",
      "Epoch 170/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5347 - loss: 1.0298 - val_accuracy: 0.5556 - val_loss: 0.8979\n",
      "Epoch 171/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6021 - loss: 0.9735 - val_accuracy: 0.5432 - val_loss: 0.8960\n",
      "Epoch 172/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5603 - loss: 0.9766 - val_accuracy: 0.5432 - val_loss: 0.9321\n",
      "Epoch 173/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5638 - loss: 0.9851 - val_accuracy: 0.5432 - val_loss: 0.8930\n",
      "Epoch 174/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5631 - loss: 1.0181 - val_accuracy: 0.5432 - val_loss: 0.8938\n",
      "Epoch 175/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5822 - loss: 0.9670 - val_accuracy: 0.5556 - val_loss: 0.8839\n",
      "Epoch 176/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5679 - loss: 0.9683 - val_accuracy: 0.5432 - val_loss: 0.8860\n",
      "Epoch 177/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5686 - loss: 1.0015 - val_accuracy: 0.5432 - val_loss: 0.8940\n",
      "Epoch 178/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5624 - loss: 0.9339 - val_accuracy: 0.5432 - val_loss: 0.8864\n",
      "Epoch 179/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5345 - loss: 1.0674 - val_accuracy: 0.5432 - val_loss: 0.8975\n",
      "Epoch 180/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5405 - loss: 1.0599 - val_accuracy: 0.5432 - val_loss: 0.8804\n",
      "Epoch 181/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5536 - loss: 1.0002 - val_accuracy: 0.5432 - val_loss: 0.9002\n",
      "Epoch 182/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6099 - loss: 0.9444 - val_accuracy: 0.5556 - val_loss: 0.8726\n",
      "Epoch 183/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6440 - loss: 0.9305 - val_accuracy: 0.5432 - val_loss: 0.8929\n",
      "Epoch 184/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5808 - loss: 0.9582 - val_accuracy: 0.5679 - val_loss: 0.8662\n",
      "Epoch 185/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5849 - loss: 0.9171 - val_accuracy: 0.5432 - val_loss: 0.8711\n",
      "Epoch 186/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5632 - loss: 0.9779 - val_accuracy: 0.5556 - val_loss: 0.8661\n",
      "Epoch 187/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5671 - loss: 0.9553 - val_accuracy: 0.5432 - val_loss: 0.8666\n",
      "Epoch 188/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5550 - loss: 0.9920 - val_accuracy: 0.5802 - val_loss: 0.8649\n",
      "Epoch 189/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6176 - loss: 0.9274 - val_accuracy: 0.5556 - val_loss: 0.8622\n",
      "Epoch 190/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5692 - loss: 0.9553 - val_accuracy: 0.5556 - val_loss: 0.8587\n",
      "Epoch 191/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5934 - loss: 0.9682 - val_accuracy: 0.5432 - val_loss: 0.8639\n",
      "Epoch 192/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5792 - loss: 0.9885 - val_accuracy: 0.5556 - val_loss: 0.8758\n",
      "Epoch 193/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5854 - loss: 0.9233 - val_accuracy: 0.5679 - val_loss: 0.8550\n",
      "Epoch 194/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5808 - loss: 0.8953 - val_accuracy: 0.5556 - val_loss: 0.8672\n",
      "Epoch 195/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5515 - loss: 0.9844 - val_accuracy: 0.5556 - val_loss: 0.8535\n",
      "Epoch 196/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5799 - loss: 0.9379 - val_accuracy: 0.5679 - val_loss: 0.8508\n",
      "Epoch 197/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5797 - loss: 0.9204 - val_accuracy: 0.5556 - val_loss: 0.8538\n",
      "Epoch 198/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6064 - loss: 0.8914 - val_accuracy: 0.5679 - val_loss: 0.8473\n",
      "Epoch 199/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6114 - loss: 0.8765 - val_accuracy: 0.5679 - val_loss: 0.8501\n",
      "Epoch 200/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5783 - loss: 0.9635 - val_accuracy: 0.5679 - val_loss: 0.8470\n",
      "Epoch 201/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5693 - loss: 0.9747 - val_accuracy: 0.5556 - val_loss: 0.8548\n",
      "Epoch 202/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5711 - loss: 0.9095 - val_accuracy: 0.5679 - val_loss: 0.8429\n",
      "Epoch 203/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5874 - loss: 0.9156 - val_accuracy: 0.5432 - val_loss: 0.8468\n",
      "Epoch 204/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5639 - loss: 0.9384 - val_accuracy: 0.5679 - val_loss: 0.8440\n",
      "Epoch 205/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5936 - loss: 0.9004 - val_accuracy: 0.5556 - val_loss: 0.8473\n",
      "Epoch 206/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6014 - loss: 0.9523 - val_accuracy: 0.5556 - val_loss: 0.8503\n",
      "Epoch 207/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5712 - loss: 0.9100 - val_accuracy: 0.5556 - val_loss: 0.8472\n",
      "Epoch 208/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5885 - loss: 0.9223 - val_accuracy: 0.5679 - val_loss: 0.8380\n",
      "Epoch 209/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6069 - loss: 0.9213 - val_accuracy: 0.5556 - val_loss: 0.8506\n",
      "Epoch 210/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5681 - loss: 0.8998 - val_accuracy: 0.5679 - val_loss: 0.8314\n",
      "Epoch 211/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5886 - loss: 0.9033 - val_accuracy: 0.5679 - val_loss: 0.8324\n",
      "Epoch 212/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5891 - loss: 0.9077 - val_accuracy: 0.5556 - val_loss: 0.8395\n",
      "Epoch 213/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5315 - loss: 0.9689 - val_accuracy: 0.5556 - val_loss: 0.8349\n",
      "Epoch 214/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5861 - loss: 0.8990 - val_accuracy: 0.5802 - val_loss: 0.8333\n",
      "Epoch 215/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6020 - loss: 0.8917 - val_accuracy: 0.5679 - val_loss: 0.8290\n",
      "Epoch 216/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5990 - loss: 0.8665 - val_accuracy: 0.5556 - val_loss: 0.8378\n",
      "Epoch 217/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5891 - loss: 0.9222 - val_accuracy: 0.5556 - val_loss: 0.8280\n",
      "Epoch 218/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5984 - loss: 0.9137 - val_accuracy: 0.5432 - val_loss: 0.8609\n",
      "Epoch 219/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5661 - loss: 0.9074 - val_accuracy: 0.5556 - val_loss: 0.8270\n",
      "Epoch 220/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5632 - loss: 0.9353 - val_accuracy: 0.5556 - val_loss: 0.8290\n",
      "Epoch 221/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5797 - loss: 0.9386 - val_accuracy: 0.5679 - val_loss: 0.8188\n",
      "Epoch 222/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5724 - loss: 0.9551 - val_accuracy: 0.5556 - val_loss: 0.8318\n",
      "Epoch 223/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6036 - loss: 0.8879 - val_accuracy: 0.5679 - val_loss: 0.8194\n",
      "Epoch 224/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5728 - loss: 0.9025 - val_accuracy: 0.5679 - val_loss: 0.8198\n",
      "Epoch 225/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5948 - loss: 0.9035 - val_accuracy: 0.5432 - val_loss: 0.8430\n",
      "Epoch 226/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6125 - loss: 0.8920 - val_accuracy: 0.5432 - val_loss: 0.8503\n",
      "Epoch 227/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6238 - loss: 0.8502 - val_accuracy: 0.5679 - val_loss: 0.8176\n",
      "Epoch 228/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5957 - loss: 0.8679 - val_accuracy: 0.5802 - val_loss: 0.8137\n",
      "Epoch 229/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5831 - loss: 0.8805 - val_accuracy: 0.5802 - val_loss: 0.8191\n",
      "Epoch 230/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5438 - loss: 0.9157 - val_accuracy: 0.5679 - val_loss: 0.8144\n",
      "Epoch 231/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5385 - loss: 0.8538 - val_accuracy: 0.5802 - val_loss: 0.8130\n",
      "Epoch 232/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5774 - loss: 0.9194 - val_accuracy: 0.5679 - val_loss: 0.8132\n",
      "Epoch 233/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5795 - loss: 0.8844 - val_accuracy: 0.5802 - val_loss: 0.8158\n",
      "Epoch 234/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5593 - loss: 0.9297 - val_accuracy: 0.5679 - val_loss: 0.8117\n",
      "Epoch 235/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6143 - loss: 0.8821 - val_accuracy: 0.5802 - val_loss: 0.8109\n",
      "Epoch 236/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5473 - loss: 0.9575 - val_accuracy: 0.5556 - val_loss: 0.8208\n",
      "Epoch 237/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5753 - loss: 0.8254 - val_accuracy: 0.5432 - val_loss: 0.8395\n",
      "Epoch 238/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6108 - loss: 0.8727 - val_accuracy: 0.5679 - val_loss: 0.8090\n",
      "Epoch 239/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5753 - loss: 0.8901 - val_accuracy: 0.5679 - val_loss: 0.8121\n",
      "Epoch 240/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5725 - loss: 0.8882 - val_accuracy: 0.5679 - val_loss: 0.8088\n",
      "Epoch 241/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6088 - loss: 0.8273 - val_accuracy: 0.5679 - val_loss: 0.8121\n",
      "Epoch 242/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6068 - loss: 0.8632 - val_accuracy: 0.5679 - val_loss: 0.8084\n",
      "Epoch 243/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5411 - loss: 0.8968 - val_accuracy: 0.5802 - val_loss: 0.8065\n",
      "Epoch 244/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5650 - loss: 0.8874 - val_accuracy: 0.5679 - val_loss: 0.8121\n",
      "Epoch 245/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5838 - loss: 0.8396 - val_accuracy: 0.5679 - val_loss: 0.8059\n",
      "Epoch 246/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6191 - loss: 0.8547 - val_accuracy: 0.5679 - val_loss: 0.8073\n",
      "Epoch 247/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6056 - loss: 0.8313 - val_accuracy: 0.5802 - val_loss: 0.8083\n",
      "Epoch 248/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6373 - loss: 0.8137 - val_accuracy: 0.5802 - val_loss: 0.8135\n",
      "Epoch 249/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5806 - loss: 0.9100 - val_accuracy: 0.5802 - val_loss: 0.8052\n",
      "Epoch 250/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5985 - loss: 0.8927 - val_accuracy: 0.5679 - val_loss: 0.8128\n",
      "Epoch 251/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5830 - loss: 0.8762 - val_accuracy: 0.5556 - val_loss: 0.8162\n",
      "Epoch 252/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6290 - loss: 0.8316 - val_accuracy: 0.5926 - val_loss: 0.8046\n",
      "Epoch 253/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5976 - loss: 0.8550 - val_accuracy: 0.5679 - val_loss: 0.8023\n",
      "Epoch 254/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5957 - loss: 0.8838 - val_accuracy: 0.5556 - val_loss: 0.8159\n",
      "Epoch 255/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5362 - loss: 0.8760 - val_accuracy: 0.5802 - val_loss: 0.7991\n",
      "Epoch 256/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5733 - loss: 0.8561 - val_accuracy: 0.5802 - val_loss: 0.8036\n",
      "Epoch 257/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6014 - loss: 0.8278 - val_accuracy: 0.5679 - val_loss: 0.8024\n",
      "Epoch 258/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6292 - loss: 0.8431 - val_accuracy: 0.5556 - val_loss: 0.8171\n",
      "Epoch 259/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5896 - loss: 0.8865 - val_accuracy: 0.5802 - val_loss: 0.8079\n",
      "Epoch 260/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5924 - loss: 0.8570 - val_accuracy: 0.5802 - val_loss: 0.8005\n",
      "Epoch 261/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5466 - loss: 0.9100 - val_accuracy: 0.5926 - val_loss: 0.7955\n",
      "Epoch 262/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5939 - loss: 0.8807 - val_accuracy: 0.5802 - val_loss: 0.8050\n",
      "Epoch 263/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5845 - loss: 0.8091 - val_accuracy: 0.5802 - val_loss: 0.7980\n",
      "Epoch 264/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5599 - loss: 0.8607 - val_accuracy: 0.5556 - val_loss: 0.8129\n",
      "Epoch 265/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5920 - loss: 0.8707 - val_accuracy: 0.5802 - val_loss: 0.8071\n",
      "Epoch 266/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5812 - loss: 0.8317 - val_accuracy: 0.5679 - val_loss: 0.7984\n",
      "Epoch 267/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5683 - loss: 0.8758 - val_accuracy: 0.5802 - val_loss: 0.7988\n",
      "Epoch 268/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5697 - loss: 0.8486 - val_accuracy: 0.5926 - val_loss: 0.7968\n",
      "Epoch 269/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5811 - loss: 0.8488 - val_accuracy: 0.5679 - val_loss: 0.8021\n",
      "Epoch 270/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6079 - loss: 0.8511 - val_accuracy: 0.5802 - val_loss: 0.7940\n",
      "Epoch 271/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5578 - loss: 0.8421 - val_accuracy: 0.5802 - val_loss: 0.7971\n",
      "Epoch 272/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5896 - loss: 0.8627 - val_accuracy: 0.5802 - val_loss: 0.7953\n",
      "Epoch 273/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6000 - loss: 0.8464 - val_accuracy: 0.5679 - val_loss: 0.7994\n",
      "Epoch 274/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5982 - loss: 0.8703 - val_accuracy: 0.5802 - val_loss: 0.7995\n",
      "Epoch 275/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5796 - loss: 0.8400 - val_accuracy: 0.5802 - val_loss: 0.7944\n",
      "Epoch 276/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6183 - loss: 0.8604 - val_accuracy: 0.5556 - val_loss: 0.8081\n",
      "Epoch 277/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6366 - loss: 0.7901 - val_accuracy: 0.5802 - val_loss: 0.7949\n",
      "Epoch 278/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6073 - loss: 0.9105 - val_accuracy: 0.5679 - val_loss: 0.8100\n",
      "Epoch 279/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5774 - loss: 0.9014 - val_accuracy: 0.5679 - val_loss: 0.7954\n",
      "Epoch 280/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5571 - loss: 0.8715 - val_accuracy: 0.5802 - val_loss: 0.7931\n",
      "Epoch 281/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5580 - loss: 0.8718 - val_accuracy: 0.5802 - val_loss: 0.8021\n",
      "Epoch 282/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5714 - loss: 0.8914 - val_accuracy: 0.5679 - val_loss: 0.7950\n",
      "Epoch 283/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5991 - loss: 0.8206 - val_accuracy: 0.5926 - val_loss: 0.7876\n",
      "Epoch 284/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5682 - loss: 0.8549 - val_accuracy: 0.5802 - val_loss: 0.7928\n",
      "Epoch 285/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5896 - loss: 0.8036 - val_accuracy: 0.5802 - val_loss: 0.7894\n",
      "Epoch 286/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6397 - loss: 0.8486 - val_accuracy: 0.5802 - val_loss: 0.7925\n",
      "Epoch 287/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6063 - loss: 0.8272 - val_accuracy: 0.5802 - val_loss: 0.7985\n",
      "Epoch 288/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6148 - loss: 0.8567 - val_accuracy: 0.5926 - val_loss: 0.7902\n",
      "Epoch 289/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5522 - loss: 0.8773 - val_accuracy: 0.5556 - val_loss: 0.8067\n",
      "Epoch 290/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5646 - loss: 0.9007 - val_accuracy: 0.5556 - val_loss: 0.8143\n",
      "Epoch 291/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6027 - loss: 0.8380 - val_accuracy: 0.5802 - val_loss: 0.7890\n",
      "Epoch 292/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5739 - loss: 0.8978 - val_accuracy: 0.5802 - val_loss: 0.7962\n",
      "Epoch 293/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5956 - loss: 0.8646 - val_accuracy: 0.5926 - val_loss: 0.7903\n",
      "Epoch 294/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6309 - loss: 0.7882 - val_accuracy: 0.5926 - val_loss: 0.7884\n",
      "Epoch 295/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6163 - loss: 0.7876 - val_accuracy: 0.5802 - val_loss: 0.8022\n",
      "Epoch 296/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6418 - loss: 0.8010 - val_accuracy: 0.5802 - val_loss: 0.7942\n",
      "Epoch 297/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6185 - loss: 0.8243 - val_accuracy: 0.5926 - val_loss: 0.7886\n",
      "Epoch 298/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5695 - loss: 0.8625 - val_accuracy: 0.5802 - val_loss: 0.7877\n",
      "Epoch 299/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5943 - loss: 0.8279 - val_accuracy: 0.5802 - val_loss: 0.7880\n",
      "Epoch 300/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6296 - loss: 0.8113 - val_accuracy: 0.5802 - val_loss: 0.7949\n",
      "Epoch 301/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5839 - loss: 0.8205 - val_accuracy: 0.5926 - val_loss: 0.7835\n",
      "Epoch 302/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6119 - loss: 0.8260 - val_accuracy: 0.5802 - val_loss: 0.7890\n",
      "Epoch 303/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5576 - loss: 0.8361 - val_accuracy: 0.5802 - val_loss: 0.7867\n",
      "Epoch 304/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5727 - loss: 0.8846 - val_accuracy: 0.5802 - val_loss: 0.7889\n",
      "Epoch 305/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6210 - loss: 0.8396 - val_accuracy: 0.5802 - val_loss: 0.7836\n",
      "Epoch 306/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6575 - loss: 0.8028 - val_accuracy: 0.5926 - val_loss: 0.7827\n",
      "Epoch 307/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6326 - loss: 0.8090 - val_accuracy: 0.5802 - val_loss: 0.7869\n",
      "Epoch 308/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6020 - loss: 0.8136 - val_accuracy: 0.5802 - val_loss: 0.7881\n",
      "Epoch 309/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5895 - loss: 0.8092 - val_accuracy: 0.5802 - val_loss: 0.7850\n",
      "Epoch 310/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5603 - loss: 0.8621 - val_accuracy: 0.5802 - val_loss: 0.7802\n",
      "Epoch 311/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6746 - loss: 0.7594 - val_accuracy: 0.5926 - val_loss: 0.7773\n",
      "Epoch 312/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6000 - loss: 0.7985 - val_accuracy: 0.5926 - val_loss: 0.7784\n",
      "Epoch 313/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6095 - loss: 0.8321 - val_accuracy: 0.5802 - val_loss: 0.7854\n",
      "Epoch 314/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6023 - loss: 0.8327 - val_accuracy: 0.5802 - val_loss: 0.7868\n",
      "Epoch 315/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6000 - loss: 0.7832 - val_accuracy: 0.5802 - val_loss: 0.7851\n",
      "Epoch 316/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5674 - loss: 0.8235 - val_accuracy: 0.5802 - val_loss: 0.7852\n",
      "Epoch 317/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5837 - loss: 0.8105 - val_accuracy: 0.5926 - val_loss: 0.7754\n",
      "Epoch 318/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6065 - loss: 0.8366 - val_accuracy: 0.5926 - val_loss: 0.7771\n",
      "Epoch 319/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5689 - loss: 0.8507 - val_accuracy: 0.5556 - val_loss: 0.8027\n",
      "Epoch 320/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5851 - loss: 0.8113 - val_accuracy: 0.5926 - val_loss: 0.7796\n",
      "Epoch 321/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6112 - loss: 0.7925 - val_accuracy: 0.5802 - val_loss: 0.7837\n",
      "Epoch 322/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5828 - loss: 0.8523 - val_accuracy: 0.5802 - val_loss: 0.7871\n",
      "Epoch 323/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6188 - loss: 0.8111 - val_accuracy: 0.5802 - val_loss: 0.7758\n",
      "Epoch 324/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6119 - loss: 0.8035 - val_accuracy: 0.5556 - val_loss: 0.7998\n",
      "Epoch 325/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5542 - loss: 0.8137 - val_accuracy: 0.5802 - val_loss: 0.7776\n",
      "Epoch 326/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6041 - loss: 0.8095 - val_accuracy: 0.5802 - val_loss: 0.7809\n",
      "Epoch 327/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6398 - loss: 0.8178 - val_accuracy: 0.6049 - val_loss: 0.7764\n",
      "Epoch 328/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6309 - loss: 0.7899 - val_accuracy: 0.5802 - val_loss: 0.7880\n",
      "Epoch 329/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6069 - loss: 0.8027 - val_accuracy: 0.5926 - val_loss: 0.7765\n",
      "Epoch 330/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6141 - loss: 0.7997 - val_accuracy: 0.5926 - val_loss: 0.7746\n",
      "Epoch 331/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5852 - loss: 0.8277 - val_accuracy: 0.5802 - val_loss: 0.7790\n",
      "Epoch 332/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6201 - loss: 0.8185 - val_accuracy: 0.5926 - val_loss: 0.7719\n",
      "Epoch 333/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6445 - loss: 0.8055 - val_accuracy: 0.5926 - val_loss: 0.7706\n",
      "Epoch 334/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5799 - loss: 0.8265 - val_accuracy: 0.5926 - val_loss: 0.7714\n",
      "Epoch 335/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6114 - loss: 0.7930 - val_accuracy: 0.5802 - val_loss: 0.7714\n",
      "Epoch 336/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5981 - loss: 0.8474 - val_accuracy: 0.5802 - val_loss: 0.7792\n",
      "Epoch 337/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6013 - loss: 0.8079 - val_accuracy: 0.5926 - val_loss: 0.7723\n",
      "Epoch 338/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5702 - loss: 0.8357 - val_accuracy: 0.5802 - val_loss: 0.7708\n",
      "Epoch 339/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5872 - loss: 0.7916 - val_accuracy: 0.5802 - val_loss: 0.7712\n",
      "Epoch 340/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6141 - loss: 0.8203 - val_accuracy: 0.5802 - val_loss: 0.7739\n",
      "Epoch 341/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5594 - loss: 0.8524 - val_accuracy: 0.5802 - val_loss: 0.7758\n",
      "Epoch 342/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6202 - loss: 0.7857 - val_accuracy: 0.5926 - val_loss: 0.7686\n",
      "Epoch 343/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5680 - loss: 0.8580 - val_accuracy: 0.5802 - val_loss: 0.7700\n",
      "Epoch 344/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5947 - loss: 0.8020 - val_accuracy: 0.5679 - val_loss: 0.7712\n",
      "Epoch 345/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6008 - loss: 0.7961 - val_accuracy: 0.5926 - val_loss: 0.7682\n",
      "Epoch 346/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6186 - loss: 0.8229 - val_accuracy: 0.6049 - val_loss: 0.7674\n",
      "Epoch 347/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6227 - loss: 0.8127 - val_accuracy: 0.5802 - val_loss: 0.7777\n",
      "Epoch 348/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6154 - loss: 0.8180 - val_accuracy: 0.5679 - val_loss: 0.7669\n",
      "Epoch 349/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6040 - loss: 0.8006 - val_accuracy: 0.5802 - val_loss: 0.7714\n",
      "Epoch 350/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6467 - loss: 0.8198 - val_accuracy: 0.5679 - val_loss: 0.7656\n",
      "Epoch 351/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5951 - loss: 0.8346 - val_accuracy: 0.5926 - val_loss: 0.7631\n",
      "Epoch 352/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6015 - loss: 0.7938 - val_accuracy: 0.5802 - val_loss: 0.7629\n",
      "Epoch 353/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6243 - loss: 0.8181 - val_accuracy: 0.5802 - val_loss: 0.7718\n",
      "Epoch 354/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5798 - loss: 0.8891 - val_accuracy: 0.6049 - val_loss: 0.7629\n",
      "Epoch 355/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5929 - loss: 0.8010 - val_accuracy: 0.5926 - val_loss: 0.7615\n",
      "Epoch 356/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6026 - loss: 0.8296 - val_accuracy: 0.5926 - val_loss: 0.7633\n",
      "Epoch 357/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5714 - loss: 0.8098 - val_accuracy: 0.6049 - val_loss: 0.7589\n",
      "Epoch 358/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5912 - loss: 0.7969 - val_accuracy: 0.5926 - val_loss: 0.7646\n",
      "Epoch 359/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6474 - loss: 0.7558 - val_accuracy: 0.5802 - val_loss: 0.7719\n",
      "Epoch 360/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6482 - loss: 0.7796 - val_accuracy: 0.5802 - val_loss: 0.7604\n",
      "Epoch 361/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5982 - loss: 0.8256 - val_accuracy: 0.5926 - val_loss: 0.7567\n",
      "Epoch 362/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5795 - loss: 0.8164 - val_accuracy: 0.5802 - val_loss: 0.7597\n",
      "Epoch 363/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5742 - loss: 0.8217 - val_accuracy: 0.5926 - val_loss: 0.7574\n",
      "Epoch 364/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6123 - loss: 0.8016 - val_accuracy: 0.5926 - val_loss: 0.7524\n",
      "Epoch 365/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5842 - loss: 0.8717 - val_accuracy: 0.5926 - val_loss: 0.7523\n",
      "Epoch 366/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6176 - loss: 0.7476 - val_accuracy: 0.5802 - val_loss: 0.7522\n",
      "Epoch 367/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5491 - loss: 0.8321 - val_accuracy: 0.5802 - val_loss: 0.7614\n",
      "Epoch 368/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6162 - loss: 0.7717 - val_accuracy: 0.5926 - val_loss: 0.7510\n",
      "Epoch 369/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5933 - loss: 0.8126 - val_accuracy: 0.5926 - val_loss: 0.7544\n",
      "Epoch 370/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5595 - loss: 0.7826 - val_accuracy: 0.6049 - val_loss: 0.7508\n",
      "Epoch 371/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6149 - loss: 0.7958 - val_accuracy: 0.5802 - val_loss: 0.7472\n",
      "Epoch 372/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6350 - loss: 0.7826 - val_accuracy: 0.5802 - val_loss: 0.7495\n",
      "Epoch 373/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5971 - loss: 0.7911 - val_accuracy: 0.6049 - val_loss: 0.7439\n",
      "Epoch 374/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6288 - loss: 0.7810 - val_accuracy: 0.5679 - val_loss: 0.7452\n",
      "Epoch 375/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6037 - loss: 0.7525 - val_accuracy: 0.5926 - val_loss: 0.7438\n",
      "Epoch 376/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5514 - loss: 0.8054 - val_accuracy: 0.5802 - val_loss: 0.7654\n",
      "Epoch 377/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5913 - loss: 0.8489 - val_accuracy: 0.5802 - val_loss: 0.7436\n",
      "Epoch 378/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5691 - loss: 0.7914 - val_accuracy: 0.5802 - val_loss: 0.7454\n",
      "Epoch 379/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5200 - loss: 0.8174 - val_accuracy: 0.5802 - val_loss: 0.7545\n",
      "Epoch 380/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5875 - loss: 0.7881 - val_accuracy: 0.5679 - val_loss: 0.7473\n",
      "Epoch 381/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6109 - loss: 0.7316 - val_accuracy: 0.5802 - val_loss: 0.7449\n",
      "Epoch 382/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6081 - loss: 0.7559 - val_accuracy: 0.5802 - val_loss: 0.7466\n",
      "Epoch 383/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6048 - loss: 0.8042 - val_accuracy: 0.5802 - val_loss: 0.7448\n",
      "Epoch 384/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6028 - loss: 0.7910 - val_accuracy: 0.5802 - val_loss: 0.7578\n",
      "Epoch 385/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5956 - loss: 0.7822 - val_accuracy: 0.6049 - val_loss: 0.7502\n",
      "Epoch 386/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5952 - loss: 0.7874 - val_accuracy: 0.6173 - val_loss: 0.7317\n",
      "Epoch 387/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6327 - loss: 0.7604 - val_accuracy: 0.6173 - val_loss: 0.7412\n",
      "Epoch 388/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6086 - loss: 0.7951 - val_accuracy: 0.6296 - val_loss: 0.7433\n",
      "Epoch 389/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5895 - loss: 0.8029 - val_accuracy: 0.6173 - val_loss: 0.7354\n",
      "Epoch 390/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5823 - loss: 0.7785 - val_accuracy: 0.6173 - val_loss: 0.7353\n",
      "Epoch 391/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6315 - loss: 0.7625 - val_accuracy: 0.5926 - val_loss: 0.7356\n",
      "Epoch 392/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6031 - loss: 0.7786 - val_accuracy: 0.6420 - val_loss: 0.7340\n",
      "Epoch 393/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6021 - loss: 0.7716 - val_accuracy: 0.5926 - val_loss: 0.7269\n",
      "Epoch 394/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5944 - loss: 0.8168 - val_accuracy: 0.6049 - val_loss: 0.7286\n",
      "Epoch 395/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6138 - loss: 0.7793 - val_accuracy: 0.6049 - val_loss: 0.7349\n",
      "Epoch 396/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6090 - loss: 0.7820 - val_accuracy: 0.6049 - val_loss: 0.7395\n",
      "Epoch 397/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6394 - loss: 0.7573 - val_accuracy: 0.6543 - val_loss: 0.7247\n",
      "Epoch 398/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6468 - loss: 0.7753 - val_accuracy: 0.6296 - val_loss: 0.7250\n",
      "Epoch 399/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5648 - loss: 0.8096 - val_accuracy: 0.6420 - val_loss: 0.7266\n",
      "Epoch 400/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6680 - loss: 0.7673 - val_accuracy: 0.6049 - val_loss: 0.7377\n",
      "Epoch 401/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6541 - loss: 0.7935 - val_accuracy: 0.6049 - val_loss: 0.7301\n",
      "Epoch 402/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5685 - loss: 0.8007 - val_accuracy: 0.6173 - val_loss: 0.7256\n",
      "Epoch 403/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6410 - loss: 0.7480 - val_accuracy: 0.6420 - val_loss: 0.7246\n",
      "Epoch 404/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5751 - loss: 0.7953 - val_accuracy: 0.6296 - val_loss: 0.7459\n",
      "Epoch 405/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5752 - loss: 0.8106 - val_accuracy: 0.6667 - val_loss: 0.7218\n",
      "Epoch 406/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6553 - loss: 0.7381 - val_accuracy: 0.6173 - val_loss: 0.7414\n",
      "Epoch 407/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6276 - loss: 0.7532 - val_accuracy: 0.6420 - val_loss: 0.7206\n",
      "Epoch 408/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6162 - loss: 0.7446 - val_accuracy: 0.6543 - val_loss: 0.7186\n",
      "Epoch 409/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5779 - loss: 0.8153 - val_accuracy: 0.6173 - val_loss: 0.7455\n",
      "Epoch 410/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6124 - loss: 0.7363 - val_accuracy: 0.6543 - val_loss: 0.7295\n",
      "Epoch 411/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5445 - loss: 0.8003 - val_accuracy: 0.6543 - val_loss: 0.7294\n",
      "Epoch 412/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6066 - loss: 0.7605 - val_accuracy: 0.6543 - val_loss: 0.7263\n",
      "Epoch 413/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5639 - loss: 0.7802 - val_accuracy: 0.6790 - val_loss: 0.7163\n",
      "Epoch 414/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5928 - loss: 0.7700 - val_accuracy: 0.6543 - val_loss: 0.7243\n",
      "Epoch 415/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6063 - loss: 0.7387 - val_accuracy: 0.6790 - val_loss: 0.7147\n",
      "Epoch 416/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6781 - loss: 0.7082 - val_accuracy: 0.6543 - val_loss: 0.7135\n",
      "Epoch 417/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5827 - loss: 0.7878 - val_accuracy: 0.6296 - val_loss: 0.7256\n",
      "Epoch 418/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5636 - loss: 0.8222 - val_accuracy: 0.6667 - val_loss: 0.7229\n",
      "Epoch 419/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6123 - loss: 0.7519 - val_accuracy: 0.6543 - val_loss: 0.7157\n",
      "Epoch 420/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5989 - loss: 0.7743 - val_accuracy: 0.6543 - val_loss: 0.7157\n",
      "Epoch 421/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6478 - loss: 0.7486 - val_accuracy: 0.6543 - val_loss: 0.7256\n",
      "Epoch 422/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6068 - loss: 0.7628 - val_accuracy: 0.6543 - val_loss: 0.7206\n",
      "Epoch 423/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5984 - loss: 0.7401 - val_accuracy: 0.6667 - val_loss: 0.7197\n",
      "Epoch 424/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5975 - loss: 0.7671 - val_accuracy: 0.6543 - val_loss: 0.7185\n",
      "Epoch 425/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5996 - loss: 0.7905 - val_accuracy: 0.6667 - val_loss: 0.7189\n",
      "Epoch 426/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5966 - loss: 0.7656 - val_accuracy: 0.6667 - val_loss: 0.7182\n",
      "Epoch 427/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6564 - loss: 0.7642 - val_accuracy: 0.6543 - val_loss: 0.7134\n",
      "Epoch 428/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5868 - loss: 0.7873 - val_accuracy: 0.6543 - val_loss: 0.7242\n",
      "Epoch 429/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5863 - loss: 0.7516 - val_accuracy: 0.6543 - val_loss: 0.7166\n",
      "Epoch 430/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6065 - loss: 0.7714 - val_accuracy: 0.6667 - val_loss: 0.7112\n",
      "Epoch 431/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6084 - loss: 0.7751 - val_accuracy: 0.6420 - val_loss: 0.7251\n",
      "Epoch 432/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6105 - loss: 0.7633 - val_accuracy: 0.6543 - val_loss: 0.7055\n",
      "Epoch 433/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6339 - loss: 0.7679 - val_accuracy: 0.6667 - val_loss: 0.7038\n",
      "Epoch 434/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5734 - loss: 0.7514 - val_accuracy: 0.6667 - val_loss: 0.7025\n",
      "Epoch 435/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6239 - loss: 0.7217 - val_accuracy: 0.6543 - val_loss: 0.7231\n",
      "Epoch 436/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6523 - loss: 0.7462 - val_accuracy: 0.6543 - val_loss: 0.7108\n",
      "Epoch 437/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5839 - loss: 0.7507 - val_accuracy: 0.6667 - val_loss: 0.7074\n",
      "Epoch 438/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5742 - loss: 0.8126 - val_accuracy: 0.6667 - val_loss: 0.7214\n",
      "Epoch 439/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6253 - loss: 0.7471 - val_accuracy: 0.6667 - val_loss: 0.7131\n",
      "Epoch 440/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6351 - loss: 0.7528 - val_accuracy: 0.6790 - val_loss: 0.7130\n",
      "Epoch 441/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5868 - loss: 0.7772 - val_accuracy: 0.6790 - val_loss: 0.7053\n",
      "Epoch 442/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5810 - loss: 0.7667 - val_accuracy: 0.6543 - val_loss: 0.7027\n",
      "Epoch 443/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6028 - loss: 0.7513 - val_accuracy: 0.6790 - val_loss: 0.7040\n",
      "Epoch 444/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6003 - loss: 0.7542 - val_accuracy: 0.6667 - val_loss: 0.6987\n",
      "Epoch 445/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5857 - loss: 0.7940 - val_accuracy: 0.6543 - val_loss: 0.7097\n",
      "Epoch 446/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6067 - loss: 0.7556 - val_accuracy: 0.6543 - val_loss: 0.6988\n",
      "Epoch 447/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5854 - loss: 0.7709 - val_accuracy: 0.6790 - val_loss: 0.7127\n",
      "Epoch 448/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5773 - loss: 0.8225 - val_accuracy: 0.6667 - val_loss: 0.7131\n",
      "Epoch 449/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6098 - loss: 0.7264 - val_accuracy: 0.6543 - val_loss: 0.7002\n",
      "Epoch 450/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6070 - loss: 0.7050 - val_accuracy: 0.6543 - val_loss: 0.7203\n",
      "Epoch 451/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5899 - loss: 0.7746 - val_accuracy: 0.6667 - val_loss: 0.6951\n",
      "Epoch 452/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6137 - loss: 0.7562 - val_accuracy: 0.6790 - val_loss: 0.6950\n",
      "Epoch 453/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5984 - loss: 0.7802 - val_accuracy: 0.6790 - val_loss: 0.7057\n",
      "Epoch 454/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6014 - loss: 0.7542 - val_accuracy: 0.6667 - val_loss: 0.6967\n",
      "Epoch 455/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5918 - loss: 0.7852 - val_accuracy: 0.6667 - val_loss: 0.7002\n",
      "Epoch 456/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6066 - loss: 0.7522 - val_accuracy: 0.6790 - val_loss: 0.6994\n",
      "Epoch 457/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6334 - loss: 0.7077 - val_accuracy: 0.6543 - val_loss: 0.6988\n",
      "Epoch 458/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6226 - loss: 0.7679 - val_accuracy: 0.6667 - val_loss: 0.7131\n",
      "Epoch 459/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6114 - loss: 0.7412 - val_accuracy: 0.6667 - val_loss: 0.6952\n",
      "Epoch 460/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6164 - loss: 0.7784 - val_accuracy: 0.6790 - val_loss: 0.7108\n",
      "Epoch 461/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6106 - loss: 0.7483 - val_accuracy: 0.6667 - val_loss: 0.6912\n",
      "Epoch 462/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6023 - loss: 0.7637 - val_accuracy: 0.6790 - val_loss: 0.6923\n",
      "Epoch 463/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6156 - loss: 0.7299 - val_accuracy: 0.6667 - val_loss: 0.7123\n",
      "Epoch 464/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6005 - loss: 0.7332 - val_accuracy: 0.6790 - val_loss: 0.6955\n",
      "Epoch 465/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6293 - loss: 0.7505 - val_accuracy: 0.6790 - val_loss: 0.6909\n",
      "Epoch 466/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6179 - loss: 0.7588 - val_accuracy: 0.6790 - val_loss: 0.6923\n",
      "Epoch 467/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6022 - loss: 0.7681 - val_accuracy: 0.6543 - val_loss: 0.7023\n",
      "Epoch 468/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6224 - loss: 0.7591 - val_accuracy: 0.6667 - val_loss: 0.6965\n",
      "Epoch 469/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6458 - loss: 0.7142 - val_accuracy: 0.6420 - val_loss: 0.6971\n",
      "Epoch 470/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5604 - loss: 0.7659 - val_accuracy: 0.6667 - val_loss: 0.6892\n",
      "Epoch 471/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6168 - loss: 0.7374 - val_accuracy: 0.6667 - val_loss: 0.6955\n",
      "Epoch 472/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6544 - loss: 0.6956 - val_accuracy: 0.6667 - val_loss: 0.6984\n",
      "Epoch 473/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5998 - loss: 0.7400 - val_accuracy: 0.6667 - val_loss: 0.6885\n",
      "Epoch 474/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6903 - loss: 0.6934 - val_accuracy: 0.6790 - val_loss: 0.6870\n",
      "Epoch 475/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6426 - loss: 0.7232 - val_accuracy: 0.6667 - val_loss: 0.6881\n",
      "Epoch 476/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6380 - loss: 0.7280 - val_accuracy: 0.6790 - val_loss: 0.7085\n",
      "Epoch 477/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6260 - loss: 0.7266 - val_accuracy: 0.6790 - val_loss: 0.6968\n",
      "Epoch 478/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6253 - loss: 0.7206 - val_accuracy: 0.6790 - val_loss: 0.7095\n",
      "Epoch 479/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5754 - loss: 0.7872 - val_accuracy: 0.6667 - val_loss: 0.6992\n",
      "Epoch 480/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5891 - loss: 0.8142 - val_accuracy: 0.6667 - val_loss: 0.7006\n",
      "Epoch 481/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6283 - loss: 0.7025 - val_accuracy: 0.6667 - val_loss: 0.6906\n",
      "Epoch 482/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6175 - loss: 0.7335 - val_accuracy: 0.6667 - val_loss: 0.6888\n",
      "Epoch 483/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5961 - loss: 0.7296 - val_accuracy: 0.6914 - val_loss: 0.7165\n",
      "Epoch 484/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6301 - loss: 0.7502 - val_accuracy: 0.6667 - val_loss: 0.6842\n",
      "Epoch 485/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6047 - loss: 0.7049 - val_accuracy: 0.6420 - val_loss: 0.6842\n",
      "Epoch 486/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6110 - loss: 0.7084 - val_accuracy: 0.6790 - val_loss: 0.6816\n",
      "Epoch 487/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6187 - loss: 0.7497 - val_accuracy: 0.6543 - val_loss: 0.6835\n",
      "Epoch 488/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5918 - loss: 0.7646 - val_accuracy: 0.6790 - val_loss: 0.6867\n",
      "Epoch 489/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6041 - loss: 0.7376 - val_accuracy: 0.6790 - val_loss: 0.6872\n",
      "Epoch 490/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6244 - loss: 0.7383 - val_accuracy: 0.6667 - val_loss: 0.6829\n",
      "Epoch 491/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6245 - loss: 0.7519 - val_accuracy: 0.6667 - val_loss: 0.7075\n",
      "Epoch 492/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5740 - loss: 0.7768 - val_accuracy: 0.6790 - val_loss: 0.7012\n",
      "Epoch 493/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5949 - loss: 0.7574 - val_accuracy: 0.6790 - val_loss: 0.6969\n",
      "Epoch 494/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6372 - loss: 0.6987 - val_accuracy: 0.6667 - val_loss: 0.6789\n",
      "Epoch 495/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6480 - loss: 0.7304 - val_accuracy: 0.6667 - val_loss: 0.6972\n",
      "Epoch 496/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6478 - loss: 0.7113 - val_accuracy: 0.6914 - val_loss: 0.6897\n",
      "Epoch 497/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6201 - loss: 0.7826 - val_accuracy: 0.6667 - val_loss: 0.6981\n",
      "Epoch 498/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6048 - loss: 0.7421 - val_accuracy: 0.6420 - val_loss: 0.6756\n",
      "Epoch 499/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5941 - loss: 0.7802 - val_accuracy: 0.6543 - val_loss: 0.6748\n",
      "Epoch 500/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6104 - loss: 0.7499 - val_accuracy: 0.6914 - val_loss: 0.6728\n",
      "Epoch 501/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5961 - loss: 0.7602 - val_accuracy: 0.6667 - val_loss: 0.6824\n",
      "Epoch 502/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6939 - loss: 0.7111 - val_accuracy: 0.6667 - val_loss: 0.6943\n",
      "Epoch 503/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5802 - loss: 0.7324 - val_accuracy: 0.6790 - val_loss: 0.6840\n",
      "Epoch 504/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6245 - loss: 0.7370 - val_accuracy: 0.6667 - val_loss: 0.6802\n",
      "Epoch 505/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6117 - loss: 0.7765 - val_accuracy: 0.6790 - val_loss: 0.7094\n",
      "Epoch 506/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5849 - loss: 0.7744 - val_accuracy: 0.6914 - val_loss: 0.7146\n",
      "Epoch 507/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5820 - loss: 0.7335 - val_accuracy: 0.6543 - val_loss: 0.6827\n",
      "Epoch 508/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5991 - loss: 0.7584 - val_accuracy: 0.6543 - val_loss: 0.6768\n",
      "Epoch 509/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6093 - loss: 0.7420 - val_accuracy: 0.6790 - val_loss: 0.6933\n",
      "Epoch 510/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6065 - loss: 0.7410 - val_accuracy: 0.6667 - val_loss: 0.6811\n",
      "Epoch 511/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5935 - loss: 0.7613 - val_accuracy: 0.6790 - val_loss: 0.7015\n",
      "Epoch 512/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6626 - loss: 0.7108 - val_accuracy: 0.6790 - val_loss: 0.6992\n",
      "Epoch 513/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6500 - loss: 0.6884 - val_accuracy: 0.6914 - val_loss: 0.6983\n",
      "Epoch 514/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5916 - loss: 0.7660 - val_accuracy: 0.6790 - val_loss: 0.6883\n",
      "Epoch 515/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5929 - loss: 0.7020 - val_accuracy: 0.6667 - val_loss: 0.6778\n",
      "Epoch 516/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6066 - loss: 0.7290 - val_accuracy: 0.6543 - val_loss: 0.6720\n",
      "Epoch 517/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5774 - loss: 0.7301 - val_accuracy: 0.6667 - val_loss: 0.6694\n",
      "Epoch 518/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5837 - loss: 0.7525 - val_accuracy: 0.6543 - val_loss: 0.6727\n",
      "Epoch 519/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6162 - loss: 0.7076 - val_accuracy: 0.6790 - val_loss: 0.6708\n",
      "Epoch 520/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5931 - loss: 0.7631 - val_accuracy: 0.6543 - val_loss: 0.6739\n",
      "Epoch 521/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6640 - loss: 0.6788 - val_accuracy: 0.6543 - val_loss: 0.6740\n",
      "Epoch 522/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6129 - loss: 0.7094 - val_accuracy: 0.6667 - val_loss: 0.6737\n",
      "Epoch 523/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5901 - loss: 0.7306 - val_accuracy: 0.6543 - val_loss: 0.6793\n",
      "Epoch 524/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6391 - loss: 0.7133 - val_accuracy: 0.6420 - val_loss: 0.6784\n",
      "Epoch 525/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6516 - loss: 0.6831 - val_accuracy: 0.6667 - val_loss: 0.6751\n",
      "Epoch 526/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6629 - loss: 0.7276 - val_accuracy: 0.6790 - val_loss: 0.6813\n",
      "Epoch 527/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6523 - loss: 0.6828 - val_accuracy: 0.6420 - val_loss: 0.6732\n",
      "Epoch 528/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6469 - loss: 0.7110 - val_accuracy: 0.6790 - val_loss: 0.6748\n",
      "Epoch 529/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6533 - loss: 0.7103 - val_accuracy: 0.6667 - val_loss: 0.6717\n",
      "Epoch 530/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6354 - loss: 0.7045 - val_accuracy: 0.6667 - val_loss: 0.6638\n",
      "Epoch 531/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6567 - loss: 0.7532 - val_accuracy: 0.6420 - val_loss: 0.6674\n",
      "Epoch 532/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6210 - loss: 0.7396 - val_accuracy: 0.6543 - val_loss: 0.6707\n",
      "Epoch 533/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6294 - loss: 0.7274 - val_accuracy: 0.6667 - val_loss: 0.6687\n",
      "Epoch 534/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6390 - loss: 0.6944 - val_accuracy: 0.6914 - val_loss: 0.6827\n",
      "Epoch 535/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6259 - loss: 0.7119 - val_accuracy: 0.6790 - val_loss: 0.6791\n",
      "Epoch 536/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6577 - loss: 0.6619 - val_accuracy: 0.6420 - val_loss: 0.6719\n",
      "Epoch 537/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6108 - loss: 0.7054 - val_accuracy: 0.6790 - val_loss: 0.6770\n",
      "Epoch 538/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5984 - loss: 0.7575 - val_accuracy: 0.6790 - val_loss: 0.6713\n",
      "Epoch 539/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6019 - loss: 0.7078 - val_accuracy: 0.6543 - val_loss: 0.6734\n",
      "Epoch 540/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5814 - loss: 0.7242 - val_accuracy: 0.6667 - val_loss: 0.6696\n",
      "Epoch 541/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5916 - loss: 0.7311 - val_accuracy: 0.6420 - val_loss: 0.6694\n",
      "Epoch 542/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6030 - loss: 0.6866 - val_accuracy: 0.6420 - val_loss: 0.6666\n",
      "Epoch 543/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6158 - loss: 0.7264 - val_accuracy: 0.6790 - val_loss: 0.6839\n",
      "Epoch 544/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6424 - loss: 0.7116 - val_accuracy: 0.6790 - val_loss: 0.6830\n",
      "Epoch 545/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6698 - loss: 0.6647 - val_accuracy: 0.6790 - val_loss: 0.6887\n",
      "Epoch 546/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6416 - loss: 0.7165 - val_accuracy: 0.6543 - val_loss: 0.6624\n",
      "Epoch 547/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6439 - loss: 0.7116 - val_accuracy: 0.6790 - val_loss: 0.6791\n",
      "Epoch 548/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6532 - loss: 0.6958 - val_accuracy: 0.6790 - val_loss: 0.6771\n",
      "Epoch 549/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6248 - loss: 0.7079 - val_accuracy: 0.6543 - val_loss: 0.6677\n",
      "Epoch 550/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5731 - loss: 0.7076 - val_accuracy: 0.6543 - val_loss: 0.6674\n",
      "Epoch 551/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6007 - loss: 0.7746 - val_accuracy: 0.6296 - val_loss: 0.6645\n",
      "Epoch 552/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6449 - loss: 0.7326 - val_accuracy: 0.6790 - val_loss: 0.6783\n",
      "Epoch 553/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6513 - loss: 0.7012 - val_accuracy: 0.6543 - val_loss: 0.6611\n",
      "Epoch 554/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6529 - loss: 0.6990 - val_accuracy: 0.6914 - val_loss: 0.6974\n",
      "Epoch 555/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6362 - loss: 0.7346 - val_accuracy: 0.6914 - val_loss: 0.7081\n",
      "Epoch 556/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6174 - loss: 0.7060 - val_accuracy: 0.6667 - val_loss: 0.6694\n",
      "Epoch 557/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5867 - loss: 0.7330 - val_accuracy: 0.6543 - val_loss: 0.6718\n",
      "Epoch 558/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5992 - loss: 0.7430 - val_accuracy: 0.6296 - val_loss: 0.6714\n",
      "Epoch 559/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5768 - loss: 0.7060 - val_accuracy: 0.7160 - val_loss: 0.7027\n",
      "Epoch 560/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6083 - loss: 0.7097 - val_accuracy: 0.6543 - val_loss: 0.6617\n",
      "Epoch 561/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5966 - loss: 0.7608 - val_accuracy: 0.6667 - val_loss: 0.6631\n",
      "Epoch 562/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6710 - loss: 0.6668 - val_accuracy: 0.6790 - val_loss: 0.6829\n",
      "Epoch 563/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5899 - loss: 0.7512 - val_accuracy: 0.6914 - val_loss: 0.6989\n",
      "Epoch 564/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6108 - loss: 0.7393 - val_accuracy: 0.6420 - val_loss: 0.6589\n",
      "Epoch 565/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6664 - loss: 0.6623 - val_accuracy: 0.6420 - val_loss: 0.6657\n",
      "Epoch 566/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6240 - loss: 0.6717 - val_accuracy: 0.6296 - val_loss: 0.6566\n",
      "Epoch 567/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6257 - loss: 0.7022 - val_accuracy: 0.6667 - val_loss: 0.6632\n",
      "Epoch 568/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6497 - loss: 0.7037 - val_accuracy: 0.6420 - val_loss: 0.6572\n",
      "Epoch 569/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6546 - loss: 0.6949 - val_accuracy: 0.6543 - val_loss: 0.6611\n",
      "Epoch 570/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5992 - loss: 0.7010 - val_accuracy: 0.6790 - val_loss: 0.6720\n",
      "Epoch 571/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6606 - loss: 0.6639 - val_accuracy: 0.7160 - val_loss: 0.6895\n",
      "Epoch 572/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6259 - loss: 0.6979 - val_accuracy: 0.6914 - val_loss: 0.6752\n",
      "Epoch 573/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6123 - loss: 0.7592 - val_accuracy: 0.6914 - val_loss: 0.6718\n",
      "Epoch 574/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6303 - loss: 0.7120 - val_accuracy: 0.6914 - val_loss: 0.6752\n",
      "Epoch 575/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5798 - loss: 0.7408 - val_accuracy: 0.6790 - val_loss: 0.6726\n",
      "Epoch 576/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6755 - loss: 0.6650 - val_accuracy: 0.6914 - val_loss: 0.6780\n",
      "Epoch 577/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6582 - loss: 0.7016 - val_accuracy: 0.6667 - val_loss: 0.6605\n",
      "Epoch 578/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6710 - loss: 0.6796 - val_accuracy: 0.6420 - val_loss: 0.6533\n",
      "Epoch 579/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5978 - loss: 0.6893 - val_accuracy: 0.7037 - val_loss: 0.6968\n",
      "Epoch 580/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6246 - loss: 0.7215 - val_accuracy: 0.7160 - val_loss: 0.6870\n",
      "Epoch 581/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6359 - loss: 0.7029 - val_accuracy: 0.6543 - val_loss: 0.6531\n",
      "Epoch 582/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5619 - loss: 0.7648 - val_accuracy: 0.6543 - val_loss: 0.6538\n",
      "Epoch 583/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6108 - loss: 0.7424 - val_accuracy: 0.6420 - val_loss: 0.6524\n",
      "Epoch 584/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6008 - loss: 0.7024 - val_accuracy: 0.6543 - val_loss: 0.6638\n",
      "Epoch 585/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5946 - loss: 0.7370 - val_accuracy: 0.7160 - val_loss: 0.6853\n",
      "Epoch 586/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5667 - loss: 0.7444 - val_accuracy: 0.7037 - val_loss: 0.6744\n",
      "Epoch 587/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5793 - loss: 0.7191 - val_accuracy: 0.7160 - val_loss: 0.6755\n",
      "Epoch 588/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6203 - loss: 0.7454 - val_accuracy: 0.6543 - val_loss: 0.6514\n",
      "Epoch 589/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5902 - loss: 0.7217 - val_accuracy: 0.6667 - val_loss: 0.6653\n",
      "Epoch 590/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6385 - loss: 0.6905 - val_accuracy: 0.7037 - val_loss: 0.6791\n",
      "Epoch 591/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6353 - loss: 0.6998 - val_accuracy: 0.6543 - val_loss: 0.6553\n",
      "Epoch 592/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6382 - loss: 0.7180 - val_accuracy: 0.6667 - val_loss: 0.6566\n",
      "Epoch 593/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6473 - loss: 0.7107 - val_accuracy: 0.6296 - val_loss: 0.6519\n",
      "Epoch 594/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5809 - loss: 0.7314 - val_accuracy: 0.6296 - val_loss: 0.6594\n",
      "Epoch 595/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6451 - loss: 0.7282 - val_accuracy: 0.7160 - val_loss: 0.6884\n",
      "Epoch 596/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5869 - loss: 0.7522 - val_accuracy: 0.6790 - val_loss: 0.6789\n",
      "Epoch 597/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6201 - loss: 0.6984 - val_accuracy: 0.7037 - val_loss: 0.6898\n",
      "Epoch 598/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6047 - loss: 0.7232 - val_accuracy: 0.6543 - val_loss: 0.6591\n",
      "Epoch 599/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6433 - loss: 0.6933 - val_accuracy: 0.6420 - val_loss: 0.6531\n",
      "Epoch 600/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6515 - loss: 0.6733 - val_accuracy: 0.6543 - val_loss: 0.6481\n",
      "Epoch 601/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6695 - loss: 0.6986 - val_accuracy: 0.7037 - val_loss: 0.6740\n",
      "Epoch 602/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6013 - loss: 0.6845 - val_accuracy: 0.6420 - val_loss: 0.6624\n",
      "Epoch 603/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6635 - loss: 0.6721 - val_accuracy: 0.7037 - val_loss: 0.6717\n",
      "Epoch 604/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6189 - loss: 0.7154 - val_accuracy: 0.6420 - val_loss: 0.6616\n",
      "Epoch 605/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6445 - loss: 0.6780 - val_accuracy: 0.6420 - val_loss: 0.6499\n",
      "Epoch 606/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6354 - loss: 0.6950 - val_accuracy: 0.6420 - val_loss: 0.6516\n",
      "Epoch 607/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5555 - loss: 0.7455 - val_accuracy: 0.6667 - val_loss: 0.6619\n",
      "Epoch 608/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6247 - loss: 0.7256 - val_accuracy: 0.6914 - val_loss: 0.6698\n",
      "Epoch 609/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6612 - loss: 0.6621 - val_accuracy: 0.6790 - val_loss: 0.6724\n",
      "Epoch 610/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6249 - loss: 0.7085 - val_accuracy: 0.6543 - val_loss: 0.6600\n",
      "Epoch 611/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6661 - loss: 0.6729 - val_accuracy: 0.6914 - val_loss: 0.6662\n",
      "Epoch 612/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6070 - loss: 0.7454 - val_accuracy: 0.6667 - val_loss: 0.6380\n",
      "Epoch 613/1000\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5961 - loss: 0.7387 - val_accuracy: 0.6667 - val_loss: 0.6399\n",
      "Epoch 614/1000\n",
      "\u001b[1m  1/130\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.6667 - loss: 0.4785"
     ]
    }
   ],
   "source": [
    "start = perf_counter()\n",
    "\n",
    "history = individual_model.fit(\n",
    "    np.hstack((x_traits_train, x_t_stress_train)),\n",
    "    yi_train,\n",
    "    epochs=600,\n",
    "    validation_data=(np.hstack((x_traits_val, x_t_stress_val)), yi_val),\n",
    "    batch_size=3,\n",
    "    # callbacks=[ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=30, min_lr=1e-5)]\n",
    ")\n",
    "\n",
    "print(perf_counter() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954d0a7d-c456-4afc-9bf2-111ac5f34f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(trait_cols, individual_model.weights[0].numpy().flatten()[1:])\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56db62db-e0a9-4d43-bc9b-af47a0f9508a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = individual_model.predict(np.hstack((x_traits_val, x_t_stress_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9303bc94-3acf-47d4-8735-598408e6e455",
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_pred.argmax(axis=1) == yi_val.argmax(axis=1)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cdab78-59cf-44d8-9a2a-944ea06ebd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "yi_val[~(y_pred.argmax(axis=1) == yi_val.argmax(axis=1))].argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3479a4d-3a9a-4b1f-997e-6546fef5370a",
   "metadata": {},
   "outputs": [],
   "source": [
    "((y_pred > .5) == yi_val).mean(axis=0), (~yi_val).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfccba8-a5fd-4bb2-83cf-cedd25ea4131",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = np.zeros((len(stresses), len(stresses)))\n",
    "\n",
    "for i1, s1 in enumerate(stresses):\n",
    "    for i2, s2 in enumerate(stresses):\n",
    "        prop = ((y_pred.argmax(axis=1) == i1) & (yi_val.argmax(axis=1) == i2)).mean()\n",
    "        confusion[i1,i2] = prop\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "cax = ax.matshow(confusion)\n",
    "ax.set_xticklabels([''] + stresses, rotation=90)\n",
    "ax.set_yticklabels([''] + stresses)\n",
    "fig.colorbar(cax)\n",
    "\n",
    "for (i, j), z in np.ndenumerate(confusion):\n",
    "    ax.text(j, i, '{:0.2f}'.format(z), ha='center', va='center')\n",
    "\n",
    "print(stresses)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d592e7-4e9e-45d4-8a4f-07f032c61009",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_pred = y_pred.argmax(axis=1)\n",
    "temp_real = yi_val.argmax(axis=1)\n",
    "temp_pred[temp_pred == 3] = 0\n",
    "temp_real[temp_real == 3] = 0\n",
    "\n",
    "(temp_pred == temp_real).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f1a489-226f-4cba-8fb5-171be48e1077",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.gca()\n",
    "\n",
    "ax.plot(history.history['loss'], label='Training')\n",
    "ax.plot(\n",
    "    np.convolve(np.array(history.history['val_loss']), np.ones(1)/1, mode='valid'),\n",
    "    label='Validation (Running Mean)'\n",
    ")\n",
    "ax.legend()\n",
    "ax.set_xlabel('# Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_ylim((0, 1))\n",
    "ax.set_title('Individual Loss over Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "2b3fef90-ef12-42d8-b114-00958cb796d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    }
   ],
   "source": [
    "sel_val_1 = (yi_val.sum(axis=1) <= 1).flatten()\n",
    "y_pred_1 = individual_model.predict(x_traits_val[sel_val_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "37a08ae0-9fed-4eb8-a313-dcb8a03e43d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6521739130434783"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_pred_1.argmax(axis=1) == yi_val[sel_val_1].argmax(axis=1)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d889a3-c0bb-4b21-825e-88143eb423e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
