{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee7e7b86-b977-47a5-ba5d-9ed2b1fdac0f",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8cb5ce0-f5b7-49f2-860c-77800a1c158e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import norm\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv1D, MaxPooling1D, Dense, Flatten, Input, AveragePooling1D, Dropout, Softmax, Layer\n",
    "from keras.optimizers import Adam, Nadam\n",
    "from keras.regularizers import L1, L2, Regularizer, L1L2\n",
    "from keras.callbacks import ReduceLROnPlateau, LearningRateScheduler, Callback, LambdaCallback\n",
    "from keras.metrics import Metric\n",
    "from keras import ops\n",
    "\n",
    "from time import perf_counter\n",
    "import functools\n",
    "import itertools\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4719d771-9fca-4e41-be72-bbea116b0c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "stresses = ['Gm', 'Drought', 'Nutrient_Deficiency', 'Fs', 'Salinity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "637f054d-6243-4486-9e3c-05af014aa535",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thead\\AppData\\Local\\Temp\\ipykernel_9104\\1297277926.py:2: DtypeWarning: Columns (2155) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_path)\n"
     ]
    }
   ],
   "source": [
    "csv_path = r'..\\combined.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True, errors='ignore')\n",
    "df.drop(columns=['Fungal_infection'], inplace=True, errors='ignore')\n",
    "df[stresses] = df[stresses].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "057ff01b-88c7-4b81-8760-b17477496043",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_cols = [col for col in df.columns if col[0] == 'X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57b48d75-9016-409e-afc8-abd0bece7eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "trait_cols = np.array(['Photo',\n",
    "       'Ci', 'Cond', 'CTleaf', 'Trmmol', 'WUEi', 'WUEin', 'Fv_Fm', 'Fv_Fo',\n",
    "       'PI', 'SLA', 'LWC', 'Suc', 'OP', 'OP100', 'RWC', 'WP', 'N', 'C',\n",
    "       'Neoxanthin', 'Violaxanthin', 'Lutein', 'Zeaxanthin', 'Chl_b', 'Chl_a',\n",
    "       'B_carotene', 'Glucose', 'Fructose', 'Sucrose', 'Sugars', 'Starch',\n",
    "       'Ellagic', 'Gal', 'Rut', 'CTs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdbdbf0-28db-4e5b-a4c9-12c4a1582ccb",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9e7ea95-2cdb-4dc5-b4a1-74ebf26662fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_res(x, blur_factor=10):\n",
    "    spec_x = x[:,:(x.shape[1]//blur_factor * blur_factor)]\n",
    "    blur_x = (spec_x.flatten()\n",
    "     .reshape((spec_x.shape[0] * spec_x.shape[1] // blur_factor, blur_factor))\n",
    "     .mean(axis=1)\n",
    "     .reshape((spec_x.shape[0], spec_x.shape[1] // blur_factor))\n",
    "    )\n",
    "\n",
    "    return blur_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d0cade06-cef6-4185-b862-f46b081b9672",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzy_win = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7cdde18c-6557-40d2-af1e-04a5dbdaa846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_reshape(x):\n",
    "    return x.reshape((-1, x.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a29192ca-70d1-4ccc-bf68-c14ca85d7cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "blur_factor = 2\n",
    "\n",
    "x_spec = df[spec_cols].values\n",
    "yb = df[stresses].values.any(axis=1)\n",
    "\n",
    "x_spec /= x_spec.max()\n",
    "\n",
    "x_spec_train, x_spec_val, yb_train, yb_val = train_test_split(x_spec, yb, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3ee9ee70-0f74-41fa-82ff-aad5f3c1b692",
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.cache\n",
    "def fuzzy_dx_init(shape, dtype=None):\n",
    "    half_shape = list(shape)\n",
    "    half_shape[0] //= 2\n",
    "    half_shape = tuple(half_shape)\n",
    "    return np.vstack((np.ones(half_shape) * -1/half_shape[0], np.ones(half_shape)/half_shape[0]))\n",
    "\n",
    "dropout_k = .0\n",
    "max_pool_k = 1\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Input(shape=(x_spec_train.shape[1],1)),\n",
    "    Conv1D(1, fuzzy_win*2, trainable=False, kernel_initializer=fuzzy_dx_init),\n",
    "    # Conv1D(1, fuzzy_win*2, trainable=False, kernel_initializer=fuzzy_dx_init),\n",
    "    # Conv1D(1, fuzzy_win*2, trainable=False, kernel_initializer=fuzzy_dx_init),\n",
    "    AveragePooling1D(blur_factor),\n",
    "    Conv1D(20, 5, kernel_regularizer=L2(.00), activation='relu'),\n",
    "    Dropout(dropout_k),\n",
    "    MaxPooling1D(max_pool_k),\n",
    "    Conv1D(20, 5, kernel_regularizer=L2(.00), activation='relu'),\n",
    "    Dropout(dropout_k),\n",
    "    MaxPooling1D(max_pool_k),\n",
    "    Conv1D(20, 5, kernel_regularizer=L2(.00), activation='relu'),\n",
    "    Dropout(dropout_k),\n",
    "    MaxPooling1D(max_pool_k),\n",
    "    Conv1D(20, 5, kernel_regularizer=L2(.00), activation='relu'),\n",
    "    Dropout(dropout_k),\n",
    "    MaxPooling1D(max_pool_k),\n",
    "    Conv1D(20, 5, kernel_regularizer=L2(.00), activation='relu'),\n",
    "    Dropout(dropout_k),\n",
    "    MaxPooling1D(max_pool_k),\n",
    "    Conv1D(20, 5, kernel_regularizer=L2(.00), activation='relu'),\n",
    "    Dropout(dropout_k),\n",
    "    MaxPooling1D(max_pool_k),\n",
    "    Conv1D(20, 5, kernel_regularizer=L2(.00), activation='relu'),\n",
    "    Dropout(dropout_k),\n",
    "    MaxPooling1D(max_pool_k),\n",
    "    Conv1D(20, 5, kernel_regularizer=L2(.00), activation='relu'),\n",
    "    Dropout(dropout_k),\n",
    "    MaxPooling1D(max_pool_k),\n",
    "    Conv1D(20, 5, kernel_regularizer=L2(.00), activation='relu'),\n",
    "    Dropout(dropout_k),\n",
    "    MaxPooling1D(max_pool_k),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(dropout_k),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(dropout_k),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(dropout_k),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(dropout_k),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(dropout_k),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(dropout_k),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(dropout_k),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer=Nadam(1e-4), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "185139d4-a6f9-43ae-99ad-e0fb08680a55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - accuracy: 0.2500 - loss: 0.6932 - val_accuracy: 0.6667 - val_loss: 0.6930\n",
      "Epoch 2/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.7500 - loss: 0.6929 - val_accuracy: 0.6667 - val_loss: 0.6927\n",
      "Epoch 3/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.7500 - loss: 0.6925 - val_accuracy: 0.6667 - val_loss: 0.6925\n",
      "Epoch 4/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.7500 - loss: 0.6921 - val_accuracy: 0.6667 - val_loss: 0.6921\n",
      "Epoch 5/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.7500 - loss: 0.6916 - val_accuracy: 0.6667 - val_loss: 0.6917\n",
      "Epoch 6/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.7500 - loss: 0.6909 - val_accuracy: 0.6667 - val_loss: 0.6910\n",
      "Epoch 7/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.7500 - loss: 0.6899 - val_accuracy: 0.6667 - val_loss: 0.6901\n",
      "Epoch 8/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.7500 - loss: 0.6885 - val_accuracy: 0.6667 - val_loss: 0.6889\n",
      "Epoch 9/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.7500 - loss: 0.6868 - val_accuracy: 0.6667 - val_loss: 0.6873\n",
      "Epoch 10/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.7500 - loss: 0.6843 - val_accuracy: 0.6667 - val_loss: 0.6851\n",
      "Epoch 11/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.7500 - loss: 0.6810 - val_accuracy: 0.6667 - val_loss: 0.6823\n",
      "Epoch 12/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.7500 - loss: 0.6766 - val_accuracy: 0.6667 - val_loss: 0.6786\n",
      "Epoch 13/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.7500 - loss: 0.6707 - val_accuracy: 0.6667 - val_loss: 0.6738\n",
      "Epoch 14/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.7500 - loss: 0.6631 - val_accuracy: 0.6667 - val_loss: 0.6681\n",
      "Epoch 15/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.7500 - loss: 0.6536 - val_accuracy: 0.6667 - val_loss: 0.6614\n",
      "Epoch 16/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.7500 - loss: 0.6422 - val_accuracy: 0.6667 - val_loss: 0.6540\n",
      "Epoch 17/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.7500 - loss: 0.6287 - val_accuracy: 0.6667 - val_loss: 0.6467\n",
      "Epoch 18/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.7500 - loss: 0.6138 - val_accuracy: 0.6667 - val_loss: 0.6405\n",
      "Epoch 19/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.7500 - loss: 0.5983 - val_accuracy: 0.6667 - val_loss: 0.6369\n",
      "Epoch 20/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.7500 - loss: 0.5837 - val_accuracy: 0.6667 - val_loss: 0.6375\n",
      "Epoch 21/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.7500 - loss: 0.5718 - val_accuracy: 0.6667 - val_loss: 0.6435\n",
      "Epoch 22/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.7500 - loss: 0.5643 - val_accuracy: 0.6667 - val_loss: 0.6540\n",
      "Epoch 23/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.7500 - loss: 0.5621 - val_accuracy: 0.6667 - val_loss: 0.6651\n",
      "Epoch 24/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 0.7500 - loss: 0.5633 - val_accuracy: 0.6667 - val_loss: 0.6720\n",
      "Epoch 25/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.7500 - loss: 0.5650 - val_accuracy: 0.6667 - val_loss: 0.6736\n",
      "Epoch 26/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.7500 - loss: 0.5654 - val_accuracy: 0.6667 - val_loss: 0.6717\n",
      "Epoch 27/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.7500 - loss: 0.5649 - val_accuracy: 0.6667 - val_loss: 0.6682\n",
      "Epoch 28/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.7500 - loss: 0.5640 - val_accuracy: 0.6667 - val_loss: 0.6645\n",
      "Epoch 29/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.7500 - loss: 0.5632 - val_accuracy: 0.6667 - val_loss: 0.6609\n",
      "Epoch 30/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.7500 - loss: 0.5625 - val_accuracy: 0.6667 - val_loss: 0.6580\n",
      "Epoch 31/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.7500 - loss: 0.5622 - val_accuracy: 0.6667 - val_loss: 0.6556\n",
      "Epoch 32/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.7500 - loss: 0.5620 - val_accuracy: 0.6667 - val_loss: 0.6540\n",
      "Epoch 33/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.7500 - loss: 0.5620 - val_accuracy: 0.6667 - val_loss: 0.6530\n",
      "Epoch 34/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.7500 - loss: 0.5620 - val_accuracy: 0.6667 - val_loss: 0.6525\n",
      "Epoch 35/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.7500 - loss: 0.5620 - val_accuracy: 0.6667 - val_loss: 0.6523\n",
      "Epoch 36/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.7500 - loss: 0.5620 - val_accuracy: 0.6667 - val_loss: 0.6525\n",
      "Epoch 37/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.7500 - loss: 0.5620 - val_accuracy: 0.6667 - val_loss: 0.6529\n",
      "Epoch 38/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.7500 - loss: 0.5620 - val_accuracy: 0.6667 - val_loss: 0.6532\n",
      "Epoch 39/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.7500 - loss: 0.5619 - val_accuracy: 0.6667 - val_loss: 0.6536\n",
      "Epoch 40/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.7500 - loss: 0.5619 - val_accuracy: 0.6667 - val_loss: 0.6540\n",
      "Epoch 41/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.7500 - loss: 0.5619 - val_accuracy: 0.6667 - val_loss: 0.6542\n",
      "Epoch 42/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.7500 - loss: 0.5619 - val_accuracy: 0.6667 - val_loss: 0.6543\n",
      "Epoch 43/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.7500 - loss: 0.5619 - val_accuracy: 0.6667 - val_loss: 0.6544\n",
      "Epoch 44/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.7500 - loss: 0.5619 - val_accuracy: 0.6667 - val_loss: 0.6543\n",
      "Epoch 45/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 0.7500 - loss: 0.5619 - val_accuracy: 0.6667 - val_loss: 0.6543\n",
      "Epoch 46/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.7500 - loss: 0.5619 - val_accuracy: 0.6667 - val_loss: 0.6543\n",
      "Epoch 47/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 0.7500 - loss: 0.5619 - val_accuracy: 0.6667 - val_loss: 0.6542\n",
      "Epoch 48/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.7500 - loss: 0.5619 - val_accuracy: 0.6667 - val_loss: 0.6542\n",
      "Epoch 49/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.7500 - loss: 0.5618 - val_accuracy: 0.6667 - val_loss: 0.6541\n",
      "Epoch 50/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.7500 - loss: 0.5618 - val_accuracy: 0.6667 - val_loss: 0.6541\n",
      "Epoch 51/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.7500 - loss: 0.5618 - val_accuracy: 0.6667 - val_loss: 0.6541\n",
      "Epoch 52/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.7500 - loss: 0.5618 - val_accuracy: 0.6667 - val_loss: 0.6541\n",
      "Epoch 53/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.7500 - loss: 0.5618 - val_accuracy: 0.6667 - val_loss: 0.6541\n",
      "Epoch 54/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.7500 - loss: 0.5618 - val_accuracy: 0.6667 - val_loss: 0.6541\n",
      "Epoch 55/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 0.7500 - loss: 0.5618 - val_accuracy: 0.6667 - val_loss: 0.6542\n",
      "Epoch 56/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.7500 - loss: 0.5618 - val_accuracy: 0.6667 - val_loss: 0.6542\n",
      "Epoch 57/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.7500 - loss: 0.5617 - val_accuracy: 0.6667 - val_loss: 0.6542\n",
      "Epoch 58/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.7500 - loss: 0.5617 - val_accuracy: 0.6667 - val_loss: 0.6542\n",
      "Epoch 59/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.7500 - loss: 0.5617 - val_accuracy: 0.6667 - val_loss: 0.6542\n",
      "Epoch 60/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - accuracy: 0.7500 - loss: 0.5617 - val_accuracy: 0.6667 - val_loss: 0.6542\n",
      "Epoch 61/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.7500 - loss: 0.5617 - val_accuracy: 0.6667 - val_loss: 0.6542\n",
      "Epoch 62/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.7500 - loss: 0.5617 - val_accuracy: 0.6667 - val_loss: 0.6542\n",
      "Epoch 63/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.7500 - loss: 0.5617 - val_accuracy: 0.6667 - val_loss: 0.6542\n",
      "Epoch 64/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 0.7500 - loss: 0.5616 - val_accuracy: 0.6667 - val_loss: 0.6542\n",
      "Epoch 65/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.7500 - loss: 0.5616 - val_accuracy: 0.6667 - val_loss: 0.6542\n",
      "Epoch 66/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.7500 - loss: 0.5616 - val_accuracy: 0.6667 - val_loss: 0.6542\n",
      "Epoch 67/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.7500 - loss: 0.5616 - val_accuracy: 0.6667 - val_loss: 0.6543\n",
      "Epoch 68/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.7500 - loss: 0.5616 - val_accuracy: 0.6667 - val_loss: 0.6543\n",
      "Epoch 69/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - accuracy: 0.7500 - loss: 0.5616 - val_accuracy: 0.6667 - val_loss: 0.6543\n",
      "Epoch 70/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.7500 - loss: 0.5615 - val_accuracy: 0.6667 - val_loss: 0.6543\n",
      "Epoch 71/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.7500 - loss: 0.5615 - val_accuracy: 0.6667 - val_loss: 0.6543\n",
      "Epoch 72/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.7500 - loss: 0.5615 - val_accuracy: 0.6667 - val_loss: 0.6543\n",
      "Epoch 73/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.7500 - loss: 0.5615 - val_accuracy: 0.6667 - val_loss: 0.6543\n",
      "Epoch 74/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.7500 - loss: 0.5614 - val_accuracy: 0.6667 - val_loss: 0.6544\n",
      "Epoch 75/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.7500 - loss: 0.5614 - val_accuracy: 0.6667 - val_loss: 0.6544\n",
      "Epoch 76/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.7500 - loss: 0.5614 - val_accuracy: 0.6667 - val_loss: 0.6544\n",
      "Epoch 77/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.7500 - loss: 0.5614 - val_accuracy: 0.6667 - val_loss: 0.6544\n",
      "Epoch 78/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.7500 - loss: 0.5613 - val_accuracy: 0.6667 - val_loss: 0.6544\n",
      "Epoch 79/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.7500 - loss: 0.5613 - val_accuracy: 0.6667 - val_loss: 0.6544\n",
      "Epoch 80/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.7500 - loss: 0.5613 - val_accuracy: 0.6667 - val_loss: 0.6544\n",
      "Epoch 81/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.7500 - loss: 0.5612 - val_accuracy: 0.6667 - val_loss: 0.6545\n",
      "Epoch 82/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.7500 - loss: 0.5612 - val_accuracy: 0.6667 - val_loss: 0.6545\n",
      "Epoch 83/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.7500 - loss: 0.5612 - val_accuracy: 0.6667 - val_loss: 0.6545\n",
      "Epoch 84/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.7500 - loss: 0.5611 - val_accuracy: 0.6667 - val_loss: 0.6545\n",
      "Epoch 85/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.7500 - loss: 0.5611 - val_accuracy: 0.6667 - val_loss: 0.6545\n",
      "Epoch 86/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.7500 - loss: 0.5611 - val_accuracy: 0.6667 - val_loss: 0.6545\n",
      "Epoch 87/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.7500 - loss: 0.5610 - val_accuracy: 0.6667 - val_loss: 0.6546\n",
      "Epoch 88/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.7500 - loss: 0.5610 - val_accuracy: 0.6667 - val_loss: 0.6546\n",
      "Epoch 89/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.7500 - loss: 0.5609 - val_accuracy: 0.6667 - val_loss: 0.6546\n",
      "Epoch 90/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 0.7500 - loss: 0.5609 - val_accuracy: 0.6667 - val_loss: 0.6547\n",
      "Epoch 91/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.7500 - loss: 0.5608 - val_accuracy: 0.6667 - val_loss: 0.6547\n",
      "Epoch 92/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.7500 - loss: 0.5608 - val_accuracy: 0.6667 - val_loss: 0.6547\n",
      "Epoch 93/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.7500 - loss: 0.5607 - val_accuracy: 0.6667 - val_loss: 0.6547\n",
      "Epoch 94/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.7500 - loss: 0.5607 - val_accuracy: 0.6667 - val_loss: 0.6548\n",
      "Epoch 95/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - accuracy: 0.7500 - loss: 0.5606 - val_accuracy: 0.6667 - val_loss: 0.6548\n",
      "Epoch 96/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.7500 - loss: 0.5605 - val_accuracy: 0.6667 - val_loss: 0.6547\n",
      "Epoch 97/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.7500 - loss: 0.5605 - val_accuracy: 0.6667 - val_loss: 0.6547\n",
      "Epoch 98/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.7500 - loss: 0.5604 - val_accuracy: 0.6667 - val_loss: 0.6548\n",
      "Epoch 99/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.7500 - loss: 0.5603 - val_accuracy: 0.6667 - val_loss: 0.6547\n",
      "Epoch 100/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.7500 - loss: 0.5602 - val_accuracy: 0.6667 - val_loss: 0.6549\n",
      "Epoch 101/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.7500 - loss: 0.5601 - val_accuracy: 0.6667 - val_loss: 0.6550\n",
      "Epoch 102/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.7500 - loss: 0.5600 - val_accuracy: 0.6667 - val_loss: 0.6551\n",
      "Epoch 103/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.7500 - loss: 0.5599 - val_accuracy: 0.6667 - val_loss: 0.6552\n",
      "Epoch 104/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 0.7500 - loss: 0.5598 - val_accuracy: 0.6667 - val_loss: 0.6552\n",
      "Epoch 105/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.7500 - loss: 0.5597 - val_accuracy: 0.6667 - val_loss: 0.6552\n",
      "Epoch 106/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 0.7500 - loss: 0.5596 - val_accuracy: 0.6667 - val_loss: 0.6551\n",
      "Epoch 107/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.7500 - loss: 0.5594 - val_accuracy: 0.6667 - val_loss: 0.6555\n",
      "Epoch 108/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - accuracy: 0.7500 - loss: 0.5593 - val_accuracy: 0.6667 - val_loss: 0.6556\n",
      "Epoch 109/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.7500 - loss: 0.5591 - val_accuracy: 0.6667 - val_loss: 0.6556\n",
      "Epoch 110/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.7500 - loss: 0.5589 - val_accuracy: 0.6667 - val_loss: 0.6557\n",
      "Epoch 111/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.7500 - loss: 0.5587 - val_accuracy: 0.6667 - val_loss: 0.6558\n",
      "Epoch 112/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.7500 - loss: 0.5585 - val_accuracy: 0.6667 - val_loss: 0.6556\n",
      "Epoch 113/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.7500 - loss: 0.5583 - val_accuracy: 0.6667 - val_loss: 0.6559\n",
      "Epoch 114/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.7500 - loss: 0.5580 - val_accuracy: 0.6667 - val_loss: 0.6562\n",
      "Epoch 115/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.7500 - loss: 0.5578 - val_accuracy: 0.6667 - val_loss: 0.6563\n",
      "Epoch 116/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.7500 - loss: 0.5575 - val_accuracy: 0.6667 - val_loss: 0.6563\n",
      "Epoch 117/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.7500 - loss: 0.5571 - val_accuracy: 0.6667 - val_loss: 0.6562\n",
      "Epoch 118/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.7500 - loss: 0.5567 - val_accuracy: 0.6667 - val_loss: 0.6569\n",
      "Epoch 119/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.7500 - loss: 0.5563 - val_accuracy: 0.6667 - val_loss: 0.6571\n",
      "Epoch 120/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.7500 - loss: 0.5558 - val_accuracy: 0.6667 - val_loss: 0.6570\n",
      "Epoch 121/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.7500 - loss: 0.5553 - val_accuracy: 0.6667 - val_loss: 0.6573\n",
      "Epoch 122/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.7500 - loss: 0.5548 - val_accuracy: 0.6667 - val_loss: 0.6578\n",
      "Epoch 123/400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.7500 - loss: 0.5541"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m start \u001b[38;5;241m=\u001b[39m perf_counter()\n\u001b[1;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mcnn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcnn_reshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_spec_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43myb_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcnn_reshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_spec_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(perf_counter() \u001b[38;5;241m-\u001b[39m start)\n",
      "File \u001b[1;32m~\\.virtualenvs\\stress_prediction-gwCXE-ib\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\.virtualenvs\\stress_prediction-gwCXE-ib\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:345\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_epoch_iterator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_epoch_iterator \u001b[38;5;241m=\u001b[39m TFEpochIterator(\n\u001b[0;32m    336\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m    337\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    343\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    344\u001b[0m     )\n\u001b[1;32m--> 345\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    355\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    357\u001b[0m }\n\u001b[0;32m    358\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32m~\\.virtualenvs\\stress_prediction-gwCXE-ib\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\.virtualenvs\\stress_prediction-gwCXE-ib\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:433\u001b[0m, in \u001b[0;36mTensorFlowTrainer.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    432\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m--> 433\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    434\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    435\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_end(step, logs)\n",
      "File \u001b[1;32m~\\.virtualenvs\\stress_prediction-gwCXE-ib\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\.virtualenvs\\stress_prediction-gwCXE-ib\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\.virtualenvs\\stress_prediction-gwCXE-ib\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\.virtualenvs\\stress_prediction-gwCXE-ib\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.virtualenvs\\stress_prediction-gwCXE-ib\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\.virtualenvs\\stress_prediction-gwCXE-ib\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\.virtualenvs\\stress_prediction-gwCXE-ib\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\.virtualenvs\\stress_prediction-gwCXE-ib\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1567\u001b[0m   )\n",
      "File \u001b[1;32m~\\.virtualenvs\\stress_prediction-gwCXE-ib\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = perf_counter()\n",
    "\n",
    "history = cnn_model.fit(\n",
    "    cnn_reshape(x_spec_train[:20]),\n",
    "    yb_train[:20],\n",
    "    epochs=400,\n",
    "    validation_data=(cnn_reshape(x_spec_val), yb_val),\n",
    "    batch_size=200,\n",
    ")\n",
    "\n",
    "print(perf_counter() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f27b2a-5df1-4db7-89f3-8b3c0c8f458b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.gca()\n",
    "\n",
    "ax.plot(history.history['loss'], label='Training')\n",
    "ax.plot(\n",
    "    np.convolve(np.array(history.history['val_loss']), np.ones(10)/10, mode='valid'),\n",
    "    label='Validation (Running Mean)'\n",
    ")\n",
    "ax.legend()\n",
    "ax.set_xlabel('# Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_ylim((0, 1))\n",
    "ax.set_title('CNN Loss over Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824e7187-f76b-4497-8bc2-ea41158e350a",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1a9f6f-c3a9-4110-a1e1-b5f33a8c0321",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c57e57a-d38d-4139-816a-a5c782ccd1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[trait_cols].values\n",
    "\n",
    "x = (x - x.min(axis=0))/(x.max(axis=0)-x.min(axis=0))\n",
    "y = df[stresses].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91903b08-6a6f-480b-bd03-37658cf63f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "782d0e80-26e2-481e-bae6-5ed6d3ecde3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "yb_train, yb_val = y_train.any(axis=1), y_val.any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffbeda64-aa36-49bb-ae0a-26163a85ede3",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb57fab-fde9-4ab9-8f46-a72c5b99bddc",
   "metadata": {},
   "source": [
    "##### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31c6cba1-d8e5-4747-8db5-6d787ebcb5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_aug = .6\n",
    "\n",
    "aug_sample = np.random.randint(low=0, high=x_train.shape[0], size=(20000,))\n",
    "x_train_aug = x_train[aug_sample]\n",
    "y_train_aug = y_train[aug_sample]\n",
    "\n",
    "x_train_aug += (\n",
    "    np.random.random_sample(size=x_train_aug.shape) * z_aug*x_train.std(axis=0) - .5*z_aug*x_train.std(axis=0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb178a3-b645-4344-a404-075ea4fe3390",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548aaadc-4f16-4a89-b024-79bf6d236884",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "cbfa097b-143d-49aa-8583-630b3afcc93a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.62817\n",
      "[1]\tvalidation_0-logloss:0.62629\n",
      "[2]\tvalidation_0-logloss:0.62446\n",
      "[3]\tvalidation_0-logloss:0.62306\n",
      "[4]\tvalidation_0-logloss:0.62128\n",
      "[5]\tvalidation_0-logloss:0.61989\n",
      "[6]\tvalidation_0-logloss:0.61842\n",
      "[7]\tvalidation_0-logloss:0.61682\n",
      "[8]\tvalidation_0-logloss:0.61509\n",
      "[9]\tvalidation_0-logloss:0.61367\n",
      "[10]\tvalidation_0-logloss:0.61235\n",
      "[11]\tvalidation_0-logloss:0.61077\n",
      "[12]\tvalidation_0-logloss:0.60958\n",
      "[13]\tvalidation_0-logloss:0.60802\n",
      "[14]\tvalidation_0-logloss:0.60657\n",
      "[15]\tvalidation_0-logloss:0.60532\n",
      "[16]\tvalidation_0-logloss:0.60391\n",
      "[17]\tvalidation_0-logloss:0.60268\n",
      "[18]\tvalidation_0-logloss:0.60147\n",
      "[19]\tvalidation_0-logloss:0.60024\n",
      "[20]\tvalidation_0-logloss:0.59908\n",
      "[21]\tvalidation_0-logloss:0.59785\n",
      "[22]\tvalidation_0-logloss:0.59673\n",
      "[23]\tvalidation_0-logloss:0.59555\n",
      "[24]\tvalidation_0-logloss:0.59449\n",
      "[25]\tvalidation_0-logloss:0.59338\n",
      "[26]\tvalidation_0-logloss:0.59233\n",
      "[27]\tvalidation_0-logloss:0.59169\n",
      "[28]\tvalidation_0-logloss:0.59067\n",
      "[29]\tvalidation_0-logloss:0.59006\n",
      "[30]\tvalidation_0-logloss:0.58961\n",
      "[31]\tvalidation_0-logloss:0.58857\n",
      "[32]\tvalidation_0-logloss:0.58761\n",
      "[33]\tvalidation_0-logloss:0.58720\n",
      "[34]\tvalidation_0-logloss:0.58621\n",
      "[35]\tvalidation_0-logloss:0.58582\n",
      "[36]\tvalidation_0-logloss:0.58502\n",
      "[37]\tvalidation_0-logloss:0.58446\n",
      "[38]\tvalidation_0-logloss:0.58358\n",
      "[39]\tvalidation_0-logloss:0.58269\n",
      "[40]\tvalidation_0-logloss:0.58182\n",
      "[41]\tvalidation_0-logloss:0.58073\n",
      "[42]\tvalidation_0-logloss:0.58013\n",
      "[43]\tvalidation_0-logloss:0.57943\n",
      "[44]\tvalidation_0-logloss:0.57863\n",
      "[45]\tvalidation_0-logloss:0.57783\n",
      "[46]\tvalidation_0-logloss:0.57703\n",
      "[47]\tvalidation_0-logloss:0.57632\n",
      "[48]\tvalidation_0-logloss:0.57574\n",
      "[49]\tvalidation_0-logloss:0.57496\n",
      "[50]\tvalidation_0-logloss:0.57441\n",
      "[51]\tvalidation_0-logloss:0.57367\n",
      "[52]\tvalidation_0-logloss:0.57301\n",
      "[53]\tvalidation_0-logloss:0.57223\n",
      "[54]\tvalidation_0-logloss:0.57160\n",
      "[55]\tvalidation_0-logloss:0.57088\n",
      "[56]\tvalidation_0-logloss:0.57042\n",
      "[57]\tvalidation_0-logloss:0.56963\n",
      "[58]\tvalidation_0-logloss:0.56892\n",
      "[59]\tvalidation_0-logloss:0.56813\n",
      "[60]\tvalidation_0-logloss:0.56741\n",
      "[61]\tvalidation_0-logloss:0.56665\n",
      "[62]\tvalidation_0-logloss:0.56614\n",
      "[63]\tvalidation_0-logloss:0.56545\n",
      "[64]\tvalidation_0-logloss:0.56490\n",
      "[65]\tvalidation_0-logloss:0.56418\n",
      "[66]\tvalidation_0-logloss:0.56351\n",
      "[67]\tvalidation_0-logloss:0.56304\n",
      "[68]\tvalidation_0-logloss:0.56257\n",
      "[69]\tvalidation_0-logloss:0.56180\n",
      "[70]\tvalidation_0-logloss:0.56124\n",
      "[71]\tvalidation_0-logloss:0.56080\n",
      "[72]\tvalidation_0-logloss:0.56017\n",
      "[73]\tvalidation_0-logloss:0.55963\n",
      "[74]\tvalidation_0-logloss:0.55928\n",
      "[75]\tvalidation_0-logloss:0.55858\n",
      "[76]\tvalidation_0-logloss:0.55812\n",
      "[77]\tvalidation_0-logloss:0.55763\n",
      "[78]\tvalidation_0-logloss:0.55708\n",
      "[79]\tvalidation_0-logloss:0.55683\n",
      "[80]\tvalidation_0-logloss:0.55640\n",
      "[81]\tvalidation_0-logloss:0.55610\n",
      "[82]\tvalidation_0-logloss:0.55564\n",
      "[83]\tvalidation_0-logloss:0.55540\n",
      "[84]\tvalidation_0-logloss:0.55494\n",
      "[85]\tvalidation_0-logloss:0.55461\n",
      "[86]\tvalidation_0-logloss:0.55439\n",
      "[87]\tvalidation_0-logloss:0.55407\n",
      "[88]\tvalidation_0-logloss:0.55376\n",
      "[89]\tvalidation_0-logloss:0.55350\n",
      "[90]\tvalidation_0-logloss:0.55301\n",
      "[91]\tvalidation_0-logloss:0.55277\n",
      "[92]\tvalidation_0-logloss:0.55231\n",
      "[93]\tvalidation_0-logloss:0.55193\n",
      "[94]\tvalidation_0-logloss:0.55166\n",
      "[95]\tvalidation_0-logloss:0.55160\n",
      "[96]\tvalidation_0-logloss:0.55108\n",
      "[97]\tvalidation_0-logloss:0.55087\n",
      "[98]\tvalidation_0-logloss:0.55065\n",
      "[99]\tvalidation_0-logloss:0.55024\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-34 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-34 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-34 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-34 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-34 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-34 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-34 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-34 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-34 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-34 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-34 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-34 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-34 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-34 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-34 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-34 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-34 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-34 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-34 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-34 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-34 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-34 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-34 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-34 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-34 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-34 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-34 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-34 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-34 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-34 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-34 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-34 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-34 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-34 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-34 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-34 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-34 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-34 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-34 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-34 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-34 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-34 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-34\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=5,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.05, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=10,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" checked><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=5,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.05, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=10,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=5,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.05, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=10,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf = xgb.XGBClassifier(\n",
    "    early_stopping_rounds=5,\n",
    "    max_depth=10,\n",
    "    max_leaves=10,\n",
    "    gamma=.05,\n",
    "    scale_pos_weight=.75,\n",
    "    learning_rate=1e-2,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=0,\n",
    ")\n",
    "xgb_clf.fit(x_train, yb_train, eval_set=[(x_val, yb_val)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "a577c8cd-fbad-486d-8a57-4d6542dfc533",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8115942028985508, 0.9605263157894737, 0.4)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = xgb_clf.predict(x_val)\n",
    "(y_pred == yb_val).mean(), (y_pred[yb_val] > .5).mean(), (y_pred[~yb_val] < .5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cce17b-5351-4766-914b-94f87ee3f554",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Custom Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7ee8bfe-fcb0-4241-900e-15e52794591b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Accuracy(Metric):\n",
    "    def __init__(self, name='accuracy', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.accuracy = self.add_variable(\n",
    "            shape=(),\n",
    "            initializer='zeros',\n",
    "            name='accuracy'\n",
    "        )\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        p = tf.cast(tf.reduce_all((y_pred > .5) == y_true, axis=1), tf.float32)\n",
    "        \n",
    "        self.accuracy.assign(tf.reduce_mean(p))\n",
    "\n",
    "    def result(self):\n",
    "        return self.accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310b2beb-d47f-4582-8ca5-e6f88fb42003",
   "metadata": {},
   "source": [
    "CancelOut, based on [this paper](https://www.researchgate.net/publication/335698779_CancelOut_A_Layer_for_Feature_Selection_in_Deep_Neural_Networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac651fd6-9151-45f4-9d4d-cdf96a0f3bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class COReg(Regularizer):\n",
    "    def __init__(self, lambda_1=1e-3, lambda_2=1e-3):\n",
    "        self.lambda_1 = lambda_1\n",
    "        self.lambda_2 = lambda_2\n",
    "\n",
    "    def call(self, x):\n",
    "        return -1*lambda_1*ops.var(x) + L1(lambda_2)(x)\n",
    "\n",
    "class CancelOutLayer(Layer):\n",
    "    def __init__(self, lambda_1=1e-3, lambda_2=1e-3, **kwargs):\n",
    "        super(CancelOutLayer, self).__init__(**kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        weight_shape = (1, input_shape[-1])\n",
    "\n",
    "        \n",
    "        \n",
    "        self.kernel = self.add_weight(\n",
    "            name='kernel', \n",
    "            shape=weight_shape,\n",
    "            initializer='uniform',\n",
    "            trainable=True,\n",
    "            regularizer=COReg\n",
    "        )\n",
    "        \n",
    "        self.bias = self.add_weight(\n",
    "            name='bias', \n",
    "            shape=weight_shape,\n",
    "            initializer='zeros',\n",
    "            trainable=True\n",
    "        )\n",
    "        \n",
    "        self.built=True\n",
    "    \n",
    "    #operation:\n",
    "    def call(self, inputs):\n",
    "        return (inputs * self.kernel) + self.bias\n",
    "    \n",
    "    #output shape\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "    \n",
    "    #for saving the model - only necessary if you have parameters in __init__\n",
    "    def get_config(self):\n",
    "        config = super(SingleConnected, self).get_config()\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d0a4c99-7010-4848-a2c2-6c306173d8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_lr(epochs, lr):\n",
    "    if epochs < 50:\n",
    "        return 1e-2\n",
    "    else:\n",
    "        return 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb828d3-8516-4038-ac76-3763fc7c5f10",
   "metadata": {},
   "source": [
    "#### Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c07d6e7-f501-419e-bb62-79304eee8a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_k = 0\n",
    "reg_k = 0\n",
    "areg_k = 1e-4\n",
    "\n",
    "model = Sequential([\n",
    "    Input((x.shape[1],)),\n",
    "    CancelOutLayer(lambda_1=1e-2, lambda_2=1e-3),\n",
    "    Dense(128, kernel_regularizer=L1L2(reg_k), activity_regularizer=L2(areg_k), activation='relu'),\n",
    "    Dropout(dropout_k),\n",
    "    Dense(64, kernel_regularizer=L1L2(reg_k), activity_regularizer=L2(areg_k), activation='relu'),\n",
    "    Dropout(dropout_k),\n",
    "    Dense(64, kernel_regularizer=L1L2(reg_k), activity_regularizer=L2(areg_k), activation='relu'),\n",
    "    Dropout(dropout_k),\n",
    "    Dense(64, kernel_regularizer=L1L2(reg_k), activity_regularizer=L2(areg_k), activation='relu'),\n",
    "    Dropout(dropout_k),\n",
    "    Dense(256, kernel_regularizer=L1L2(reg_k), activity_regularizer=L2(areg_k), activation='relu'),\n",
    "    Dropout(dropout_k),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Nadam(1e-4),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9451f219-4ad5-4511-90e1-6877b2dfbe35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - accuracy: 0.4719 - loss: 0.6936 - val_accuracy: 0.6763 - val_loss: 0.6927\n",
      "Epoch 2/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6580 - loss: 0.6928 - val_accuracy: 0.6763 - val_loss: 0.6920\n",
      "Epoch 3/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6563 - loss: 0.6922 - val_accuracy: 0.6763 - val_loss: 0.6913\n",
      "Epoch 4/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6675 - loss: 0.6914 - val_accuracy: 0.6763 - val_loss: 0.6905\n",
      "Epoch 5/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6671 - loss: 0.6906 - val_accuracy: 0.6763 - val_loss: 0.6896\n",
      "Epoch 6/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6575 - loss: 0.6900 - val_accuracy: 0.6763 - val_loss: 0.6887\n",
      "Epoch 7/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6671 - loss: 0.6888 - val_accuracy: 0.6763 - val_loss: 0.6876\n",
      "Epoch 8/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6571 - loss: 0.6882 - val_accuracy: 0.6763 - val_loss: 0.6865\n",
      "Epoch 9/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6575 - loss: 0.6872 - val_accuracy: 0.6763 - val_loss: 0.6853\n",
      "Epoch 10/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6613 - loss: 0.6860 - val_accuracy: 0.6763 - val_loss: 0.6841\n",
      "Epoch 11/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6721 - loss: 0.6842 - val_accuracy: 0.6763 - val_loss: 0.6827\n",
      "Epoch 12/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6550 - loss: 0.6840 - val_accuracy: 0.6763 - val_loss: 0.6813\n",
      "Epoch 13/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6584 - loss: 0.6825 - val_accuracy: 0.6763 - val_loss: 0.6798\n",
      "Epoch 14/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6642 - loss: 0.6808 - val_accuracy: 0.6763 - val_loss: 0.6781\n",
      "Epoch 15/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6517 - loss: 0.6805 - val_accuracy: 0.6763 - val_loss: 0.6764\n",
      "Epoch 16/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6646 - loss: 0.6778 - val_accuracy: 0.6763 - val_loss: 0.6747\n",
      "Epoch 17/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6621 - loss: 0.6767 - val_accuracy: 0.6763 - val_loss: 0.6728\n",
      "Epoch 18/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6563 - loss: 0.6759 - val_accuracy: 0.6763 - val_loss: 0.6709\n",
      "Epoch 19/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6596 - loss: 0.6739 - val_accuracy: 0.6763 - val_loss: 0.6689\n",
      "Epoch 20/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6646 - loss: 0.6715 - val_accuracy: 0.6763 - val_loss: 0.6668\n",
      "Epoch 21/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6792 - loss: 0.6670 - val_accuracy: 0.6763 - val_loss: 0.6647\n",
      "Epoch 22/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6625 - loss: 0.6687 - val_accuracy: 0.6763 - val_loss: 0.6627\n",
      "Epoch 23/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6621 - loss: 0.6673 - val_accuracy: 0.6763 - val_loss: 0.6608\n",
      "Epoch 24/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6805 - loss: 0.6613 - val_accuracy: 0.6763 - val_loss: 0.6589\n",
      "Epoch 25/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6663 - loss: 0.6635 - val_accuracy: 0.6763 - val_loss: 0.6572\n",
      "Epoch 26/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6530 - loss: 0.6664 - val_accuracy: 0.6763 - val_loss: 0.6557\n",
      "Epoch 27/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6775 - loss: 0.6576 - val_accuracy: 0.6763 - val_loss: 0.6543\n",
      "Epoch 28/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6555 - loss: 0.6640 - val_accuracy: 0.6763 - val_loss: 0.6531\n",
      "Epoch 29/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6700 - loss: 0.6581 - val_accuracy: 0.6763 - val_loss: 0.6520\n",
      "Epoch 30/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6580 - loss: 0.6618 - val_accuracy: 0.6763 - val_loss: 0.6511\n",
      "Epoch 31/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6680 - loss: 0.6574 - val_accuracy: 0.6763 - val_loss: 0.6503\n",
      "Epoch 32/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6659 - loss: 0.6577 - val_accuracy: 0.6763 - val_loss: 0.6495\n",
      "Epoch 33/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6717 - loss: 0.6546 - val_accuracy: 0.6763 - val_loss: 0.6488\n",
      "Epoch 34/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6692 - loss: 0.6550 - val_accuracy: 0.6763 - val_loss: 0.6482\n",
      "Epoch 35/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6667 - loss: 0.6556 - val_accuracy: 0.6763 - val_loss: 0.6477\n",
      "Epoch 36/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6563 - loss: 0.6597 - val_accuracy: 0.6763 - val_loss: 0.6472\n",
      "Epoch 37/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6634 - loss: 0.6560 - val_accuracy: 0.6763 - val_loss: 0.6467\n",
      "Epoch 38/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6730 - loss: 0.6513 - val_accuracy: 0.6763 - val_loss: 0.6462\n",
      "Epoch 39/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6775 - loss: 0.6487 - val_accuracy: 0.6763 - val_loss: 0.6458\n",
      "Epoch 40/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6675 - loss: 0.6528 - val_accuracy: 0.6763 - val_loss: 0.6454\n",
      "Epoch 41/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6559 - loss: 0.6577 - val_accuracy: 0.6763 - val_loss: 0.6450\n",
      "Epoch 42/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6596 - loss: 0.6558 - val_accuracy: 0.6763 - val_loss: 0.6446\n",
      "Epoch 43/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6692 - loss: 0.6509 - val_accuracy: 0.6763 - val_loss: 0.6440\n",
      "Epoch 44/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6696 - loss: 0.6503 - val_accuracy: 0.6763 - val_loss: 0.6435\n",
      "Epoch 45/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6663 - loss: 0.6514 - val_accuracy: 0.6763 - val_loss: 0.6431\n",
      "Epoch 46/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6659 - loss: 0.6512 - val_accuracy: 0.6763 - val_loss: 0.6426\n",
      "Epoch 47/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6709 - loss: 0.6484 - val_accuracy: 0.6763 - val_loss: 0.6421\n",
      "Epoch 48/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6738 - loss: 0.6466 - val_accuracy: 0.6763 - val_loss: 0.6417\n",
      "Epoch 49/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6634 - loss: 0.6512 - val_accuracy: 0.6763 - val_loss: 0.6413\n",
      "Epoch 50/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6763 - loss: 0.6446 - val_accuracy: 0.6763 - val_loss: 0.6408\n",
      "Epoch 51/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6642 - loss: 0.6498 - val_accuracy: 0.6763 - val_loss: 0.6404\n",
      "Epoch 52/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6605 - loss: 0.6516 - val_accuracy: 0.6763 - val_loss: 0.6399\n",
      "Epoch 53/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6725 - loss: 0.6453 - val_accuracy: 0.6763 - val_loss: 0.6393\n",
      "Epoch 54/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6634 - loss: 0.6495 - val_accuracy: 0.6763 - val_loss: 0.6387\n",
      "Epoch 55/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6663 - loss: 0.6473 - val_accuracy: 0.6763 - val_loss: 0.6381\n",
      "Epoch 56/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6496 - loss: 0.6549 - val_accuracy: 0.6763 - val_loss: 0.6376\n",
      "Epoch 57/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6634 - loss: 0.6483 - val_accuracy: 0.6763 - val_loss: 0.6369\n",
      "Epoch 58/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6530 - loss: 0.6526 - val_accuracy: 0.6763 - val_loss: 0.6362\n",
      "Epoch 59/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6767 - loss: 0.6404 - val_accuracy: 0.6763 - val_loss: 0.6355\n",
      "Epoch 60/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6746 - loss: 0.6410 - val_accuracy: 0.6763 - val_loss: 0.6350\n",
      "Epoch 61/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6734 - loss: 0.6407 - val_accuracy: 0.6763 - val_loss: 0.6345\n",
      "Epoch 62/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6592 - loss: 0.6475 - val_accuracy: 0.6763 - val_loss: 0.6341\n",
      "Epoch 63/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6584 - loss: 0.6469 - val_accuracy: 0.6763 - val_loss: 0.6334\n",
      "Epoch 64/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6496 - loss: 0.6516 - val_accuracy: 0.6763 - val_loss: 0.6325\n",
      "Epoch 65/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6609 - loss: 0.6451 - val_accuracy: 0.6763 - val_loss: 0.6316\n",
      "Epoch 66/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6617 - loss: 0.6442 - val_accuracy: 0.6763 - val_loss: 0.6308\n",
      "Epoch 67/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6667 - loss: 0.6411 - val_accuracy: 0.6763 - val_loss: 0.6300\n",
      "Epoch 68/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6642 - loss: 0.6417 - val_accuracy: 0.6763 - val_loss: 0.6293\n",
      "Epoch 69/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6680 - loss: 0.6398 - val_accuracy: 0.6763 - val_loss: 0.6285\n",
      "Epoch 70/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6596 - loss: 0.6421 - val_accuracy: 0.6763 - val_loss: 0.6276\n",
      "Epoch 71/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6684 - loss: 0.6372 - val_accuracy: 0.6763 - val_loss: 0.6266\n",
      "Epoch 72/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6525 - loss: 0.6446 - val_accuracy: 0.6763 - val_loss: 0.6257\n",
      "Epoch 73/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6563 - loss: 0.6426 - val_accuracy: 0.6763 - val_loss: 0.6246\n",
      "Epoch 74/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6700 - loss: 0.6344 - val_accuracy: 0.6763 - val_loss: 0.6236\n",
      "Epoch 75/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6800 - loss: 0.6279 - val_accuracy: 0.6763 - val_loss: 0.6226\n",
      "Epoch 76/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6613 - loss: 0.6379 - val_accuracy: 0.6763 - val_loss: 0.6217\n",
      "Epoch 77/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6575 - loss: 0.6393 - val_accuracy: 0.6763 - val_loss: 0.6204\n",
      "Epoch 78/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6609 - loss: 0.6366 - val_accuracy: 0.6763 - val_loss: 0.6189\n",
      "Epoch 79/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6538 - loss: 0.6376 - val_accuracy: 0.6763 - val_loss: 0.6175\n",
      "Epoch 80/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6692 - loss: 0.6297 - val_accuracy: 0.6763 - val_loss: 0.6162\n",
      "Epoch 81/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6750 - loss: 0.6257 - val_accuracy: 0.6763 - val_loss: 0.6150\n",
      "Epoch 82/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6567 - loss: 0.6350 - val_accuracy: 0.6763 - val_loss: 0.6139\n",
      "Epoch 83/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6650 - loss: 0.6285 - val_accuracy: 0.6763 - val_loss: 0.6121\n",
      "Epoch 84/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6671 - loss: 0.6252 - val_accuracy: 0.6763 - val_loss: 0.6106\n",
      "Epoch 85/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6588 - loss: 0.6293 - val_accuracy: 0.6763 - val_loss: 0.6092\n",
      "Epoch 86/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6463 - loss: 0.6364 - val_accuracy: 0.6763 - val_loss: 0.6077\n",
      "Epoch 87/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6605 - loss: 0.6265 - val_accuracy: 0.6763 - val_loss: 0.6060\n",
      "Epoch 88/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6713 - loss: 0.6186 - val_accuracy: 0.6763 - val_loss: 0.6046\n",
      "Epoch 89/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6696 - loss: 0.6211 - val_accuracy: 0.6763 - val_loss: 0.6035\n",
      "Epoch 90/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6567 - loss: 0.6262 - val_accuracy: 0.6763 - val_loss: 0.6020\n",
      "Epoch 91/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6634 - loss: 0.6258 - val_accuracy: 0.6763 - val_loss: 0.6003\n",
      "Epoch 92/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6613 - loss: 0.6221 - val_accuracy: 0.6763 - val_loss: 0.5988\n",
      "Epoch 93/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6617 - loss: 0.6192 - val_accuracy: 0.6763 - val_loss: 0.5974\n",
      "Epoch 94/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6750 - loss: 0.6122 - val_accuracy: 0.6763 - val_loss: 0.5962\n",
      "Epoch 95/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6621 - loss: 0.6180 - val_accuracy: 0.6763 - val_loss: 0.5947\n",
      "Epoch 96/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6509 - loss: 0.6234 - val_accuracy: 0.6763 - val_loss: 0.5931\n",
      "Epoch 97/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6588 - loss: 0.6204 - val_accuracy: 0.6763 - val_loss: 0.5917\n",
      "Epoch 98/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6588 - loss: 0.6170 - val_accuracy: 0.6763 - val_loss: 0.5905\n",
      "Epoch 99/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6659 - loss: 0.6135 - val_accuracy: 0.6763 - val_loss: 0.5894\n",
      "Epoch 100/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6555 - loss: 0.6171 - val_accuracy: 0.6763 - val_loss: 0.5882\n",
      "Epoch 101/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6696 - loss: 0.6081 - val_accuracy: 0.6763 - val_loss: 0.5871\n",
      "Epoch 102/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6659 - loss: 0.6094 - val_accuracy: 0.6763 - val_loss: 0.5862\n",
      "Epoch 103/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6630 - loss: 0.6130 - val_accuracy: 0.6763 - val_loss: 0.5848\n",
      "Epoch 104/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6709 - loss: 0.6035 - val_accuracy: 0.6763 - val_loss: 0.5837\n",
      "Epoch 105/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6671 - loss: 0.6064 - val_accuracy: 0.6763 - val_loss: 0.5829\n",
      "Epoch 106/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6673 - loss: 0.6105 - val_accuracy: 0.6763 - val_loss: 0.5817\n",
      "Epoch 107/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6701 - loss: 0.6105 - val_accuracy: 0.6860 - val_loss: 0.5806\n",
      "Epoch 108/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6887 - loss: 0.6014 - val_accuracy: 0.7005 - val_loss: 0.5797\n",
      "Epoch 109/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6991 - loss: 0.6083 - val_accuracy: 0.7246 - val_loss: 0.5791\n",
      "Epoch 110/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7043 - loss: 0.6043 - val_accuracy: 0.7246 - val_loss: 0.5780\n",
      "Epoch 111/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7146 - loss: 0.6048 - val_accuracy: 0.7295 - val_loss: 0.5772\n",
      "Epoch 112/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6993 - loss: 0.6117 - val_accuracy: 0.7295 - val_loss: 0.5764\n",
      "Epoch 113/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7149 - loss: 0.6068 - val_accuracy: 0.7246 - val_loss: 0.5755\n",
      "Epoch 114/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7152 - loss: 0.6092 - val_accuracy: 0.7440 - val_loss: 0.5750\n",
      "Epoch 115/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7209 - loss: 0.6033 - val_accuracy: 0.7536 - val_loss: 0.5746\n",
      "Epoch 116/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7197 - loss: 0.6098 - val_accuracy: 0.7488 - val_loss: 0.5734\n",
      "Epoch 117/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7281 - loss: 0.6077 - val_accuracy: 0.7440 - val_loss: 0.5725\n",
      "Epoch 118/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7227 - loss: 0.6013 - val_accuracy: 0.7488 - val_loss: 0.5718\n",
      "Epoch 119/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7251 - loss: 0.6003 - val_accuracy: 0.7536 - val_loss: 0.5711\n",
      "Epoch 120/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7369 - loss: 0.5923 - val_accuracy: 0.7488 - val_loss: 0.5709\n",
      "Epoch 121/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7450 - loss: 0.5902 - val_accuracy: 0.7488 - val_loss: 0.5711\n",
      "Epoch 122/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7351 - loss: 0.5955 - val_accuracy: 0.7488 - val_loss: 0.5700\n",
      "Epoch 123/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7305 - loss: 0.5992 - val_accuracy: 0.7585 - val_loss: 0.5687\n",
      "Epoch 124/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7339 - loss: 0.6022 - val_accuracy: 0.7585 - val_loss: 0.5679\n",
      "Epoch 125/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7253 - loss: 0.6004 - val_accuracy: 0.7585 - val_loss: 0.5672\n",
      "Epoch 126/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7321 - loss: 0.5966 - val_accuracy: 0.7585 - val_loss: 0.5665\n",
      "Epoch 127/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7393 - loss: 0.5978 - val_accuracy: 0.7536 - val_loss: 0.5659\n",
      "Epoch 128/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7369 - loss: 0.6022 - val_accuracy: 0.7585 - val_loss: 0.5651\n",
      "Epoch 129/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7337 - loss: 0.6017 - val_accuracy: 0.7536 - val_loss: 0.5644\n",
      "Epoch 130/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7229 - loss: 0.6048 - val_accuracy: 0.7585 - val_loss: 0.5636\n",
      "Epoch 131/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7328 - loss: 0.5999 - val_accuracy: 0.7585 - val_loss: 0.5629\n",
      "Epoch 132/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7314 - loss: 0.5984 - val_accuracy: 0.7633 - val_loss: 0.5623\n",
      "Epoch 133/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7445 - loss: 0.5912 - val_accuracy: 0.7585 - val_loss: 0.5619\n",
      "Epoch 134/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7352 - loss: 0.5970 - val_accuracy: 0.7585 - val_loss: 0.5612\n",
      "Epoch 135/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7416 - loss: 0.5941 - val_accuracy: 0.7633 - val_loss: 0.5602\n",
      "Epoch 136/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7359 - loss: 0.5987 - val_accuracy: 0.7633 - val_loss: 0.5595\n",
      "Epoch 137/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7289 - loss: 0.6027 - val_accuracy: 0.7633 - val_loss: 0.5588\n",
      "Epoch 138/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7401 - loss: 0.5930 - val_accuracy: 0.7633 - val_loss: 0.5582\n",
      "Epoch 139/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7428 - loss: 0.5899 - val_accuracy: 0.7536 - val_loss: 0.5579\n",
      "Epoch 140/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7503 - loss: 0.5847 - val_accuracy: 0.7633 - val_loss: 0.5568\n",
      "Epoch 141/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7283 - loss: 0.5976 - val_accuracy: 0.7633 - val_loss: 0.5561\n",
      "Epoch 142/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7367 - loss: 0.5959 - val_accuracy: 0.7681 - val_loss: 0.5554\n",
      "Epoch 143/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7415 - loss: 0.5881 - val_accuracy: 0.7585 - val_loss: 0.5553\n",
      "Epoch 144/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7425 - loss: 0.5947 - val_accuracy: 0.7633 - val_loss: 0.5541\n",
      "Epoch 145/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7401 - loss: 0.5874 - val_accuracy: 0.7681 - val_loss: 0.5533\n",
      "Epoch 146/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7404 - loss: 0.5958 - val_accuracy: 0.7681 - val_loss: 0.5527\n",
      "Epoch 147/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7454 - loss: 0.5903 - val_accuracy: 0.7633 - val_loss: 0.5520\n",
      "Epoch 148/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7494 - loss: 0.5856 - val_accuracy: 0.7729 - val_loss: 0.5518\n",
      "Epoch 149/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7407 - loss: 0.5879 - val_accuracy: 0.7633 - val_loss: 0.5509\n",
      "Epoch 150/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7417 - loss: 0.5906 - val_accuracy: 0.7681 - val_loss: 0.5501\n",
      "Epoch 151/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7475 - loss: 0.5811 - val_accuracy: 0.7681 - val_loss: 0.5493\n",
      "Epoch 152/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7452 - loss: 0.5918 - val_accuracy: 0.7681 - val_loss: 0.5487\n",
      "Epoch 153/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7450 - loss: 0.5869 - val_accuracy: 0.7729 - val_loss: 0.5480\n",
      "Epoch 154/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7511 - loss: 0.5805 - val_accuracy: 0.7729 - val_loss: 0.5473\n",
      "Epoch 155/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7384 - loss: 0.5856 - val_accuracy: 0.7729 - val_loss: 0.5468\n",
      "Epoch 156/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7552 - loss: 0.5796 - val_accuracy: 0.7778 - val_loss: 0.5461\n",
      "Epoch 157/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7365 - loss: 0.5937 - val_accuracy: 0.7729 - val_loss: 0.5455\n",
      "Epoch 158/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7445 - loss: 0.5819 - val_accuracy: 0.7729 - val_loss: 0.5447\n",
      "Epoch 159/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7555 - loss: 0.5709 - val_accuracy: 0.7729 - val_loss: 0.5441\n",
      "Epoch 160/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7404 - loss: 0.5850 - val_accuracy: 0.7778 - val_loss: 0.5435\n",
      "Epoch 161/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7456 - loss: 0.5820 - val_accuracy: 0.7778 - val_loss: 0.5429\n",
      "Epoch 162/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7456 - loss: 0.5798 - val_accuracy: 0.7778 - val_loss: 0.5422\n",
      "Epoch 163/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7443 - loss: 0.5760 - val_accuracy: 0.7778 - val_loss: 0.5417\n",
      "Epoch 164/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7666 - loss: 0.5659 - val_accuracy: 0.7874 - val_loss: 0.5412\n",
      "Epoch 165/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7530 - loss: 0.5722 - val_accuracy: 0.7874 - val_loss: 0.5406\n",
      "Epoch 166/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7523 - loss: 0.5785 - val_accuracy: 0.7681 - val_loss: 0.5399\n",
      "Epoch 167/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7499 - loss: 0.5695 - val_accuracy: 0.7778 - val_loss: 0.5391\n",
      "Epoch 168/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7609 - loss: 0.5686 - val_accuracy: 0.7874 - val_loss: 0.5390\n",
      "Epoch 169/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7526 - loss: 0.5739 - val_accuracy: 0.7874 - val_loss: 0.5388\n",
      "Epoch 170/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7580 - loss: 0.5713 - val_accuracy: 0.7681 - val_loss: 0.5376\n",
      "Epoch 171/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7495 - loss: 0.5722 - val_accuracy: 0.7681 - val_loss: 0.5370\n",
      "Epoch 172/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7530 - loss: 0.5756 - val_accuracy: 0.7729 - val_loss: 0.5363\n",
      "Epoch 173/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7538 - loss: 0.5740 - val_accuracy: 0.7681 - val_loss: 0.5360\n",
      "Epoch 174/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7353 - loss: 0.5865 - val_accuracy: 0.7633 - val_loss: 0.5361\n",
      "Epoch 175/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7503 - loss: 0.5767 - val_accuracy: 0.7681 - val_loss: 0.5347\n",
      "Epoch 176/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7511 - loss: 0.5699 - val_accuracy: 0.7729 - val_loss: 0.5336\n",
      "Epoch 177/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7521 - loss: 0.5727 - val_accuracy: 0.7729 - val_loss: 0.5332\n",
      "Epoch 178/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7463 - loss: 0.5755 - val_accuracy: 0.7729 - val_loss: 0.5328\n",
      "Epoch 179/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7534 - loss: 0.5609 - val_accuracy: 0.7778 - val_loss: 0.5315\n",
      "Epoch 180/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7539 - loss: 0.5674 - val_accuracy: 0.7681 - val_loss: 0.5319\n",
      "Epoch 181/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7584 - loss: 0.5591 - val_accuracy: 0.7729 - val_loss: 0.5304\n",
      "Epoch 182/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7625 - loss: 0.5625 - val_accuracy: 0.7826 - val_loss: 0.5296\n",
      "Epoch 183/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7639 - loss: 0.5616 - val_accuracy: 0.7826 - val_loss: 0.5288\n",
      "Epoch 184/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7558 - loss: 0.5667 - val_accuracy: 0.7729 - val_loss: 0.5289\n",
      "Epoch 185/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7604 - loss: 0.5622 - val_accuracy: 0.7729 - val_loss: 0.5278\n",
      "Epoch 186/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7522 - loss: 0.5662 - val_accuracy: 0.7778 - val_loss: 0.5268\n",
      "Epoch 187/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7602 - loss: 0.5610 - val_accuracy: 0.7729 - val_loss: 0.5274\n",
      "Epoch 188/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7631 - loss: 0.5579 - val_accuracy: 0.7923 - val_loss: 0.5254\n",
      "Epoch 189/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7657 - loss: 0.5564 - val_accuracy: 0.7729 - val_loss: 0.5246\n",
      "Epoch 190/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7613 - loss: 0.5651 - val_accuracy: 0.7729 - val_loss: 0.5257\n",
      "Epoch 191/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7556 - loss: 0.5564 - val_accuracy: 0.7729 - val_loss: 0.5241\n",
      "Epoch 192/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7693 - loss: 0.5484 - val_accuracy: 0.7874 - val_loss: 0.5233\n",
      "Epoch 193/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7755 - loss: 0.5489 - val_accuracy: 0.7874 - val_loss: 0.5223\n",
      "Epoch 194/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7613 - loss: 0.5615 - val_accuracy: 0.7729 - val_loss: 0.5232\n",
      "Epoch 195/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7686 - loss: 0.5512 - val_accuracy: 0.7729 - val_loss: 0.5213\n",
      "Epoch 196/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7665 - loss: 0.5550 - val_accuracy: 0.7729 - val_loss: 0.5205\n",
      "Epoch 197/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7651 - loss: 0.5512 - val_accuracy: 0.7633 - val_loss: 0.5213\n",
      "Epoch 198/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7848 - loss: 0.5402 - val_accuracy: 0.7778 - val_loss: 0.5197\n",
      "Epoch 199/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7773 - loss: 0.5403 - val_accuracy: 0.7874 - val_loss: 0.5227\n",
      "Epoch 200/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7711 - loss: 0.5470 - val_accuracy: 0.7729 - val_loss: 0.5186\n",
      "18.188217199989595\n"
     ]
    }
   ],
   "source": [
    "start = perf_counter()\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    yb_train,\n",
    "    epochs=200,\n",
    "    validation_data=(x_val, yb_val),\n",
    "    batch_size=300,\n",
    "    class_weight={0: 1, 1: 1}\n",
    "    # callbacks=[LearningRateScheduler(drop_lr)]\n",
    ")\n",
    "\n",
    "print(perf_counter() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "201db04d-b41b-49aa-ab3f-ca4ad28e423e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Binary NN Loss over Training')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.gca()\n",
    "\n",
    "ax.plot(history.history['accuracy'], label='Training')\n",
    "ax.plot(\n",
    "    np.convolve(np.array(history.history['val_accuracy']), np.ones(5)/5, mode='valid'),\n",
    "    label='Validation (Running Mean)'\n",
    ")\n",
    "ax.legend()\n",
    "ax.set_xlabel('# Epochs')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_ylim((0, 1))\n",
    "ax.set_title('Binary NN Loss over Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7a5d0bf-ddff-41fb-83fe-0531435c8bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d30df83-b141-470b-b71a-545c464956ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9714285714285714"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# True Positive Accuracy\n",
    "(y_pred[yb_val] > .5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2af2fde4-cf6e-494b-a687-27dc22313cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3582089552238806"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# True Negative Accuracy\n",
    "(y_pred[~yb_val] < .5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf3ada6-e22f-4409-a549-98b25ba992af",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "02717ef7-b27d-4a48-909e-c2f4457af7a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dropout_k = .05\n",
    "reg_k = 1e-3\n",
    "\n",
    "# model = Sequential([\n",
    "#     Input((x.shape[1],)),\n",
    "#     Dense(256, kernel_regularizer=L2(reg_k), activation='relu'),\n",
    "#     Dropout(dropout_k),\n",
    "#     Dense(256, kernel_regularizer=L2(reg_k), activation='relu'),\n",
    "#     Dropout(dropout_k),\n",
    "#     Dense(80, kernel_regularizer=L2(reg_k), activation='relu'),\n",
    "#     Dropout(dropout_k),\n",
    "#     Dense(40, kernel_regularizer=L2(reg_k), activation='relu'),\n",
    "#     Dropout(dropout_k),\n",
    "#     Dense(40, kernel_regularizer=L2(reg_k), activation='relu'),\n",
    "#     Dropout(dropout_k),\n",
    "#     Dense(20, kernel_regularizer=L2(reg_k), activation='relu'),\n",
    "#     Dropout(dropout_k),\n",
    "#     Dense(20, kernel_regularizer=L2(reg_k), activation='relu'),\n",
    "#     Dropout(dropout_k),\n",
    "#     Dense(y.shape[1], activation='sigmoid'),\n",
    "# \n",
    "\n",
    "model = Sequential([\n",
    "    Input((x.shape[1],)),\n",
    "    CancelOutLayer(lambda_1=1e-3, lambda_2=1e-3),\n",
    "    Dense(256, kernel_regularizer=L2(reg_k), activation='relu'),\n",
    "    Dropout(dropout_k),\n",
    "    Dense(256, kernel_regularizer=L2(reg_k), activation='relu'),\n",
    "    Dropout(dropout_k),\n",
    "    Dense(256, kernel_regularizer=L2(reg_k), activation='relu'),\n",
    "    Dropout(dropout_k),\n",
    "    Dense(256, kernel_regularizer=L2(reg_k), activation='relu'),\n",
    "    Dropout(dropout_k),\n",
    "    Dense(64, kernel_regularizer=L2(reg_k), activation='relu'),\n",
    "    Dropout(dropout_k),\n",
    "    Dense(y.shape[1], activation='softmax'),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Nadam(1e-2),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[Accuracy],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad532feb-4526-4dc7-9a90-9fa40d11e502",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "5110f59b-aebe-41fa-9c75-ca8800fdb892",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.3424 - loss: 1.0798 - val_accuracy: 0.3575 - val_loss: 0.8408\n",
      "Epoch 2/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.8400 - val_accuracy: 0.3575 - val_loss: 0.7037\n",
      "Epoch 3/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.3424 - loss: 0.7031 - val_accuracy: 0.3575 - val_loss: 0.5989\n",
      "Epoch 4/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.5985 - val_accuracy: 0.3575 - val_loss: 0.5119\n",
      "Epoch 5/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.3424 - loss: 0.5115 - val_accuracy: 0.3575 - val_loss: 0.4378\n",
      "Epoch 6/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.3424 - loss: 0.4374 - val_accuracy: 0.3575 - val_loss: 0.3748\n",
      "Epoch 7/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.3424 - loss: 0.3745 - val_accuracy: 0.3575 - val_loss: 0.3219\n",
      "Epoch 8/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.3424 - loss: 0.3215 - val_accuracy: 0.3575 - val_loss: 0.2781\n",
      "Epoch 9/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3424 - loss: 0.2777 - val_accuracy: 0.3575 - val_loss: 0.2427\n",
      "Epoch 10/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.2423 - val_accuracy: 0.3575 - val_loss: 0.2147\n",
      "Epoch 11/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.2144 - val_accuracy: 0.3575 - val_loss: 0.1932\n",
      "Epoch 12/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.3424 - loss: 0.1930 - val_accuracy: 0.3575 - val_loss: 0.1775\n",
      "Epoch 13/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1771 - val_accuracy: 0.3575 - val_loss: 0.1664\n",
      "Epoch 14/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1661 - val_accuracy: 0.3575 - val_loss: 0.1592\n",
      "Epoch 15/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.3424 - loss: 0.1588 - val_accuracy: 0.3575 - val_loss: 0.1549\n",
      "Epoch 16/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1546 - val_accuracy: 0.3575 - val_loss: 0.1529\n",
      "Epoch 17/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1526 - val_accuracy: 0.3575 - val_loss: 0.1523\n",
      "Epoch 18/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.3424 - loss: 0.1521 - val_accuracy: 0.3575 - val_loss: 0.1528\n",
      "Epoch 19/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1525 - val_accuracy: 0.3575 - val_loss: 0.1537\n",
      "Epoch 20/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1533 - val_accuracy: 0.3575 - val_loss: 0.1547\n",
      "Epoch 21/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.3424 - loss: 0.1545 - val_accuracy: 0.3575 - val_loss: 0.1557\n",
      "Epoch 22/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.3424 - loss: 0.1554 - val_accuracy: 0.3575 - val_loss: 0.1564\n",
      "Epoch 23/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.3424 - loss: 0.1561 - val_accuracy: 0.3575 - val_loss: 0.1567\n",
      "Epoch 24/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.3424 - loss: 0.1564 - val_accuracy: 0.3575 - val_loss: 0.1567\n",
      "Epoch 25/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.3424 - loss: 0.1564 - val_accuracy: 0.3575 - val_loss: 0.1562\n",
      "Epoch 26/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.3424 - loss: 0.1560 - val_accuracy: 0.3575 - val_loss: 0.1555\n",
      "Epoch 27/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.3424 - loss: 0.1552 - val_accuracy: 0.3575 - val_loss: 0.1546\n",
      "Epoch 28/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1544 - val_accuracy: 0.3575 - val_loss: 0.1535\n",
      "Epoch 29/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1531 - val_accuracy: 0.3575 - val_loss: 0.1523\n",
      "Epoch 30/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1520 - val_accuracy: 0.3575 - val_loss: 0.1512\n",
      "Epoch 31/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1508 - val_accuracy: 0.3575 - val_loss: 0.1500\n",
      "Epoch 32/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1497 - val_accuracy: 0.3575 - val_loss: 0.1490\n",
      "Epoch 33/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1487 - val_accuracy: 0.3575 - val_loss: 0.1480\n",
      "Epoch 34/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.3424 - loss: 0.1477 - val_accuracy: 0.3575 - val_loss: 0.1473\n",
      "Epoch 35/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3424 - loss: 0.1470 - val_accuracy: 0.3575 - val_loss: 0.1466\n",
      "Epoch 36/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1463 - val_accuracy: 0.3575 - val_loss: 0.1461\n",
      "Epoch 37/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1459 - val_accuracy: 0.3575 - val_loss: 0.1457\n",
      "Epoch 38/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1455 - val_accuracy: 0.3575 - val_loss: 0.1455\n",
      "Epoch 39/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1452 - val_accuracy: 0.3575 - val_loss: 0.1453\n",
      "Epoch 40/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1450 - val_accuracy: 0.3575 - val_loss: 0.1452\n",
      "Epoch 41/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1449 - val_accuracy: 0.3575 - val_loss: 0.1451\n",
      "Epoch 42/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1448 - val_accuracy: 0.3575 - val_loss: 0.1451\n",
      "Epoch 43/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.3424 - loss: 0.1448 - val_accuracy: 0.3575 - val_loss: 0.1451\n",
      "Epoch 44/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.3424 - loss: 0.1448 - val_accuracy: 0.3575 - val_loss: 0.1450\n",
      "Epoch 45/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1447 - val_accuracy: 0.3575 - val_loss: 0.1450\n",
      "Epoch 46/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3424 - loss: 0.1448 - val_accuracy: 0.3575 - val_loss: 0.1450\n",
      "Epoch 47/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1447 - val_accuracy: 0.3575 - val_loss: 0.1450\n",
      "Epoch 48/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1447 - val_accuracy: 0.3575 - val_loss: 0.1450\n",
      "Epoch 49/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1446 - val_accuracy: 0.3575 - val_loss: 0.1449\n",
      "Epoch 50/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1447 - val_accuracy: 0.3575 - val_loss: 0.1449\n",
      "Epoch 51/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1447 - val_accuracy: 0.3575 - val_loss: 0.1449\n",
      "Epoch 52/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1446 - val_accuracy: 0.3575 - val_loss: 0.1448\n",
      "Epoch 53/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1446 - val_accuracy: 0.3575 - val_loss: 0.1448\n",
      "Epoch 54/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1446 - val_accuracy: 0.3575 - val_loss: 0.1448\n",
      "Epoch 55/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1445 - val_accuracy: 0.3575 - val_loss: 0.1448\n",
      "Epoch 56/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1445 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 57/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 58/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 59/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 60/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 61/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 62/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 63/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 64/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 65/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 66/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1445 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 67/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 68/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 69/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 70/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 71/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 72/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 73/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 74/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 75/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 76/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 77/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 78/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 79/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 80/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 81/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 82/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 83/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 84/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 85/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 86/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 87/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 88/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 89/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 90/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 91/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 92/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 93/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 94/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 95/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 96/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 97/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 98/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 99/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 100/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 101/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 102/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 103/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 104/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 105/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 106/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 107/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 108/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 109/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 110/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 111/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 112/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 113/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 114/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 115/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 116/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 117/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 118/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 119/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 120/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 121/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 122/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 123/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 124/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 125/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 126/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 127/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 128/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 129/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 130/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 131/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 132/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 133/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 134/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 135/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 136/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 137/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 138/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 139/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 140/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 141/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 142/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 143/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 144/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 145/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 146/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 147/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 148/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 149/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 150/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 151/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 152/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 153/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 154/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 155/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 156/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 157/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 158/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 159/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 160/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 161/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 162/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 163/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 164/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 165/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 166/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 167/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 168/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 169/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 170/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 171/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 172/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 173/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 174/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 175/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 176/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 177/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 178/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 179/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 180/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 181/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 182/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 183/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 184/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 185/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 186/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 187/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 188/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 189/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 190/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 191/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 192/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 193/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 194/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 195/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 196/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 197/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 198/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 199/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 200/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 201/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 202/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 203/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 204/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 205/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 206/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 207/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 208/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 209/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 210/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 211/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 212/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 213/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 214/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 215/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 216/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 217/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 218/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 219/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 220/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 221/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 222/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 223/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 224/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 225/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 226/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 227/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 228/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 229/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 230/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 231/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 232/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 233/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 234/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 235/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 236/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 237/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 238/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 239/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 240/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 241/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 242/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 243/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 244/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 245/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 246/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 247/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 248/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 249/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 250/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 251/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 252/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 253/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 254/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 255/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 256/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 257/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 258/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 259/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 260/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 261/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 262/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 263/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 264/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 265/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 266/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 267/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 268/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 269/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 270/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 271/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 272/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 273/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 274/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 275/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 276/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 277/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 278/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 279/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 280/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 281/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 282/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 283/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 284/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 285/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 286/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 287/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 288/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 289/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 290/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1446\n",
      "Epoch 291/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 292/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 293/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 294/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 295/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 296/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 297/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 298/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 299/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.3424 - loss: 0.1444 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "Epoch 300/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3424 - loss: 0.1443 - val_accuracy: 0.3575 - val_loss: 0.1447\n",
      "24.646202800038736\n"
     ]
    }
   ],
   "source": [
    "start = perf_counter()\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=300,\n",
    "    validation_data=(x_val, y_val),\n",
    "    batch_size=1000,\n",
    "    # callbacks=[LearningRateScheduler(drop_lr)]\n",
    ")\n",
    "\n",
    "print(perf_counter() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "bd45ceea-61ca-4803-8402-438499aea5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8202898550724638, 0.8202898550724638)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(x_val)\n",
    "\n",
    "(~y_val).mean(), ((y_pred > .5) == y_val).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "9e1574e0-25df-4eae-9ef7-cba652b7de87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Gm', 'Drought', 'Nutrient_Deficiency', 'Fs', 'Salinity'],\n",
       " array([0.73913043, 0.91304348, 0.78743961, 0.83574879, 0.82608696]),\n",
       " array([0.73913043, 0.91304348, 0.78743961, 0.83574879, 0.82608696]))"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stresses, (~y_val).mean(axis=0), ((y_pred > .5) == y_val).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "0469e17e-c812-4388-8bf0-05e2448c0d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'NN Loss over Training')"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.gca()\n",
    "\n",
    "ax.plot(history.history['loss'], label='Training')\n",
    "ax.plot(\n",
    "    np.convolve(np.array(history.history['val_loss']), np.ones(5)/5, mode='valid'),\n",
    "    label='Validation (Running Mean)'\n",
    ")\n",
    "ax.legend()\n",
    "ax.set_xlabel('# Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_ylim((0, 1))\n",
    "ax.set_title('NN Loss over Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b89ace9-8c98-4953-91eb-acc9b86fea2f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44d6a47-2404-48a9-8b45-71f815caaf6f",
   "metadata": {},
   "source": [
    "### Layer-Wise Relevance Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "4e57dab5-a7ea-4b4c-9c2e-6face810fd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "52c174af-903b-4db0-854c-f48d2eaab2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i_s = np.random.choice(x_pca.shape[0], n_samples, replace=False)\n",
    "# temp_x = x_pca[i_s]\n",
    "\n",
    "temp_x = np.copy(x)\n",
    "activations = [temp_x]\n",
    "for layer in model.layers:\n",
    "    temp_x = layer(temp_x)\n",
    "    activations.append(temp_x.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "d704b0e0-2b45-46ca-becc-e0a9304f94ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    x = x.numpy()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "9ebb5346-4cb9-4354-83e2-2fcd0d2bcec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6: 0.006613000005017966s\n",
      "5: 0.0016463000210933387s\n",
      "4: 0.00138519995380193s\n",
      "3: 0.0008210999658331275s\n",
      "2: 0.004533899948000908s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1 is different from 35)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[301], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m weights_p \u001b[38;5;241m=\u001b[39m weights \u001b[38;5;241m*\u001b[39m (weights \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     16\u001b[0m weights_n \u001b[38;5;241m=\u001b[39m weights \u001b[38;5;241m*\u001b[39m (weights \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m pre_activations_p \u001b[38;5;241m=\u001b[39m \u001b[43mactivations\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mweights_p\u001b[49m\n\u001b[0;32m     19\u001b[0m pre_activations_n \u001b[38;5;241m=\u001b[39m activations[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m@\u001b[39m weights_n\n\u001b[0;32m     21\u001b[0m r \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(activations[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1 is different from 35)"
     ]
    }
   ],
   "source": [
    "alpha = 1\n",
    "beta = 0\n",
    "epsilon = 1e-5\n",
    "\n",
    "prev_relevance = activations[-1]\n",
    "\n",
    "for i in range(len(activations)-1,0,-1):\n",
    "    start_time = perf_counter()\n",
    "    \n",
    "    weights = np.ones((activations[i-1].shape[1], activations[i].shape[1]))\n",
    "    \n",
    "    if model.layers[i-1].weights:\n",
    "        weights = model.layers[i-1].weights[0].numpy()\n",
    "\n",
    "    weights_p = weights * (weights > 0)\n",
    "    weights_n = weights * (weights < 0)\n",
    "\n",
    "    pre_activations_p = activations[i-1] @ weights_p\n",
    "    pre_activations_n = activations[i-1] @ weights_n\n",
    "\n",
    "    r = np.zeros(activations[i-1].shape)\n",
    "\n",
    "    for j in range(activations[i-1].shape[1]):        \n",
    "        r_a = activations[i-1][:,j,np.newaxis] * np.repeat(weights_p[j,np.newaxis],activations[i-1].shape[0],axis=0) / (pre_activations_p + epsilon)\n",
    "\n",
    "        if beta == 0:\n",
    "            r[:,j] = ((alpha * r_a) * prev_relevance).sum(axis=1)\n",
    "            continue\n",
    "\n",
    "        r_b = activations[i-1][:,j,np.newaxis] * np.repeat(weights_n[j,np.newaxis],activations[i-1].shape[0],axis=0) / (pre_activations_n + epsilon)\n",
    "        r[:,j] = ((alpha * r_a - beta * r_b) * prev_relevance).sum(axis=1)\n",
    "\n",
    "    prev_relevance = r\n",
    "\n",
    "    print(f'{i}: {perf_counter() - start_time}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca95f9d-fe3b-449a-b557-699338c8bbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "del activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71957c83-6665-41a3-b090-95873bbb8ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_relevances = prev_relevance / prev_relevance.max()\n",
    "input_relevances = prev_relevance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69b22c1-4a54-4565-aef2-343fe5677469",
   "metadata": {},
   "source": [
    "#### Graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24324b37-0eb4-4d12-b03b-20f1ef7090fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_stressed_samples = 6\n",
    "# assert n_stressed_samples < n_samples\n",
    "\n",
    "# i_stressed = np.random.choice(np.arange(i_s.shape[0])[y[i_s].any(axis=1)], n_stressed_samples, replace=False)\n",
    "# i_s_stressed = i_s[i_stressed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bc32434-24f1-4060-842e-b5060e2c4ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(3, 2, constrained_layout=True, figsize=(12,9))\n",
    "# axs = list(itertools.chain.from_iterable(axs))\n",
    "# x_h = np.arange(input_relevances.shape[1])\n",
    "\n",
    "# ax_min, ax_max = input_relevances[i_stressed].min() * 1.05,input_relevances[i_stressed].max() * 1.05\n",
    "\n",
    "# for i, ax in enumerate(axs):\n",
    "#     ax.bar(x_h, input_relevances[i_stressed[i]])\n",
    "#     ax.set_xticks(x_h, labels=trait_cols, rotation=90)\n",
    "#     ax.set_title(\n",
    "#         f'Sample #{i_s_stressed[i]} {[stresses[j] for j in range(len(stresses)) if y[i_s_stressed[i]][j]]}'\n",
    "#     )\n",
    "#     ax.set_ylabel('Normalized Relevance')\n",
    "#     ax.set_ylim((ax_min, ax_max))\n",
    "\n",
    "# fig.suptitle(f'Layer-wise Relevance Propagation ($\\\\alpha$={alpha}, $\\\\beta$={beta})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ef8320-fada-4060-9f5f-de847d4b6eec",
   "metadata": {},
   "source": [
    "#### Save to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94ebca4b-5873-4b31-a599-50a4396a2bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lrp_df = pd.DataFrame(input_relevances, index=i_s, columns=trait_cols)\n",
    "# lrp_df[stresses] = df.loc[i_s, stresses]\n",
    "# lrp_df.to_csv(f'lrp_a{alpha}_b{beta}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69817d6b-b6af-4acd-bf98-b67b8a2011a2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Trait Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a8f35b-6fae-4c8a-b466-5ad1f42637aa",
   "metadata": {},
   "source": [
    "### SIS\n",
    "Simplified version of [this paper](https://proceedings.mlr.press/v89/carter19a/carter19a.pdf). \n",
    "\n",
    "Iteratively replaces different traits with their mean values. The trait that, when replaced, yields the highest accuracy is the least important. The least important trait is then replaced with its mean, and the process is repeated for the remaining traits, until the accuracy is below 80%. The remaining traits are thus the ones necessary for at least an 80% accuracy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c804f6e7-6706-466d-81d1-e3e762e53a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gm: ['Photo', 'Ci', 'Cond', 'CTleaf', 'Trmmol', 'WUEi', 'WUEin', 'Fv_Fm', 'Fv_Fo', 'PI', 'SLA', 'LWC', 'Suc', 'OP', 'OP100', 'RWC', 'WP', 'N', 'C', 'Neoxanthin', 'Violaxanthin', 'Lutein', 'Zeaxanthin', 'Chl_b', 'Chl_a', 'B_carotene', 'Glucose', 'Fructose', 'Sucrose', 'Sugars', 'Starch', 'Ellagic', 'Gal', 'Rut', 'CTs']\n",
      "Drought: ['Photo', 'Ci', 'Cond', 'CTleaf', 'Trmmol', 'WUEi', 'WUEin', 'Fv_Fm', 'Fv_Fo', 'PI', 'SLA', 'LWC', 'Suc', 'OP', 'OP100', 'RWC', 'WP', 'N', 'C', 'Neoxanthin', 'Violaxanthin', 'Lutein', 'Zeaxanthin', 'Chl_b', 'Chl_a', 'B_carotene', 'Glucose', 'Fructose', 'Sucrose', 'Sugars', 'Starch', 'Ellagic', 'Gal', 'Rut', 'CTs']\n",
      "Nutrient_Deficiency: ['Photo', 'Ci', 'Cond', 'CTleaf', 'Trmmol', 'WUEi', 'WUEin', 'Fv_Fm', 'Fv_Fo', 'PI', 'SLA', 'LWC', 'Suc', 'OP', 'OP100', 'RWC', 'WP', 'N', 'C', 'Neoxanthin', 'Violaxanthin', 'Lutein', 'Zeaxanthin', 'Chl_b', 'Chl_a', 'B_carotene', 'Glucose', 'Fructose', 'Sucrose', 'Sugars', 'Starch', 'Ellagic', 'Gal', 'Rut', 'CTs']\n",
      "Fs: ['Photo', 'Ci', 'Cond', 'CTleaf', 'Trmmol', 'WUEi', 'WUEin', 'Fv_Fm', 'Fv_Fo', 'PI', 'SLA', 'LWC', 'Suc', 'OP', 'OP100', 'RWC', 'WP', 'N', 'C', 'Neoxanthin', 'Violaxanthin', 'Lutein', 'Zeaxanthin', 'Chl_b', 'Chl_a', 'B_carotene', 'Glucose', 'Fructose', 'Sucrose', 'Sugars', 'Starch', 'Ellagic', 'Gal', 'Rut', 'CTs']\n",
      "Salinity: ['Photo', 'Ci', 'Cond', 'CTleaf', 'Trmmol', 'WUEi', 'WUEin', 'Fv_Fo', 'PI', 'N', 'C', 'Neoxanthin', 'Violaxanthin', 'Lutein', 'Zeaxanthin', 'Chl_b', 'Chl_a', 'B_carotene', 'Glucose', 'Fructose', 'Sucrose', 'Sugars', 'Starch', 'Ellagic', 'Gal', 'Rut', 'CTs']\n"
     ]
    }
   ],
   "source": [
    "important = {}\n",
    "\n",
    "for stress_i, stress in enumerate(stresses):\n",
    "    target = np.zeros((len(stresses),))\n",
    "    target[stress_i] = 1\n",
    "    \n",
    "    selected = (y == target).all(axis=1)\n",
    "    checked = np.zeros((x.shape[1],)).astype(bool)\n",
    "\n",
    "    mask = np.repeat((1-np.identity(x.shape[1])).reshape((x.shape[1], 1, x.shape[1])), selected.sum(), axis=1)\n",
    "    means = x.mean(axis=0).reshape((1, 1, x.shape[1])).repeat(x.shape[1], axis=0).repeat(selected.sum(), axis=1)\n",
    "    \n",
    "    remove_traits = []\n",
    "    temp_x = np.copy(x[selected])\n",
    "    \n",
    "    for i in range(x.shape[1]):  \n",
    "        masked = np.repeat(temp_x.reshape((1, selected.sum(), x.shape[1])), x.shape[1], axis=0)\n",
    "        \n",
    "        masked = (masked * mask) + (means * (1-mask))\n",
    "        \n",
    "        acc = np.zeros((x.shape[1],))\n",
    "        \n",
    "        for j in range(x.shape[1]):\n",
    "            if checked[j]:\n",
    "                continue\n",
    "            acc[j] = ((model(masked[j]) > .5).numpy() == target).all(axis=1).mean()\n",
    "        \n",
    "        least_important = acc.argmax()\n",
    "    \n",
    "        temp_x = masked[least_important]\n",
    "    \n",
    "        remove_traits.append((least_important, acc[least_important]))\n",
    "        checked[least_important] = True\n",
    "\n",
    "    remove_traits = np.array(remove_traits)\n",
    "    important[stress] = list(trait_cols[remove_traits[:,1]<.8])\n",
    "\n",
    "    print(f'{stress}: {important[stress]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d2d500-4882-4ba6-9bd8-584d431e3f5c",
   "metadata": {},
   "source": [
    "#### Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72e711b6-792f-4bc5-8af0-16f285ff1a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise_important = {}\n",
    "\n",
    "# for stress_i, stress in enumerate(stresses):\n",
    "#     target = np.zeros((len(stresses),))\n",
    "#     target[stress_i] = 1\n",
    "    \n",
    "#     selected = (y == target).all(axis=1)\n",
    "#     checked = np.zeros((x.shape[1],)).astype(bool)\n",
    "\n",
    "#     mask = np.repeat((1-np.identity(x.shape[1])).reshape((x.shape[1], 1, x.shape[1])), selected.sum(), axis=1)\n",
    "#     # noise = x.mean(axis=0).reshape((1, 1, x.shape[1])).repeat(x.shape[1], axis=0).repeat(selected.sum(), axis=1)\n",
    "#     sigma = 2\n",
    "#     noise = ((x[selected]) + sigma*x.std(axis=0)*(np.random.random_sample((selected.sum(), x.shape[1])) - 1/sigma)).reshape((1, selected.sum(), x.shape[1])).repeat(x.shape[1], axis=0)\n",
    "    \n",
    "#     remove_traits = []\n",
    "#     temp_x = np.copy(x[selected])\n",
    "    \n",
    "#     for i in range(x.shape[1]):  \n",
    "#         masked = np.repeat(temp_x.reshape((1, selected.sum(), x.shape[1])), x.shape[1], axis=0)\n",
    "        \n",
    "#         masked = (masked * mask) + (noise * (1-mask))\n",
    "        \n",
    "#         acc = np.zeros((x.shape[1],))\n",
    "        \n",
    "#         for j in range(x.shape[1]):\n",
    "#             if checked[j]:\n",
    "#                 continue\n",
    "#             acc[j] = ((model(masked[j]) > .5).numpy() == target).all(axis=1).mean()\n",
    "        \n",
    "#         least_important = acc.argmax()\n",
    "    \n",
    "#         temp_x = masked[least_important]\n",
    "    \n",
    "#         remove_traits.append((least_important, acc[least_important]))\n",
    "#         checked[least_important] = True\n",
    "\n",
    "#     remove_traits = np.array(remove_traits)\n",
    "#     noise_important[stress] = list(trait_cols[remove_traits[:,1]<.8])\n",
    "\n",
    "#     print(f'{stress}: {noise_important[stress]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80936d28-60e3-4e3a-9048-8f527599ee61",
   "metadata": {},
   "source": [
    "### Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a5dfb9e-02d4-4942-ac13-cd9562258a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ir_normal = input_relevances / input_relevances.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db256ece-dd45-42e5-a10f-04f0976e3665",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.empty((len(stresses), trait_cols.shape[0]))\n",
    "for stress_i in range(len(stresses)):\n",
    "    mask = np.zeros((y.shape[1],))\n",
    "    mask[stress_i] = 1\n",
    "    \n",
    "    means[stress_i] = ir_normal[(y==mask).all(axis=1)].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8fbef9b9-1031-44ef-a878-c558f4346f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gm: ['WP', 'Glucose', 'WUEin', 'B_carotene', 'Fv_Fm', 'Sucrose', 'Photo', 'Cond', 'Gal', 'RWC', 'OP', 'CTs', 'N', 'WUEi', 'LWC', 'Violaxanthin', 'Fv_Fo', 'Suc', 'Trmmol', 'Fructose', 'PI', 'OP100', 'Zeaxanthin', 'Sugars', 'Rut', 'Neoxanthin']\n",
      "Drought: ['Violaxanthin', 'N', 'B_carotene', 'Gal', 'Fv_Fo', 'Fv_Fm', 'LWC', 'Glucose', 'PI', 'Fructose', 'WUEin', 'Sucrose', 'Neoxanthin', 'Suc', 'WP', 'RWC', 'Lutein', 'WUEi', 'Zeaxanthin', 'Chl_b', 'OP', 'SLA', 'Chl_a', 'CTs', 'Sugars', 'Photo', 'OP100', 'Rut']\n",
      "Nutrient_Deficiency: ['Violaxanthin', 'OP', 'WUEin', 'WP', 'WUEi', 'Sucrose', 'Fv_Fo', 'RWC', 'LWC', 'Fv_Fm', 'Rut', 'Suc', 'Gal', 'Chl_b', 'N', 'CTs', 'B_carotene', 'Neoxanthin', 'Zeaxanthin', 'Ellagic', 'Photo', 'PI']\n",
      "Fs: ['WUEin', 'N', 'WP', 'Sucrose', 'Fv_Fm', 'Gal', 'PI', 'Fv_Fo', 'Suc', 'LWC', 'WUEi', 'Glucose', 'RWC', 'B_carotene', 'OP', 'Violaxanthin', 'Photo', 'SLA', 'CTs', 'Sugars', 'Lutein', 'Chl_b', 'Zeaxanthin', 'Fructose', 'Neoxanthin', 'Rut', 'OP100']\n",
      "Salinity: ['Sucrose', 'WUEin', 'WP', 'WUEi', 'Rut', 'LWC', 'Violaxanthin', 'RWC', 'Fv_Fo', 'OP', 'Zeaxanthin', 'Suc', 'N', 'CTs', 'Gal', 'Ellagic', 'Fv_Fm', 'B_carotene', 'Chl_b', 'Cond', 'Fructose', 'C', 'Glucose', 'Neoxanthin', 'Photo', 'PI', 'SLA']\n",
      "Using threshold: 0.17\n"
     ]
    }
   ],
   "source": [
    "thresh = .17\n",
    "\n",
    "for stress_i in range(len(stresses)):\n",
    "    i = (-1*means[stress_i, means[stress_i] > thresh]).argsort()\n",
    "    print(f'{stresses[stress_i]}: {list(trait_cols[means[stress_i] > thresh][i])}')\n",
    "\n",
    "print(f'Using threshold: {thresh}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eadc438-258b-4581-984d-9639a43fc96e",
   "metadata": {},
   "source": [
    "Sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd7d9a1-8900-44d3-8960-e7237818b238",
   "metadata": {},
   "source": [
    "### Dominance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cdf07a85-b6af-4205-bc10-2cf5d0512dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gm: 156, Gm: 156, both: 156\n",
      "Gm: 156, Drought: 34, both: 15\n",
      "Gm: 156, Nutrient_Deficiency: 120, both: 0\n",
      "Gm: 156, Fs: 70, both: 68\n",
      "Gm: 156, Salinity: 89, both: 0\n",
      "Drought: 34, Gm: 156, both: 15\n",
      "Drought: 34, Drought: 34, both: 34\n",
      "Drought: 34, Nutrient_Deficiency: 120, both: 20\n",
      "Drought: 34, Fs: 70, both: 15\n",
      "Drought: 34, Salinity: 89, both: 0\n",
      "Nutrient_Deficiency: 120, Gm: 156, both: 0\n",
      "Nutrient_Deficiency: 120, Drought: 34, both: 20\n",
      "Nutrient_Deficiency: 120, Nutrient_Deficiency: 120, both: 120\n",
      "Nutrient_Deficiency: 120, Fs: 70, both: 0\n",
      "Nutrient_Deficiency: 120, Salinity: 89, both: 87\n",
      "Fs: 70, Gm: 156, both: 68\n",
      "Fs: 70, Drought: 34, both: 15\n",
      "Fs: 70, Nutrient_Deficiency: 120, both: 0\n",
      "Fs: 70, Fs: 70, both: 70\n",
      "Fs: 70, Salinity: 89, both: 0\n",
      "Salinity: 89, Gm: 156, both: 0\n",
      "Salinity: 89, Drought: 34, both: 0\n",
      "Salinity: 89, Nutrient_Deficiency: 120, both: 87\n",
      "Salinity: 89, Fs: 70, both: 0\n",
      "Salinity: 89, Salinity: 89, both: 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thead\\AppData\\Local\\Temp\\ipykernel_21888\\1216449937.py:16: RuntimeWarning: Mean of empty slice.\n",
      "  mean_both = x[(y==mask_both).all(axis=1)].mean(axis=0)\n",
      "C:\\Users\\thead\\.virtualenvs\\stress_prediction-gwCXE-ib\\Lib\\site-packages\\numpy\\core\\_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    }
   ],
   "source": [
    "dists = np.empty((len(stresses), len(stresses)))\n",
    "\n",
    "for s1 in range(len(stresses)):\n",
    "    mask1 = np.zeros((len(stresses),))\n",
    "    mask1[s1] = 1\n",
    "\n",
    "    mean1 = x[(y==mask1).all(axis=1)].mean(axis=0)\n",
    "    \n",
    "    for s2 in range(len(stresses)):\n",
    "        mask2 = np.zeros((len(stresses),))\n",
    "        mask2[s2] = 1\n",
    "\n",
    "        mean2 = x[(y==mask2).all(axis=1)].mean(axis=0)\n",
    "\n",
    "        mask_both = np.logical_or(mask1, mask2)\n",
    "        mean_both = x[(y==mask_both).all(axis=1)].mean(axis=0)\n",
    "\n",
    "        d1 = np.linalg.norm(mean_both - mean1)\n",
    "        d2 = np.linalg.norm(mean_both - mean2)\n",
    "\n",
    "        if d1 + d2 == 0:\n",
    "            dists[s1,s2] = 0\n",
    "        else:\n",
    "            dists[s1,s2] = (d2 - d1)/(d1 + d2)\n",
    "\n",
    "        print(f'{stresses[s1]}: {(y==mask1).all(axis=1).sum()}, {stresses[s2]}: {(y==mask2).all(axis=1).sum()}, both: {(y==mask_both).all(axis=1).sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8889b3aa-b0da-482a-879a-2127bb74fbbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x1e7e96b7fd0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(dists, cmap='coolwarm')\n",
    "plt.xticks(np.arange(len(stresses)), stresses, rotation=90)\n",
    "plt.yticks(np.arange(len(stresses)), stresses)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b25bcd-e28f-488f-9e3f-178f80fee9e9",
   "metadata": {},
   "source": [
    "Positive value means closer to the variable on the vertical axis, or vertical axis variable is dominant over the horizontal axis variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0f91ff-be65-45d8-9f60-e219a3f6c748",
   "metadata": {},
   "source": [
    "### Point-Biserial Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "48866c4a-b2d1-45b1-967e-7f5eecc0b4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = np.empty((len(stresses), len(trait_cols)))\n",
    "\n",
    "for s_i in range(len(stresses)):\n",
    "    mask = np.zeros((len(stresses),))\n",
    "    mask[s_i] = 1\n",
    "    mask_v = (y==mask).all(axis=1)\n",
    "\n",
    "    mask_n = np.zeros((len(stresses),))\n",
    "    mask_n_v = (y==mask_n).all(axis=1)\n",
    "\n",
    "    c = (x[mask_v].mean(axis=0) - x[mask_n_v].mean(axis=0)) / x[mask_v | mask_n_v].std(axis=0)\n",
    "    corrs[s_i] = c * np.sqrt(mask_v.sum() * mask_n_v.sum()) / (mask_v | mask_n_v).sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9ddbefcc-7155-4ec7-aadf-1539bf66cc91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6892757293534459"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.cdf(np.abs(corrs)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b94fa6-8c02-44d6-9770-6989d3b68192",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
